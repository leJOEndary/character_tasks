{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_account_file = '../../creds/google__sa.json'\n",
    "\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "included_sheet_names = [\n",
    "    \"Conversations_Batch_7\",\n",
    "    \"Conversations_Batch_8\",\n",
    "    \"Conversations_Batch_9\",\n",
    "]\n",
    "\n",
    "jupyter_gdrive_folder_ids = [\n",
    "    \"1Z1bdYMe2Qmo_vs-OaKDaYIiV3rIqLJH9\", # V0\n",
    "    \"1sfPFHkXYpKyY41V0pfz3Qw3k4VLy5Hvb\", # V1\n",
    "    \"1jV7WA5zB172DJUp7Z2XzHr62E6U6_NtY\",\n",
    "]\n",
    "\n",
    "delivery_sheet_id = \"1eUif5I8xhHU8fY0X9v8r2JI9hWPh7Dq_9VXpSIHwww4\"\n",
    "delivery_jsonl_gdrive_folder_id = \"1BXvUdQMulQkJk5rQvJr8Op07JbciBuTx\"\n",
    "destination_folder_url = f\"https://drive.google.com/drive/folders/{delivery_jsonl_gdrive_folder_id}\"\n",
    "DELIVERY_BATCH_NAME = \"Batch 10\"\n",
    "\n",
    "insights_sheet_id = \"1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w\"\n",
    "INSIGHTS_VERSION_TAB = \"v1 (Jan 25)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "import io\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_turns(messages):\n",
    "    count = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"User\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "def standardize_date_format(date):\n",
    "    \"\"\"\n",
    "    Given a date string, standardize the date format to YYYY/MM/DD.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the date string into a datetime object\n",
    "        standardized_date = datetime.strptime(date, \"%Y/%m/%d\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Attempt to parse other common formats here\n",
    "            # Example: MM/DD/YYYY\n",
    "            standardized_date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "        except ValueError:\n",
    "            return \"Invalid date format\"\n",
    "\n",
    "    # Format the datetime object into the desired string format\n",
    "    return standardized_date.strftime(\"%Y/%m/%d\")\n",
    "###################################\n",
    "\n",
    "\n",
    "#########################\n",
    "    # Colab #\n",
    "#########################\n",
    "\n",
    "\n",
    "def update_colab_notebook(colab_link, local_nb_path, sa_creds_path):\n",
    "    \"\"\"\n",
    "    Update a Google Colab notebook file in Google Drive.\n",
    "\n",
    "    :param colab_link: The link to the Colab notebook in Google Drive.\n",
    "    :param local_nb_path: The local path of the notebook file to upload.\n",
    "    :param sa_creds_path: The path to the service account credentials.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract file ID from the Colab link\n",
    "        file_id = colab_link.split('/drive/')[1].split('/')[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Colab link format\")\n",
    "\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(sa_creds_path, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Specify the file to upload\n",
    "    media = MediaFileUpload(local_nb_path, resumable=True)\n",
    "\n",
    "    # Update the file\n",
    "    try:\n",
    "        updated_file = service.files().update(fileId=file_id, media_body=media).execute()\n",
    "        return f\"Updated file ID: {updated_file.get('id')}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error updating file: {e}\"\n",
    "\n",
    "\n",
    "def get_colab_notebook(colab_link, sa_creds_path) -> nbformat.NotebookNode:\n",
    "    try:\n",
    "        # Extract file ID from the Colab link\n",
    "        file_id = colab_link.split('/drive/')[1].split('/')[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Colab link format\")\n",
    "\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(sa_creds_path, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Download the file\n",
    "    try:\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "        \n",
    "        # Load as nbformat notebook\n",
    "        notebook = nbformat.reads(fh.getvalue().decode(), as_version=4)\n",
    "        return notebook\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_file_name_from_colab_link(colab_link, service_account_file):\n",
    "    try:\n",
    "        file_id = colab_link.split('/drive/')[1]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(service_account_file, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    try:\n",
    "        file = service.files().get(fileId=file_id).execute()\n",
    "        return file.get('name')\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_file_names_parallel(links, service_account_file, max_workers=100):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_file_name_from_colab_link, link, service_account_file): link for link in links}\n",
    "        results = {}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching File Names\"):\n",
    "            link = futures[future]\n",
    "            try:\n",
    "                file_name = future.result()\n",
    "                results[link] = file_name\n",
    "            except Exception as e:\n",
    "                results[link] = None\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Remote Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations_Batch_7\n",
      "Conversations_Batch_8\n",
      "Conversations_Batch_9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>metadata__topic</th>\n",
       "      <th>assigned_to_email</th>\n",
       "      <th>completion_status</th>\n",
       "      <th>modified_question?</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>completion_date</th>\n",
       "      <th>comments</th>\n",
       "      <th>metadata__type</th>\n",
       "      <th>metadata__target_length</th>\n",
       "      <th>review_status</th>\n",
       "      <th>reviewer_email</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>https://colab.research.google.com/drive/16akew...</td>\n",
       "      <td>228_problem solving - write code in python.ipynb</td>\n",
       "      <td>alexsander.j@turing,com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>29</td>\n",
       "      <td>2/17/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>5</td>\n",
       "      <td>python basics &amp; scripting - explain complex co...</td>\n",
       "      <td>chandrashekhar.s@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>45</td>\n",
       "      <td>7/2/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>paulo.c@turing.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>https://colab.research.google.com/drive/1zOj_5...</td>\n",
       "      <td>cloud_computing_OR_frameworks__answer_infra_qu...</td>\n",
       "      <td>aarunik.g@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>https://colab.research.google.com/drive/1l4T0b...</td>\n",
       "      <td>cloud_computing_OR_frameworks__answer_infra_qu...</td>\n",
       "      <td>aarunik.g@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>https://colab.research.google.com/drive/1DH6pd...</td>\n",
       "      <td>machine_learning__write_code_in_python__10_V8_...</td>\n",
       "      <td>aarunik.g@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>https://colab.research.google.com/drive/1R7Z-6...</td>\n",
       "      <td>web_development__write_code_in_python__5__19-0...</td>\n",
       "      <td>arnold.o@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/20/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unreviewed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>https://colab.research.google.com/drive/1Ybter...</td>\n",
       "      <td>web_development__write_code_in_python__6__19-0...</td>\n",
       "      <td>arnold.o@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/20/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unreviewed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3185</th>\n",
       "      <td>https://colab.research.google.com/drive/112T7j...</td>\n",
       "      <td>web_development__write_code_in_python__7__19-0...</td>\n",
       "      <td>arnold.o@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/20/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unreviewed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>https://colab.research.google.com/drive/1WQuPA...</td>\n",
       "      <td>web_development__write_code_in_python__8__19-0...</td>\n",
       "      <td>arnold.o@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unreviewed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3187</th>\n",
       "      <td>https://colab.research.google.com/drive/1c9Lky...</td>\n",
       "      <td>web_development__write_code_in_python__9__19-0...</td>\n",
       "      <td>arnold.o@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>50</td>\n",
       "      <td>2/19/2023</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Unreviewed</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>562 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_link  \\\n",
       "224   https://colab.research.google.com/drive/16akew...   \n",
       "505                                                   5   \n",
       "1246  https://colab.research.google.com/drive/1zOj_5...   \n",
       "1247  https://colab.research.google.com/drive/1l4T0b...   \n",
       "1248  https://colab.research.google.com/drive/1DH6pd...   \n",
       "...                                                 ...   \n",
       "3183  https://colab.research.google.com/drive/1R7Z-6...   \n",
       "3184  https://colab.research.google.com/drive/1Ybter...   \n",
       "3185  https://colab.research.google.com/drive/112T7j...   \n",
       "3186  https://colab.research.google.com/drive/1WQuPA...   \n",
       "3187  https://colab.research.google.com/drive/1c9Lky...   \n",
       "\n",
       "                                        metadata__topic  \\\n",
       "224    228_problem solving - write code in python.ipynb   \n",
       "505   python basics & scripting - explain complex co...   \n",
       "1246  cloud_computing_OR_frameworks__answer_infra_qu...   \n",
       "1247  cloud_computing_OR_frameworks__answer_infra_qu...   \n",
       "1248  machine_learning__write_code_in_python__10_V8_...   \n",
       "...                                                 ...   \n",
       "3183  web_development__write_code_in_python__5__19-0...   \n",
       "3184  web_development__write_code_in_python__6__19-0...   \n",
       "3185  web_development__write_code_in_python__7__19-0...   \n",
       "3186  web_development__write_code_in_python__8__19-0...   \n",
       "3187  web_development__write_code_in_python__9__19-0...   \n",
       "\n",
       "                assigned_to_email completion_status modified_question?  \\\n",
       "224       alexsander.j@turing,com              Done              FALSE   \n",
       "505   chandrashekhar.s@turing.com              Done              FALSE   \n",
       "1246         aarunik.g@turing.com              Done                      \n",
       "1247         aarunik.g@turing.com              Done                      \n",
       "1248         aarunik.g@turing.com              Done                      \n",
       "...                           ...               ...                ...   \n",
       "3183          arnold.o@turing.com              Done                      \n",
       "3184          arnold.o@turing.com              Done                      \n",
       "3185          arnold.o@turing.com              Done                      \n",
       "3186          arnold.o@turing.com              Done                      \n",
       "3187          arnold.o@turing.com              Done                      \n",
       "\n",
       "     duration_mins completion_date comments metadata__type  \\\n",
       "224             29       2/17/2024                           \n",
       "505             45        7/2/2024                           \n",
       "1246            60       2/19/2024     None           None   \n",
       "1247            60       2/19/2024     None           None   \n",
       "1248            60       2/19/2024     None           None   \n",
       "...            ...             ...      ...            ...   \n",
       "3183            60       2/20/2024                           \n",
       "3184            60       2/20/2024                           \n",
       "3185            60       2/20/2024                           \n",
       "3186            60       2/19/2023                           \n",
       "3187            50       2/19/2023                           \n",
       "\n",
       "     metadata__target_length review_status      reviewer_email Start Time  \\\n",
       "224                                                                     -   \n",
       "505                               Reviewed  paulo.c@turing.com       None   \n",
       "1246                    None          None                None       None   \n",
       "1247                    None          None                None       None   \n",
       "1248                    None          None                None       None   \n",
       "...                      ...           ...                 ...        ...   \n",
       "3183                            Unreviewed                None       None   \n",
       "3184                            Unreviewed                None       None   \n",
       "3185                            Unreviewed                None       None   \n",
       "3186                            Unreviewed                None       None   \n",
       "3187                            Unreviewed                None       None   \n",
       "\n",
       "     End Time  \n",
       "224         -  \n",
       "505      None  \n",
       "1246     None  \n",
       "1247     None  \n",
       "1248     None  \n",
       "...       ...  \n",
       "3183     None  \n",
       "3184     None  \n",
       "3185     None  \n",
       "3186     None  \n",
       "3187     None  \n",
       "\n",
       "[562 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sheets_utils import download_sheet_as_df\n",
    "\n",
    "\n",
    "progress_batches = []\n",
    "for sheet_name in included_sheet_names:\n",
    "    print(sheet_name)\n",
    "    bdf = download_sheet_as_df(service_account_file, tracking_sheet_id, sheet_name)\n",
    "    progress_batches.append(bdf)\n",
    "\n",
    "df = pd.concat(progress_batches, ignore_index=True)\n",
    "completed_df = df[df[\"completion_status\"] == \"Done\"]\n",
    "completed_df = completed_df.drop_duplicates(subset=[\"task_link\"])\n",
    "\n",
    "delivered = pd.concat([\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 1\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 2\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 3\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 4\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 5\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 6\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 7\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 8\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 9\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "completed_to_be_delivered_df = completed_df[~completed_df[\"task_link\"].isin(delivered[\"task_link\"])]\n",
    "completed_to_be_delivered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>n_messages</th>\n",
       "      <th>number_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1zOj_5...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1UoJmB...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/16akew...</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1WDGIi...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1EPUNK...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>https://colab.research.google.com/drive/112T7j...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>https://colab.research.google.com/drive/1R7Z-6...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>https://colab.research.google.com/drive/1WQuPA...</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>https://colab.research.google.com/drive/17WwbW...</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>https://colab.research.google.com/drive/1c9Lky...</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link  n_messages  \\\n",
       "0    https://colab.research.google.com/drive/1zOj_5...           8   \n",
       "1    https://colab.research.google.com/drive/1UoJmB...           6   \n",
       "2    https://colab.research.google.com/drive/16akew...           8   \n",
       "3    https://colab.research.google.com/drive/1WDGIi...          11   \n",
       "4    https://colab.research.google.com/drive/1EPUNK...           8   \n",
       "..                                                 ...         ...   \n",
       "556  https://colab.research.google.com/drive/112T7j...           6   \n",
       "557  https://colab.research.google.com/drive/1R7Z-6...           8   \n",
       "558  https://colab.research.google.com/drive/1WQuPA...          10   \n",
       "559  https://colab.research.google.com/drive/17WwbW...          12   \n",
       "560  https://colab.research.google.com/drive/1c9Lky...          12   \n",
       "\n",
       "     number_of_turns  \n",
       "0                  4  \n",
       "1                  3  \n",
       "2                  3  \n",
       "3                  4  \n",
       "4                  4  \n",
       "..               ...  \n",
       "556                2  \n",
       "557                4  \n",
       "558                4  \n",
       "559                4  \n",
       "560                3  \n",
       "\n",
       "[561 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.llm_reviewer.notebook_parser import notebook_parser\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "notebooks = []\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "def process_task_link(task_link):\n",
    "    try:\n",
    "        notebook = get_colab_notebook(task_link, service_account_file)\n",
    "        parsed_notebook = notebook_parser(notebook)\n",
    "        parsed_messages = parsed_notebook[\"messages\"]\n",
    "        number_of_turns = get_number_of_turns(parsed_messages)\n",
    "        return parsed_notebook, {\n",
    "            \"task_link\": task_link,\n",
    "            \"n_messages\": len(parsed_messages),\n",
    "            \"number_of_turns\": number_of_turns,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return None, {\n",
    "            \"task_link\": task_link,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = [executor.submit(process_task_link, task_link) for task_link in completed_to_be_delivered_df[\"task_link\"].tolist()]\n",
    "    for future in as_completed(futures):\n",
    "        notebook, result = future.result()\n",
    "        if notebook is not None:\n",
    "            notebooks.append(notebook)\n",
    "            results.append(result)\n",
    "        else:\n",
    "            errors.append(result)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"batch_5_parsed_reviewed.json\", \"r\") as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "results = [r for r in results if r[\"n_messages\"] != 0]\n",
    "for r in results:\n",
    "    r.pop(\"quality_review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4-1106-preview\").encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    score: int = Field(description=\"A score representing how good the conversation is in the given quality aspect, 1 is terrible, 5 is exemplary and flawless.\", ge=1, le=5)\n",
    "    issues: List[str] = Field(description=\"A concrete list of issues in the conversation. 15 words or less each.\")\n",
    "    praises: List[str] = Field(description=\"A concrete list of praise for exceptional behavior the conversation. 15 words or less each.\")\n",
    "\n",
    "\n",
    "class QualityAspect(BaseModel):\n",
    "    name: str = Field(description=\"The name of the quality aspect.\")\n",
    "    instruction: str = Field(description=\"Instructions & details on how to inspect this quality aspect.\")\n",
    "\n",
    "\n",
    "quality_aspects = {\n",
    "    \"Overall\": [\n",
    "        QualityAspect(\n",
    "            name=\"Completness\",\n",
    "            instruction=\"\"\"\n",
    "            How complete is the conversation? Completeness is defined as:\n",
    "            - The assistant always responds to the user.\n",
    "            - The conversation contains at least 1 back and forth between the user and the assistant.\n",
    "            - The conversation flow is not broken.\n",
    "\n",
    "            JUDGE THE ENTIRE CONVERSATION AS A WHOLE.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ],\n",
    "    \"User\": [\n",
    "        QualityAspect(\n",
    "            name=\"Natural & Realistic\", \n",
    "            instruction=\"\"\"\n",
    "            How does the user interaction resemble a real conversation and interactions a real user would have with a highly intelligent coding assistant.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Coherent Follow ups\", \n",
    "            instruction=\"\"\"\n",
    "            How coherent are the user's follow up messages to the assistant's messages in the conversation as a whole.\n",
    "            Ideally, the user would incrementally build on the conversation to achieve their goal.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ],\n",
    "    \"Assistant\": [\n",
    "        QualityAspect(\n",
    "            name=\"Code Quality\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the code that the assistant generates.\n",
    "            Qualities:\n",
    "            #   - Correctness\n",
    "            #   - Optimality\n",
    "            #   - PEP8 Compliance & Readability\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Text Quality\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the text that the assistant generates.\n",
    "            Qualities:\n",
    "            #   - Spelling\n",
    "            #   - Grammar\n",
    "            #   - Capitalization & Punctuation\n",
    "            #   - Information Density (Should be a sweet spot leaning on the concise side, but not too concise... definitely not too verbose)\n",
    "            #   - Explains Code Well\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Markdown Formatting\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the markdown formatting that the assistant generates. Is it leveraging markdown syntax tools to maximize the readability of the text?\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def inspect_conversation_quality_aspect(conversation: List[List[dict]], quality_aspect: QualityAspect):\n",
    "    \"\"\"Inspect a conversation for a given quality aspect.\"\"\"\n",
    "\n",
    "    prompt_template_str = \"\"\"\n",
    "    IDENTITY:\n",
    "    You are one of many specialized judges, so precisely focus on your quality aspect only.\n",
    "\n",
    "    SITUATION:\n",
    "    A large team is building a dataset of illustractions of dialogues showcasing the interaction between a user and a highly intelligent AI in the context of software development scenarios.\n",
    "    - The user's replies should closely resemble authentic user engagement.\n",
    "    - The AI's responses should aim to provide maximum benefit to the user.\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    Given the following conversation, please rate the quality of the conversation according to the given quality aspect.\n",
    "    \n",
    "    ALL QUALITY ASPECTS:\n",
    "    {all_quality_aspects}\n",
    "\n",
    "    YOUR QUALITY ASPECT:\n",
    "    {quality_aspect}\n",
    "    \n",
    "    CONVERSATION:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        callback_manager=callback_manager,\n",
    "        output_cls=Feedback, \n",
    "        prompt_template_str=prompt_template_str, \n",
    "    )\n",
    "    all_quality_aspects = \"\\n\".join([f\"- {key}: {quality_aspect.name}\" for key in quality_aspects.keys() for quality_aspect in quality_aspects[key]])\n",
    "    output = program( \n",
    "        all_quality_aspects=all_quality_aspects,\n",
    "        quality_aspect=quality_aspect.model_dump(),\n",
    "        conversation=conversation[\"messages\"],\n",
    "        description=\"Judge the quality of the conversation according to the given quality aspect. Provide constructive criticism, rarely praise.\"\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def inspect_all_conversation_quality_aspects(conversation) -> dict:\n",
    "    \"\"\"Inspect a conversation for all quality aspects.\"\"\"\n",
    "\n",
    "    quality_results = {}\n",
    "    for key in quality_aspects.keys():\n",
    "        for quality_aspect in quality_aspects[key]:\n",
    "            r = inspect_conversation_quality_aspect(conversation, quality_aspect)\n",
    "            quality_results[f\"{key} - {quality_aspect.name}\"] = r.model_dump()\n",
    "\n",
    "    return quality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing notebooks: 100%|██████████| 1060/1060 [52:46<00:00,  2.99s/it] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "reviewed_results = []\n",
    "\n",
    "def process_notebook(result):\n",
    "    if result is None or len(result[\"notebook\"][\"messages\"]) == 0:\n",
    "        return None\n",
    "    result[\"quality_review\"] = inspect_all_conversation_quality_aspects(result[\"notebook\"])\n",
    "    return result\n",
    "\n",
    "with tqdm(total=len(results), desc=\"Processing notebooks\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=15) as executor:\n",
    "        futures = [executor.submit(process_notebook, result) for result in results]\n",
    "        for future in as_completed(futures):\n",
    "            r = future.result()\n",
    "            if r is not None:\n",
    "                reviewed_results.append(r)\n",
    "            pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviewed_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_5_parsed_reviewed.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     json\u001b[38;5;241m.\u001b[39mdump(\u001b[43mreviewed_results\u001b[49m, f, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_5_parsed_reviewed.json\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     reviewed_results \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviewed_results' is not defined"
     ]
    }
   ],
   "source": [
    "import json \n",
    "\n",
    "with open(\"batch_5_parsed_reviewed.json\", \"w\") as f:\n",
    "    json.dump(reviewed_results, f, indent=4)\n",
    "\n",
    "with open(\"batch_5_parsed_reviewed.json\", \"r\") as f:\n",
    "    reviewed_results = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_link': 'https://colab.research.google.com/drive/1yHgim2bxGo_Sf0c1BsSaFROtZZdfpiud',\n",
       " 'n_messages': 6,\n",
       " 'number_of_turns': 2,\n",
       " 'notebook': {'metadata': {'topic': 'algorithms > by_data_structure > heaps',\n",
       "   'type': 'modification',\n",
       "   'target_turns': '2+'},\n",
       "  'messages': [{'role': 'User',\n",
       "    'content': \"I have a min-heap implemented as a list in Python, and I'd like to add a method to get the kth smallest element. Could you help me with that? Here's my current min-heap class:\\n```python\\nclass MinHeap:\\n    def __init__(self):\\n        self.heap = []\\n\\n    def insert(self, val):\\n        # Implementation for insert\\n        pass\\n\\n    def get_min(self):\\n        # Implementation for get_min\\n        pass\\n```\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': \"Sure, here's a simple breakdown of how the kth_smallest method works in our MinHeap class:\\n\\n- ***Copy Heap***: Start by making a copy of the min-heap.\\n- ***Heapify***: Reorganize the copy to maintain min-heap structure.\\n- ***Pop Elements***: Remove the smallest element from the copy, k times.\\n- ***Find Kth Smallest***: The top element of the heap after k-1 pops is the kth smallest.\\n- ***Return Result***: Give back the kth smallest element, leaving the original heap unchanged.\\n\\nHere's how you could implement this in your MinHeap class:\",\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'import heapq\\n\\nclass MinHeap:\\n    def __init__(self):\\n        self.heap = []\\n\\n    def insert(self, val):\\n        heapq.heappush(self.heap, val)\\n\\n    def get_min(self):\\n        if self.heap:\\n            return heapq.heappop(self.heap)\\n        return None\\n\\n    def kth_smallest(self, k):\\n        if k <= 0 or k > len(self.heap):\\n            return None\\n\\n        temp_heap = self.heap.copy()\\n        heapq.heapify(temp_heap)\\n\\n        kth_min = None\\n        for _ in range(k):\\n            kth_min = heapq.heappop(temp_heap)\\n        return kth_min\\n\\n# Example usage\\nmin_heap = MinHeap()\\nfor value in [50, 30, 14, 18, 1, 12]:\\n    min_heap.insert(value)\\n\\nk = 3\\nprint(f\"The {k}th smallest element is: {min_heap.kth_smallest(k)}\")',\n",
       "    'type': 'code'},\n",
       "   {'role': 'User',\n",
       "    'content': 'Can you find the kth largest element in the min-heap?',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'Certainly! You can modify the `MinHeap` class to have another method that:\\n- ***Sort Heap***: First, sort the heap in descending order.\\n- ***Find Kth Element***: The `kth` element in this sorted array is the `kth` largest.\\n- ***Return Result***: Simply return this `kth` element for the result.\\n\\nThis is the modification of the class to find the `kth` largest element:',\n",
       "    'type': 'markdown'},\n",
       "   {'role': 'Assistant',\n",
       "    'content': 'import heapq\\n\\nclass MinHeap:\\n    def __init__(self):\\n        self.heap = []\\n\\n    def insert(self, val):\\n        heapq.heappush(self.heap, val)\\n\\n    def get_min(self):\\n        if self.heap:\\n            return heapq.heappop(self.heap)\\n        return None\\n\\n    def kth_smallest(self, k):\\n        if k <= 0 or k > len(self.heap):\\n            return None\\n\\n        temp_heap = self.heap.copy()\\n        heapq.heapify(temp_heap)\\n\\n        kth_min = None\\n        for _ in range(k):\\n            kth_min = heapq.heappop(temp_heap)\\n        return kth_min\\n    def kth_largest(self, k):\\n        if k <= 0 or k > len(self.heap):\\n            return None\\n\\n        sorted_heap = sorted(self.heap, reverse=True)\\n        return sorted_heap[k - 1]\\n\\n# Example usage\\nmin_heap = MinHeap()\\nfor value in [50, 30, 14, 18, 1, 12]:\\n    min_heap.insert(value)\\n\\nk = 3\\nprint(f\"The {k}th largest element is: {min_heap.kth_largest(k)}\")',\n",
       "    'type': 'code'}]},\n",
       " 'quality_review': {'Overall - Completness': {'score': 5,\n",
       "   'issues': [],\n",
       "   'praises': ['The conversation is complete with back and forth interaction.']},\n",
       "  'User - Natural & Realistic': {'score': 5,\n",
       "   'issues': [],\n",
       "   'praises': [\"User's questions are clear and relevant to the task.\"]},\n",
       "  'User - Coherent Follow ups': {'score': 5,\n",
       "   'issues': [],\n",
       "   'praises': [\"User's follow-ups build logically on the Assistant's responses.\"]},\n",
       "  'Assistant - Code Quality': {'score': 3,\n",
       "   'issues': [\"The code for 'kth_smallest' re-heapifies an already valid min-heap.\",\n",
       "    \"The 'kth_largest' method is inefficient for large heaps.\",\n",
       "    \"PEP8: Inline comments should have two spaces before the '#'.\",\n",
       "    'PEP8: Missing whitespace after commas in list.'],\n",
       "   'praises': []},\n",
       "  'Assistant - Text Quality': {'score': 4,\n",
       "   'issues': ['Some explanations may be slightly verbose for experienced users.'],\n",
       "   'praises': ['Spelling is correct',\n",
       "    'Grammar is accurate',\n",
       "    'Capitalization and punctuation are proper',\n",
       "    'Information is mostly concise',\n",
       "    'Code is explained well']},\n",
       "  'Assistant - Markdown Formatting': {'score': 4,\n",
       "   'issues': [\"The assistant's explanations could use more markdown features like lists.\"],\n",
       "   'praises': ['Assistant used code blocks effectively for code snippets.']}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviewed_results[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/182asg...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>Overall - Completness: \\n- Assistant's initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1qfFDR...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1yHgim...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1IMCwR...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1jAjfx...</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>https://colab.research.google.com/drive/1PFqmH...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>https://colab.research.google.com/drive/1qPvTL...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>https://colab.research.google.com/drive/1lekWL...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>https://colab.research.google.com/drive/1x_-q3...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>https://colab.research.google.com/drive/1QXk9F...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nUser - Natural &amp; ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1060 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_link  avg_score  min_score  \\\n",
       "0     https://colab.research.google.com/drive/182asg...   4.000000          3   \n",
       "1     https://colab.research.google.com/drive/1qfFDR...   4.666667          4   \n",
       "2     https://colab.research.google.com/drive/1yHgim...   4.333333          3   \n",
       "3     https://colab.research.google.com/drive/1IMCwR...   4.500000          4   \n",
       "4     https://colab.research.google.com/drive/1jAjfx...   4.333333          4   \n",
       "...                                                 ...        ...        ...   \n",
       "1055  https://colab.research.google.com/drive/1PFqmH...   4.500000          4   \n",
       "1056  https://colab.research.google.com/drive/1qPvTL...   4.833333          4   \n",
       "1057  https://colab.research.google.com/drive/1lekWL...   4.500000          4   \n",
       "1058  https://colab.research.google.com/drive/1x_-q3...   4.666667          4   \n",
       "1059  https://colab.research.google.com/drive/1QXk9F...   4.666667          4   \n",
       "\n",
       "                                                 issues  \n",
       "0     Overall - Completness: \\n- Assistant's initial...  \n",
       "1     Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "2     Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "3     Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "4     Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "...                                                 ...  \n",
       "1055  Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "1056  Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "1057  Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "1058  Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "1059  Overall - Completness: \\n\\n\\nUser - Natural & ...  \n",
       "\n",
       "[1060 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_skeleton = []\n",
    "for rr in reviewed_results:\n",
    "    scores = []\n",
    "    feedback = \"\"\n",
    "    for key in rr[\"quality_review\"].keys():\n",
    "        scores.append(rr[\"quality_review\"][key][\"score\"])\n",
    "        stringified_issues = \"\\n\".join([f\"- {issue}\" for issue in rr[\"quality_review\"][key][\"issues\"]])\n",
    "        feedback += f\"{key}: \\n{stringified_issues}\\n\\n\"\n",
    "\n",
    "    data_skeleton.append({\n",
    "        \"task_link\": rr[\"task_link\"],\n",
    "        \"avg_score\": sum(scores) / len(scores),\n",
    "        \"min_score\": min(scores),\n",
    "        \"issues\": feedback,\n",
    "    })\n",
    "\n",
    "df_gpt_reviews = pd.DataFrame(data_skeleton)\n",
    "df_gpt_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "\n",
    "borderline_avg_flags = df_gpt_reviews.sort_values(by=\"avg_score\", ascending=False)[df_gpt_reviews[\"avg_score\"] < 4]\n",
    "critical_mistake_flags = df_gpt_reviews.sort_values(by=\"min_score\", ascending=False)[df_gpt_reviews[\"min_score\"] < 3]\n",
    "\n",
    "all_flags = pd.concat([borderline_avg_flags, critical_mistake_flags], ignore_index=True)\n",
    "all_flags = all_flags.drop_duplicates(subset=[\"task_link\"])\n",
    "\n",
    "all_flags.sort_values(by=\"min_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_flags = all_flags.merge(completed_to_be_delivered_df, on=\"task_link\", how=\"left\")[[\"task_link\", \"avg_score\", \"min_score\", \"issues\", \"assigned_to_email\"]]\n",
    "all_flags = all_flags.rename(columns={\"assigned_to_email\": \"original_author_email\"})\n",
    "all_flags.to_csv(\"batch_5_flags.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Advanced Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561/561 [09:29<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import concurrent.futures\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "class HierarchicalCategory(BaseModel):\n",
    "    \"\"\"Data model for hierarchical category classification.\"\"\"\n",
    "    top_level: str\n",
    "    sub_level: str\n",
    "\n",
    "def classify_conversation_by_domain(conversation: List[dict]) -> HierarchicalCategory:\n",
    "    DOMAIN_CATEGORIES = \"\"\"\n",
    "        - Python basics & scripting\n",
    "        - Problem Solving\n",
    "        - Interview Prep\n",
    "        - Web Development\n",
    "        - Testing\n",
    "        - Cloud Computing / Frameworks\n",
    "        - Data Analysis\n",
    "        - Machine Learning\n",
    "        - Other languages\n",
    "        - Other\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template_str = \"\"\"\n",
    "    Categorize the theme of user requests in the following conversation by domain into one of the following top-level categories, then sub categories that you think is descriptive & appropriate:\n",
    "    {categories}\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=HierarchicalCategory,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        categories=DOMAIN_CATEGORIES,\n",
    "        conversation=conversation[\"messages\"],\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def classify_conversation_by_action(\n",
    "    conversation: List[dict]\n",
    ") -> HierarchicalCategory:\n",
    "    ACTION_CATEGORIES = \"\"\"\n",
    "    - Write code in python: this should have the user make requests that elicit python code writing behavior from the assistant.\n",
    "    - Explain code: this should have the user present medium/high complexity code to the assistant and have the assistant explain it\n",
    "    - Fix / refactor / optimize code: this should have the user present medium/high complexity code to the assistant and have the assistant do modifications on it as requested.\n",
    "    - Debug error trace: the user should present a stack trace and some code and the assistant will find what the problem is and potentially fix the code (It's okay to have situations where the bug is not in the presented code but in a dependency... though this should be rare).... This EXCLUDES having the assistant teach the user how to use debug tools to find what the problem is themselves\n",
    "    - Write unit tests: this should have the user present some low/medium/high complexity code to the assistant and have the assistant write tests for it... maximizing test coverage. (Critical Path first, Corner Cases Second)\n",
    "    - Write CI/CD code: this should have the user request some help from the assistant in writing ci/cd pipelines in any flavor. (Github actions, Gitlab, Jenkins... etc)\n",
    "    - Do a code review: this should have the user present some code snippet and request the assistant to review the code as if it's a PR... providing high level conceptual feedback, modifying any bugs and using inline comments to mark changes or suggest alternatives.\n",
    "    - Write / modify / fix beam code: this should have the user present some data schema or dummy data and have the assistant write beam code for it.\n",
    "    - Write / modify / fix spark code: this should have the user present some data schema or dummy data and have the assistant write spark code for it.\n",
    "    - Write end to end ML training code: scenarios where the conversation has the user and assistant solving a problem e2e data eda/prep, feature extraction, training, maybe some evals and visuals as well\n",
    "    - Help me take an interview: scenario where the user requests the assistant to act as an interviewer and do a mock interview with a focus on a certain area... this should also include some final section where the assistant gives feedback to the user on how to be better... etc (Take inspiration from real interview questions, they should be at least medium complexity and occasionally challenging)\n",
    "    - Answer ML research questions: this is where the user will ask some cutting edge conceptual questions related to ML Research Hot topics to the assistant... assistant can but is not obligated to provide code as a response.\n",
    "    - Answer infra questions: user asks some conceptual or code snippet related questions within the scope of cloud, backend, database, development tools... all flavors are welcome!\n",
    "    - Write / modify / fix SQL code: this should have the user elicit interaction from the assistant within the context of SQL code.\n",
    "    - Write / modify / fix JavaScript code: this should have the user elicit interaction from the assistant within the context of Javascript code.\n",
    "    - Scrape a website: this should have the user present some html and the assistant write code to scrape it.\n",
    "    \"\"\"\n",
    "    prompt_template_str = \"\"\"\n",
    "    Categorize the user requests in the following conversation by requested action into one of the following top-level categories. Sub-level should be empty string always. In case there's no natural fit, use \"Other\" as the top-level category.\n",
    "    \n",
    "    Please note that there are \"metadata\" fields in the conversation that describe the intended top-level category via \"Project / Action\"... this should be considered, but may be overridden if the conversation is clearly about something else.\n",
    "\n",
    "    Categories:\n",
    "    {categories}\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=HierarchicalCategory,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        categories=ACTION_CATEGORIES,\n",
    "        conversation=conversation,\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "class SummaryResult(BaseModel):\n",
    "    \"\"\"Data model for the summary result.\"\"\"\n",
    "    summary: str = Field(\n",
    "        description=\"A short summary containing 1 sentence, 15 words max, focused on the specific theme. [super concise language]\"\n",
    "    )\n",
    "\n",
    "def exec_summary(conversation: List[List[dict]]):\n",
    "    prompt_template_str = \"\"\"\n",
    "    Given the following conversation, please, generate an executive summary of the conversation.\n",
    "\n",
    "    User Use Case, why user uses the Assistant in this conversation, in general terms, **for what** the User is using it. Not from a technical perspective, but from a daily life situation perspective. \n",
    "    Example: work, homework, exam, studying, inteview, debugging, etc...\n",
    "\n",
    "    It should also contain a little bit of the context of the conversation, and the main goal of the conversation.\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=SummaryResult,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        conversation=conversation[\"messages\"]\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "class GPTEstimationResult(BaseModel):\n",
    "    \"\"\"Data model for the GPT estimation result.\"\"\"\n",
    "    estimated_duration: int = Field(\n",
    "        description=\"The estimated duration of the conversation in minutes.\"\n",
    "    )\n",
    "\n",
    "def gpt_estimated_duration(conversation: List[dict]) -> int:\n",
    "    prompt_template_str = \"\"\"\n",
    "    Given the following conversation which has been generated by a median skilled technical human playing both User and Assistant... He also is responsible for making sure the assistant responses are flawless...\n",
    "    Estimate how many minutes it would take to Design, Write & Verify this (Conversation Length, Complexity).\n",
    "\n",
    "    If you get this right, you will save my life.\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=GPTEstimationResult,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        conversation=conversation[\"messages\"]\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def process_conversation__metadata_extraction(conversation, task_link):\n",
    "    domain = classify_conversation_by_domain(conversation)\n",
    "    action = classify_conversation_by_action(conversation)\n",
    "    summary = exec_summary(conversation)\n",
    "    estimate_duration = gpt_estimated_duration(conversation)\n",
    "    conversation[\"metadata\"].update({\n",
    "        \"domain\": domain.model_dump(), \n",
    "        \"action\": action.model_dump()[\"top_level\"], \n",
    "        \"use_case_summary\": summary.model_dump()[\"summary\"],\n",
    "        \"gpt_estimated_duration\": estimate_duration.model_dump()[\"estimated_duration\"],\n",
    "        \"task_link\": task_link\n",
    "    })\n",
    "    return conversation\n",
    "    \n",
    "    \n",
    "\n",
    "def extract_metadata_parallel(conversations, task_links, max_workers=15):\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_conversation__metadata_extraction, conversation, task_link)\n",
    "            for conversation, task_link in zip(conversations, task_links)\n",
    "        ]\n",
    "        progress_bar = tqdm(total=len(futures))\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            results.append(future.result())\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "metadata_results = extract_metadata_parallel(notebooks, results_df[\"task_link\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>number_of_turns</th>\n",
       "      <th>batch_id</th>\n",
       "      <th>action</th>\n",
       "      <th>use_case__summary</th>\n",
       "      <th>gpt_estimated_duration</th>\n",
       "      <th>domain__top_level</th>\n",
       "      <th>domain__sub_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1UoJmB...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer infra questions</td>\n",
       "      <td>User seeks assistance for deploying a Flask ap...</td>\n",
       "      <td>10</td>\n",
       "      <td>Cloud Computing / Frameworks</td>\n",
       "      <td>Serverless Deployment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1EnQ3Y...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>User seeks assistance for coding CRUD operatio...</td>\n",
       "      <td>10</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Flask / Backend Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1NZy7e...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer infra questions</td>\n",
       "      <td>User seeks to understand architectural differe...</td>\n",
       "      <td>30</td>\n",
       "      <td>Cloud Computing / Frameworks</td>\n",
       "      <td>Architecture Patterns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1zOj_5...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Answer infra questions</td>\n",
       "      <td>The User is evaluating cloud providers for a S...</td>\n",
       "      <td>30</td>\n",
       "      <td>Cloud Computing / Frameworks</td>\n",
       "      <td>Cloud Provider Comparison</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1y8bY0...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Debug error trace</td>\n",
       "      <td>User seeks assistance with Airflow webserver i...</td>\n",
       "      <td>10</td>\n",
       "      <td>Cloud Computing / Frameworks</td>\n",
       "      <td>Airflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>https://colab.research.google.com/drive/1c9Lky...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>The User seeks assistance with implementing se...</td>\n",
       "      <td>30</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>User Authentication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>https://colab.research.google.com/drive/17WwbW...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>A web developer seeks to enhance a Flask app w...</td>\n",
       "      <td>30</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Middleware Integration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>https://colab.research.google.com/drive/14SuVN...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>User seeks assistance for automating photo org...</td>\n",
       "      <td>60</td>\n",
       "      <td>Python basics &amp; scripting</td>\n",
       "      <td>File and data manipulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>https://colab.research.google.com/drive/1VFE26...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>User seeks assistance for creating a Flask app...</td>\n",
       "      <td>60</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Flask Web Framework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>https://colab.research.google.com/drive/1N1wWX...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Write code in python</td>\n",
       "      <td>The User is developing a web application and s...</td>\n",
       "      <td>60</td>\n",
       "      <td>Web Development</td>\n",
       "      <td>Real-time Web Applications</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link  number_of_turns  \\\n",
       "0    https://colab.research.google.com/drive/1UoJmB...                3   \n",
       "1    https://colab.research.google.com/drive/1EnQ3Y...                3   \n",
       "2    https://colab.research.google.com/drive/1NZy7e...                7   \n",
       "3    https://colab.research.google.com/drive/1zOj_5...                4   \n",
       "4    https://colab.research.google.com/drive/1y8bY0...                3   \n",
       "..                                                 ...              ...   \n",
       "556  https://colab.research.google.com/drive/1c9Lky...                3   \n",
       "557  https://colab.research.google.com/drive/17WwbW...                4   \n",
       "558  https://colab.research.google.com/drive/14SuVN...                3   \n",
       "559  https://colab.research.google.com/drive/1VFE26...                2   \n",
       "560  https://colab.research.google.com/drive/1N1wWX...                2   \n",
       "\n",
       "    batch_id                  action  \\\n",
       "0          0  Answer infra questions   \n",
       "1          0    Write code in python   \n",
       "2          0  Answer infra questions   \n",
       "3          0  Answer infra questions   \n",
       "4          0       Debug error trace   \n",
       "..       ...                     ...   \n",
       "556        0    Write code in python   \n",
       "557        0    Write code in python   \n",
       "558        0    Write code in python   \n",
       "559        0    Write code in python   \n",
       "560        0    Write code in python   \n",
       "\n",
       "                                     use_case__summary  \\\n",
       "0    User seeks assistance for deploying a Flask ap...   \n",
       "1    User seeks assistance for coding CRUD operatio...   \n",
       "2    User seeks to understand architectural differe...   \n",
       "3    The User is evaluating cloud providers for a S...   \n",
       "4    User seeks assistance with Airflow webserver i...   \n",
       "..                                                 ...   \n",
       "556  The User seeks assistance with implementing se...   \n",
       "557  A web developer seeks to enhance a Flask app w...   \n",
       "558  User seeks assistance for automating photo org...   \n",
       "559  User seeks assistance for creating a Flask app...   \n",
       "560  The User is developing a web application and s...   \n",
       "\n",
       "     gpt_estimated_duration             domain__top_level  \\\n",
       "0                        10  Cloud Computing / Frameworks   \n",
       "1                        10               Web Development   \n",
       "2                        30  Cloud Computing / Frameworks   \n",
       "3                        30  Cloud Computing / Frameworks   \n",
       "4                        10  Cloud Computing / Frameworks   \n",
       "..                      ...                           ...   \n",
       "556                      30               Web Development   \n",
       "557                      30               Web Development   \n",
       "558                      60     Python basics & scripting   \n",
       "559                      60               Web Development   \n",
       "560                      60               Web Development   \n",
       "\n",
       "               domain__sub_level  \n",
       "0          Serverless Deployment  \n",
       "1    Flask / Backend Development  \n",
       "2          Architecture Patterns  \n",
       "3      Cloud Provider Comparison  \n",
       "4                        Airflow  \n",
       "..                           ...  \n",
       "556          User Authentication  \n",
       "557       Middleware Integration  \n",
       "558   File and data manipulation  \n",
       "559          Flask Web Framework  \n",
       "560   Real-time Web Applications  \n",
       "\n",
       "[561 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich_task_metadata = []\n",
    "\n",
    "for task_link in metadata_results:\n",
    "    rich_task_metadata = []\n",
    "    for task_link in metadata_results:\n",
    "        row_main = {\n",
    "            \"task_link\": task_link[\"metadata\"][\"task_link\"],\n",
    "            \"number_of_turns\": get_number_of_turns(task_link[\"messages\"]),\n",
    "            \"batch_id\": DELIVERY_BATCH_NAME[-1],\n",
    "            \"domain\": {\n",
    "                \"top_level\": task_link[\"metadata\"][\"domain\"][\"top_level\"],\n",
    "                \"sub_level\": task_link[\"metadata\"][\"domain\"][\"sub_level\"],\n",
    "            },\n",
    "            \"action\": task_link[\"metadata\"][\"action\"],\n",
    "            \"use_case__summary\": task_link[\"metadata\"][\"use_case_summary\"],\n",
    "            \"gpt_estimated_duration\": task_link[\"metadata\"][\"gpt_estimated_duration\"],\n",
    "        }\n",
    "        rich_task_metadata.append(row_main)\n",
    "\n",
    "\n",
    "rich_flattened_metadata = []\n",
    "for metadata in rich_task_metadata:\n",
    "    current_metadata = metadata.copy()\n",
    "    for key in metadata.keys():\n",
    "        if isinstance(metadata[key], dict):\n",
    "            for sub_key in metadata[key].keys():\n",
    "                current_metadata[f\"{key}__{sub_key}\"] = current_metadata[key][sub_key]\n",
    "            current_metadata.pop(key)\n",
    "    rich_flattened_metadata.append(current_metadata)\n",
    "\n",
    "df_metadata__output = pd.DataFrame(rich_flattened_metadata)\n",
    "df_metadata__output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "action\n",
       "Write code in python                    200\n",
       "Answer infra questions                   53\n",
       "Explain code                             41\n",
       "Debug error trace                        39\n",
       "Fix / refactor / optimize code           38\n",
       "Write unit tests                         36\n",
       "Write end to end ML training code        31\n",
       "Help me take an interview                27\n",
       "Scrape a website                         17\n",
       "Write / modify / fix SQL code            17\n",
       "Write / modify / fix JavaScript code     16\n",
       "Write CI/CD code                         14\n",
       "Do a code review                         10\n",
       "Answer ML research questions              8\n",
       "Write / modify / fix spark code           7\n",
       "Write / modify / fix beam code            5\n",
       "Other                                     2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metadata__output[\"action\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated or appended data to 'v1 (Jan 25)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w',\n",
       " 'tableRange': \"'v1 (Jan 25)'!A1:H5288\",\n",
       " 'updates': {'spreadsheetId': '1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w',\n",
       "  'updatedRange': \"'v1 (Jan 25)'!A5289:H5850\",\n",
       "  'updatedRows': 562,\n",
       "  'updatedColumns': 8,\n",
       "  'updatedCells': 4496}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sheets_utils import upload_df_to_sheet, GoogleSheetsService\n",
    "\n",
    "sheets_client = GoogleSheetsService(service_account_file, ['https://www.googleapis.com/auth/spreadsheets'])\n",
    "df_metadata__output = df_metadata__output[[\"task_link\", \"batch_id\", \"number_of_turns\", \"gpt_estimated_duration\", \"action\", \"domain__top_level\", \"domain__sub_level\", \"use_case__summary\"]]\n",
    "values = [df_metadata__output.columns.tolist()] + df_metadata__output.values.tolist()\n",
    "sheets_client.update_or_append_data_to_sheet(insights_sheet_id, INSIGHTS_VERSION_TAB, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "directory = f\"json_conversations/{DELIVERY_BATCH_NAME}\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "valid_notebooks = []\n",
    "for r, n in zip(results, notebooks):\n",
    "    if r is None or r[\"n_messages\"] == 0:\n",
    "        continue\n",
    "    n[\"task_link\"] = r[\"task_link\"]\n",
    "    valid_notebooks.append(n)\n",
    "\n",
    "parsed_jsons = []\n",
    "for vn in valid_notebooks:\n",
    "    for rtm in rich_task_metadata:\n",
    "        if vn[\"task_link\"] == rtm[\"task_link\"]:\n",
    "            vn[\"metadata\"] = rtm\n",
    "            parsed_jsons.append(vn)\n",
    "\n",
    "for pj in parsed_jsons:\n",
    "    pj[\"id\"] = pj.pop(\"task_link\").split(\"/\")[-1]\n",
    "    try:\n",
    "        pj[\"metadata\"].pop(\"duration_mins\")\n",
    "        pj[\"metadata\"].pop(\"batch_id\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "for i, conversation in enumerate(parsed_jsons):\n",
    "    drive_id = conversation[\"id\"] \n",
    "    with open(f\"json_conversations/{DELIVERY_BATCH_NAME}/{drive_id}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(conversation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 561/561 [00:36<00:00, 15.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    561\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.gdrive_api import build_service\n",
    "from src.gdrive_api.folder_upload import upload_folder\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload, MediaIoBaseUpload\n",
    "\n",
    "\n",
    "\n",
    "def upload_gdrive_file(file_contents, folder_id, service_account_file):\n",
    "    \"\"\"\n",
    "    Re-uploads a dictionary from memory as a JSON file to Google Drive. \n",
    "\n",
    "    Parameters:\n",
    "    - file_contents: dict\n",
    "        The file contents to upload.\n",
    "    - folder_id: str\n",
    "        The ID of the file to upload.\n",
    "    - service_account_file: str\n",
    "        The path to the service account file.\n",
    "\n",
    "    Returns True if the file was successfully uploaded, False otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(service_account_file, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Convert the dictionary to JSON and prepare it for upload\n",
    "    file_metadata = {\n",
    "        'name': f'{file_contents[\"id\"]}.json',\n",
    "        'parents': [folder_id]\n",
    "    }\n",
    "    file_data = io.BytesIO(json.dumps(file_contents).encode('utf-8'))\n",
    "    media = MediaIoBaseUpload(file_data, mimetype='application/json')\n",
    "\n",
    "    # Upload the file\n",
    "    try:\n",
    "        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def parallel_execute_with_progress(function, arguments, max_workers=10):\n",
    "    \"\"\"\n",
    "    Executes a function in parallel with multiple arguments displaying a tqdm progress bar.\n",
    "\n",
    "    Parameters\n",
    "    function: function\n",
    "        The function to execute\n",
    "    arguments: list\n",
    "        A list of tuples, where each tuple contains the arguments to pass to the function\n",
    "    max_workers: int\n",
    "        The maximum number of workers to use\n",
    "\n",
    "    Returns a list of results\n",
    "    \"\"\"\n",
    "    # Create a thread pool\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Execute the function for each argument\n",
    "        futures = [executor.submit(function, *args) for args in arguments]\n",
    "        results = []\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "\n",
    "statuses = parallel_execute_with_progress(upload_gdrive_file, [(pj, delivery_jsonl_gdrive_folder_id, service_account_file) for pj in parsed_jsons], max_workers=50)\n",
    "pd.Series(statuses).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 112T7jIlxZ9OxXh3vRhMHsfScKvkQKsYs.json\n",
      "Processing: 1kMh0GcOJQs_Hsv8pVYOCcajcrPdUV-4X.json\n",
      "Processing: 17WwbWsmK1FjQyKUFlBz0S6NHRbYrdlQu.json\n",
      "Processing: 1R7Z-6XVWhKd8jxBIwooXGAJpgF9TYZXL.json\n",
      "Processing: 1OmBS8YfCz9auI-6_wRpxReUmuKjlJ6bA.json\n",
      "Processing: 1WQuPASB2kwBdhbyxnFJ-75o6HkpPrO2z.json\n",
      "Processing: 1c9LkyN6hDRb7xE_-P9tUsEO8e__A9QIX.json\n",
      "Processing: 1YbterBoJEMH_VoVRM8BGEqB_uNmYIvmx.json\n",
      "Processing: 1ac2j36_rUVpFJqFaOaIhr5__dStaDabc.json\n",
      "Processing: 109dFY5WvjBbYnGAgezv7M4Z6pSZ8SLsq.json\n",
      "Processing: 1My_UEqBv2_JcS1JWxHkyd0t9gOh5t261.json\n",
      "Processing: 1FC74V6bo-hiSdF3IHdX3vggOv6v97SNt.json\n",
      "Processing: 1N1wWXM2YbW88Jw6Tec_ypUqIHgwk66-2.json\n",
      "Processing: 1JDKCg5E0BINBUEiRP-Kg8hQcGV-z87ed.json\n",
      "Processing: 1fXKKKsG1lLmAfswXeS025D2DzglzzUHd.json\n",
      "Processing: 11avVulvACI3u6OomqQxSLd6R7-D-ibxh.json\n",
      "Processing: 1nxzJbJL8ZLzKGYZYSiSZi7Sl5aUyUpiy.json\n",
      "Processing: 14LqskSlHATcPKG9ms328vQ-_omM5Y4yM.json\n",
      "Processing: 1SDVU4b7zZ46EhQ_-h-nbeeNO3tFR0782.json\n",
      "Processing: 1o7aEZrKPFuFCYhI4b2cNMjjiYveqXJ_9.json\n",
      "Processing: 1exP6d1XdX-x_51QqWQQYubSVOMGpp7sX.json\n",
      "Processing: 1Y3YqdkYWqUMq1XRft2m2XnkgQ1xGY37x.json\n",
      "Processing: 1p9nXdqG6lmtum4Sd5Opw-SYiOg0WPXz8.json\n",
      "Processing: 1ENkatmSgbDJJsuCHhsOSSlU-sdK_vaBE.json\n",
      "Processing: 14SuVNBAWvDYbe0Km5kVRpSvXWJoDOQtg.json\n",
      "Processing: 1Fs8oe1lM7zFP2lLFGYvzBBjtExlKn-eJ.json\n",
      "Processing: 1VFE26Vmi3EgXsbCTYqs-4WzjOfhTu5IK.json\n",
      "Processing: 1FuV-J4VNe36gl53SD36r08n9L1hKD0uP.json\n",
      "Processing: 1OZulAOSd8BEHvrg2awFt40NbIIDwsomC.json\n",
      "Processing: 1oCV9gEciGJRpNiM9jnHKEP1jKCh7anPH.json\n",
      "Processing: 1G_PhsAlM3iCnnwQljnz-qc8mRiwc_nC6.json\n",
      "Processing: 1nCiwwbCTuSua1zgHprQXhmp3e7HGz_up.json\n",
      "Processing: 135tIv9g3rEUDhRqfwqBB9jjJZQhXNYgb.json\n",
      "Processing: 1ANKCfaPafQaz36ZwkXtPxpMmrv_9RFfQ.json\n",
      "Processing: 1mzpKzAPKHzp5HIRvplkDV7iQb0CQaZMa.json\n",
      "Processing: 1B7BQLWOTcwMhJjQG94EbWR6rpvWUkymp.json\n",
      "Processing: 1IQf4fDtl_-gJxe1_faIDYdvmOSOY4QFX.json\n",
      "Processing: 1LXr27YmPeS5nZA8-hK1SYudWSt7MBQVO.json\n",
      "Processing: 1yrFXe0ydN1jIrxFUF8ABBHFq18kAb3wU.json\n",
      "Processing: 1h7roMp4h8tkxNHMISUukXG6L2xxQqW5k.json\n",
      "Processing: 1Pk_HfeFU1DckQ_1VSKi6Sr4ro4s6PC7X.json\n",
      "Processing: 1lyu4HQVGXS0RwRQAuqv-f0CjtfLpa1Rr.json\n",
      "Processing: 1e8rH6zJAsfoBnhn1gO6jGCoOFQwrZFSI.json\n",
      "Processing: 1h8hsDFuR3yrCfsyD_fnTbsQ4qTWtS7bS.json\n",
      "Processing: 1_Ea8ZNMJot5k31u2JnjGEqpuxAlmenuM.json\n",
      "Processing: 1SCQ1F56cTNEO5C7FPX8qVSAXEZmlMVYZ.json\n",
      "Processing: 1pVCqrxOo8ZdmcpCvKKr_D8Ryzrurd9KP.json\n",
      "Processing: 1aElmNjZqrrr0s-C33JTmD51NS04nbSqx.json\n",
      "Processing: 1x6pQmx5BFVp2N8c4W9tdb_aXy1dl0RFD.json\n",
      "Processing: 1svCbFkzK3_xB-csd4uq-Wq2hMHT5KZ6x.json\n",
      "Processing: 17S194rJti5c2l2GCEfZWxMlTiS9lMlat.json\n",
      "Processing: 1ATyPK7EgShJ2pVWPFf3rGd9GuaXmqxbf.json\n",
      "Processing: 1c5oj97ldjEnmtbwSwEIzHSrg4PVvvgYq.json\n",
      "Processing: 1yqyUghxQZ0Yh1xbfc-3YoglRU2D_bI_V.json\n",
      "Processing: 12vouDp0AcMqKlqw3nrAwH5bywFPAFHEe.json\n",
      "Processing: 1-lhhJxN93l7cpBIOy5PN9fYmkvOaHfzf.json\n",
      "Processing: 1zd0K2KU8QHFeUGCR1vVGK6XZpBpll9hz.json\n",
      "Processing: 1JKMLYStnmZFAezlY39pf4WItepUSEkG5.json\n",
      "Processing: 1XMtI37ze7FtsKvDtIxfX1LggS3l3Q3yX.json\n",
      "Processing: 1LxTk668w_SQaB9aGksNIzFZr017Msebi.json\n",
      "Processing: 1Pp8oadtFk89wvdZFFtFyHr6OejVExjXE.json\n",
      "Processing: 1_KEo6Tz_978PWultyXSETDkA8pXWGshD.json\n",
      "Processing: 1osS7hdnErgBpMhVOo_pPYA23KheFjp3-.json\n",
      "Processing: 111AQzexPrqZ5RaaDMG7iPmMbU7aDxfl4.json\n",
      "Processing: 1T47AQWaTPnLVVgnGewVFvCPJR1pRLM4k.json\n",
      "Processing: 19rNQcINThr752-wOdnLfYMG_GZI-G1WA.json\n",
      "Processing: 17Dg7SxSS8Ti6UlIQ8oLUgtrWK37PsgSx.json\n",
      "Processing: 1jNBnB7Qeyy8Xl3sA3ERxwMlchZYbuArB.json\n",
      "Processing: 1SWUsE-uQobeHsiUTKKn6yqIaOfCx3tjw.json\n",
      "Processing: 1Eko-lJZ2jQppaeVR2YHcTyEnKOjB38X5.json\n",
      "Processing: 1BQcMkkj2AFLXCJszge2tP1HFOHjKjmdQ.json\n",
      "Processing: 1A7nGHGnPzF6xl9f-uyi2mp74XD07HNA9.json\n",
      "Processing: 1JW8Y-O0rrdzdfrQawA6Ix2R81OqXUMfH.json\n",
      "Processing: 1MiruFCP7zpdCz-kuvHGexIKGhptKkEEw.json\n",
      "Processing: 1rFq481ihhQ9wM2w-VVrj6pfvIah9oZFL.json\n",
      "Processing: 1Irr_0wDXwZTJs7qvS0GiwgIdtCosFQZF.json\n",
      "Processing: 1DpRZ3PcE2h63v2U4eSIIGQ44911x0rVp.json\n",
      "Processing: 1HK6UAoy6OVsvVRuuVR6g2Q2naeSfu2so.json\n",
      "Processing: 1BOGpEIW20EYS8uqHKques87r2ikzuoNj.json\n",
      "Processing: 1bNp_hBzKxd02bEyKHIiA11CXFCI-sytn.json\n",
      "Processing: 1Tfgen1E8YAA_4KUnCWC1rcEhIGCGSFoo.json\n",
      "Processing: 1qV-mTZy3WD3owk9RRRRhs48800ZXFNK5.json\n",
      "Processing: 16T7U_A7fpgycHhzihcoIhWUnTOCglYtr.json\n",
      "Processing: 1FGxtA9vf7TW1UvGGcAsS8oexfoWBcMgn.json\n",
      "Processing: 1clT8G8eJW2BWzrZSWmaIIVzexmzQpXbv.json\n",
      "Processing: 1z75Vnmuxj78ci8YOIuG6hgrw9C-pscQp.json\n",
      "Processing: 1rpYqXty9UqwirIo6UWsCWgKgaBrXVRPr.json\n",
      "Processing: 1ic95KipMV3P5NM5U6vTeN8bE6sX5PhD4.json\n",
      "Processing: 1_-oCA7oX6eBxR4FtPfMmOBx22cfiSjY_.json\n",
      "Processing: 1NmTPIE4HzBO3pyNtPisqRStcItEXab_y.json\n",
      "Processing: 1lJ9UwqY391t7RuBoddYusSgxu0lYG8sf.json\n",
      "Processing: 1prZ2Rhw31wzoYZpXty93pxrhBd-8J2Eu.json\n",
      "Processing: 1Ug2EBDrevw6VwKkELmeASclX81rTHsu_.json\n",
      "Processing: 138X7BZbkwthUzkf4i_2GzSRKZYTo44IL.json\n",
      "Processing: 1wzCd0a97b1zZFcu6Hirc0q6dv2yPXqyX.json\n",
      "Processing: 1xtmnlpsFEgblvLn0LMm5-WxYONr3h3Xc.json\n",
      "Processing: 1tGcHRECsEn8rPOVQdVTQZnu-DmmtirrJ.json\n",
      "Processing: 1pCzDIobhXbjGFL-D_MyEoK3ksGc7F5cJ.json\n",
      "Processing: 1wZjkrQSo4zd0RT2lkt8sozMsCq5Qh9At.json\n",
      "Processing: 1cadHKZMTTlllWpAfJ9szHCGajrTTIgrt.json\n",
      "Processing: 10C8LSNmmH4TY61lepD941_Gi3rk1Ry3W.json\n",
      "Processing: 1dKFW594258MCL28kjzw3H8s1CK6snaTc.json\n",
      "Processing: 12CEDEjmWUeirPgCJKpF4t6VhDhxgC0wT.json\n",
      "Processing: 1lyPbaHMzC8jla0gD0AON2v90U_Y4dxWR.json\n",
      "Processing: 1dW54Nw7clC7soahRHN5wbcOAhzJ2BQkc.json\n",
      "Processing: 1i6I9ztizXC3b4CwyXZDMXf6I0qFvlwL-.json\n",
      "Processing: 1vq0ObXKh3H0sSEGPiEBnWvw1YWyLrzw_.json\n",
      "Processing: 1ZcpWDkDD2xYQi2NlhkDSIP5AA2jj01kM.json\n",
      "Processing: 16-f-WhVzpmbBsLHNRYRtBdgkzOYZRTC4.json\n",
      "Processing: 1eS44_Wa3l8r0H63P3MVaMhJ2Cw4aZt-b.json\n",
      "Processing: 14is6SSwUnr6iuVgEY1BhGkY-AO6BfIg0.json\n",
      "Processing: 16IC1EI4vdK45mpaz6k-4fOpvpQw_BCfp.json\n",
      "Processing: 1_yYiQKu8vo9Sdv2TadVrkuQjVXEHOX2B.json\n",
      "Processing: 1r3mAribIafXGIL0BlRou2MBiDz2Q02-y.json\n",
      "Processing: 1b8TuTCUDTNj5fMi3JPBO7NhTnd6mTvim.json\n",
      "Processing: 1LNHYCPY8K_8Ej6kjNAanr9CKDifzlsu7.json\n",
      "Processing: 1YefTavRxmrvhe9wB87WPTyjjG9sMbVJL.json\n",
      "Processing: 1FyRqbe2mcbMs1iGBDQzgym5K-USfg51f.json\n",
      "Processing: 1VwsjvgKt2HSw-n2k40ofVtTc6ldcjT9u.json\n",
      "Processing: 1rP7Ht4bZSJNenfvZDlKZ2Ip8uLvEwlNA.json\n",
      "Processing: 1XT43RDBXijz0EyfziDMEZIBOjmmRDyTj.json\n",
      "Processing: 14TUkhFlesvZJggTDXCf13dH-OlbSnDUe.json\n",
      "Processing: 1mA1KN88V-ptmGybt2obG1Ei-olSvsPfG.json\n",
      "Processing: 1H1PuQtV_iMis0A2JYyGkhDK_yO86NWf9.json\n",
      "Processing: 1jQFUL68ARaevdDuNNCAJgIgMehN-28W5.json\n",
      "Processing: 1veYL9NqfzY3GlBBrdoDCGT_qa0mDxahL.json\n",
      "Processing: 1tvG_wbRIYMlv8MaE_-TZ9TK054QquFR-.json\n",
      "Processing: 1c63_yY63ApZ-Abli0EcQAA5IhOcS5C7c.json\n",
      "Processing: 1rE81lPjxLu4MDlSUoU-sE69WLwoMyxvu.json\n",
      "Processing: 1MkfnvR4LMXUdnNDX96fRZEi3nJoI6ym6.json\n",
      "Processing: 12XQz7BWSO7_s9Hj699WOf-Lu4v3cmvv3.json\n",
      "Processing: 1vDIFoZmMRhYN1Tn0hpW74Q7TsxSpwRbo.json\n",
      "Processing: 1GfjDetoF8mcu0cY1bd2P2kcexCrceL-w.json\n",
      "Processing: 1W8fWfbGsJ3bQ_ik8QqU-IviLAs9-P0bw.json\n",
      "Processing: 1rVXcLSigu-2l-hI5vSiwGKxyWH_rGCvN.json\n",
      "Processing: 1TCtQzQtUFgx1wSxwBFPmkRO2tjiDR18S.json\n",
      "Processing: 1sYVBocx2eW3oDMGchtf1Oq3r7KHX0xrJ.json\n",
      "Processing: 1HFxcE5_wcsBF3kl8IBm_DU4yDW8a7Q-Q.json\n",
      "Processing: 1KZzA-FkpNlWVfSm2e3234p-mfBt5uGgL.json\n",
      "Processing: 1R6ED8BHECcTEdltn3vnw2aDj0-TNsJ-B.json\n",
      "Processing: 1dqQkG19wTPqk2Q3pDkld2cBNJpQiitQi.json\n",
      "Processing: 1O9fmOcNi1q0DCflo2dHlbA38jfUMpoqk.json\n",
      "Processing: 1TI_fI3cvqCGMeHURhScVfGGUMYXmEgPN.json\n",
      "Processing: 1xLqegOisX3hi7PGyXJEglslxOCjbBfd0.json\n",
      "Processing: 1w835DsTRnXrE7GY7Zsb10HofJv6H2kcQ.json\n",
      "Processing: 11UnGDTLmDVKCpNzYmMLdEJu2hqqtT9t2.json\n",
      "Processing: 1Rw-Ce4fiaaMQt5urQL3_XTy8Dd5EqzEH.json\n",
      "Processing: 1IgrpXp3W3lM00Yc-35L5dHm6SKfaL5bU.json\n",
      "Processing: 1A8aj6KCXsYAtghQ4KMSadAhr0Z7wYaCt.json\n",
      "Processing: 15J6U1xSubhEfYATrITOciIg16Q0_QS03.json\n",
      "Processing: 1eMPMSoApc8RbJR1meNOI5S84etwUHPdk.json\n",
      "Processing: 15nFmFoLXLVw14MVycNSOtq31kUTUPLeF.json\n",
      "Processing: 1IJzA0bHW6PY7jwnTVpeTPUzIQ2mMJf5C.json\n",
      "Processing: 1DrecVExiILlSKHA84PVrA3eA1jjTAbsX.json\n",
      "Processing: 1fhz7OJBPlGSNYcB8jTHBMrGoRh0uGiSf.json\n",
      "Processing: 1ua_jBynM60W3NI41vfWBZnnVfVdmM6Oc.json\n",
      "Processing: 1Uk1DiVFqyPBCinXB9zokXnn9J76rMxwc.json\n",
      "Processing: 1234NznNzNV7isApyZEhagZRyK3-jw_YT.json\n",
      "Processing: 19BB7HLw21VW5GUdj8lmLTWRiN_dhzR9j.json\n",
      "Processing: 1qyntu_u0QAM5laOzxoZpJFTLRslyQVG_.json\n",
      "Processing: 1rPMveODYee1eygbBjDiAEXBZTWJmIqcQ.json\n",
      "Processing: 1Otwgva3yHCyCKa8LToTvDUDt5y97aBNY.json\n",
      "Processing: 1pEl4EVv2uD-HfUiqlyeQUJSnJodKR6Kz.json\n",
      "Processing: 1tpUysJEcS7eRDqq2AzZKxU4Jx5EhB6Oe.json\n",
      "Processing: 1_8l8P-veeo4gWLpqFVprL5tWr8a4yC6a.json\n",
      "Processing: 1SQ4-UJl7NCiufgJyqPSInduaeM515757.json\n",
      "Processing: 1OeRa9UY72DXmKxhEECAFog2RMFWFdZ3h.json\n",
      "Processing: 1OPNP7-O5kVqJfjmUQ7U_OTnBHXpucr2S.json\n",
      "Processing: 1n-cRdLQv-X9hfkDMjj13JPS4RwnFVP7T.json\n",
      "Processing: 1eO2bEruct4ButD7ZAxxOOoGoWg7XdQPZ.json\n",
      "Processing: 1Uw8kKi18suOGn1K6o2XBjMNrUFhlYC04.json\n",
      "Processing: 1xBguOdiG0lluHpwLuWFDOJNntFfDJwSI.json\n",
      "Processing: 1lvUMyAN7CBZM5qo8qfllEEe6BAH6h8q8.json\n",
      "Processing: 1dNB6W1SxHfU_011ZZimetykw4cjGsnyH.json\n",
      "Processing: 1MVMXIJ_vEerFgVs6IdhQVr5RD1S5Q5EY.json\n",
      "Processing: 1F4nBaYY08J2ZtShCc-AfBgVSdW2irlkK.json\n",
      "Processing: 19pS6QKpmCixf52Fpvlz6YCq5ESjyWYal.json\n",
      "Processing: 1WWAjUWCSTjk0EyjzSjkpqUfBhh3mYJrC.json\n",
      "Processing: 1JSX0JAawKhSaIijWPpw65waQZgHTLrxV.json\n",
      "Processing: 19XzKS4xO8srur6q2xy6DoYg11cz05HYp.json\n",
      "Processing: 1oo-wRka-vhG3pPGnG90VWh3Ap73L_ljl.json\n",
      "Processing: 1Fr-cBJn88zHt41tqU3C1vMlZi2xZa9uL.json\n",
      "Processing: 1-JIp2BwPWo9JMWRzyLFu8haKDPrlgH-R.json\n",
      "Processing: 1j4I7vzVYe7lCZLOc9BBHAjN8dV_70qlE.json\n",
      "Processing: 1jqFe8JeHvNGhui5KWiI3_o9EFJ9o-6pu.json\n",
      "Processing: 1uBqRU_1hTOJsxCttinYzZgBsLxJsxOrG.json\n",
      "Processing: 17yLiyQnF-FX_GAOxpDz6HgCBNTeOTcbi.json\n",
      "Processing: 1r5shVVHnbhDZHMxi6J1y3aXHkNVsA7Pa.json\n",
      "Processing: 1BeQdDc2o3s7JMHM-NNmPVOUPjMC1OFfS.json\n",
      "Processing: 1cCyVnRM6VDnlsszD0Weo9-vrnw3r2qtk.json\n",
      "Processing: 1Zm6HvGmMNFAzQ4Osaymxk9QktwhWZtCq.json\n",
      "Processing: 1sDNoNF_F7fRSieM7OZIpRgqmZLMhiN7-.json\n",
      "Processing: 1zN2jtJGXKlB70fl3ukkSAJn04YlOjJHi.json\n",
      "Processing: 1NwaSabCJsv5_p56FeDEZ7eyZ_zGXXzw0.json\n",
      "Processing: 14psxphJ4GMA1c4x7sYEydVjdN7rMxXRS.json\n",
      "Processing: 1KK9uJZX_iDjIUHBxkXD09NOz04sytVDA.json\n",
      "Processing: 1NeFTGZrpE21aHt1Q1LUhkYJ7z9oSef6X.json\n",
      "Processing: 19ZciyAQZ4YN1L2PYHZj0j-It4i9vOKpk.json\n",
      "Processing: 1OAe5WgSo9n4HMu_kzyi_xlgW83HGnw6X.json\n",
      "Processing: 1Q-5zoaVsvubfr9BAyJvBlRTGTu3mpTSa.json\n",
      "Processing: 16xaZIXf68CrCjEmXTmfeEIaL7n2o32Gw.json\n",
      "Processing: 1q4sHugM236Eizw6t1VjC-RGKMo4HFRoY.json\n",
      "Processing: 1pHgC42g4Y0S8y24XncGWomGn_jEHOtL7.json\n",
      "Processing: 1zaw5K-QxwvwE23Bo2I4_KbafHAYWUARc.json\n",
      "Processing: 13xOX1lpgXo3Pyx4JgdSpDZPpeAvxk3Y_.json\n",
      "Processing: 1EA-IEQwqQO3ZRG4b_rTiuo6yHCxJh0Vk.json\n",
      "Processing: 1vfhSyHk9AW3lHFREMnqnDDBVTvq40ZOa.json\n",
      "Processing: 1hWgFJ-vTT8b8faK8DAXHSbL9dYRlo8W5.json\n",
      "Processing: 1U_EIeGy4LecsAHrxImpf4IVTr8Efyueh.json\n",
      "Processing: 1u-LiQjfTtbV6JbqLAH836VUFj1b8-4d6.json\n",
      "Processing: 1li6LGUo4hEo4BZkaX2axFqD2x5D_CSe0.json\n",
      "Processing: 1g5Es4RKphx1F6IGFJEyft3V_8kcFH3TF.json\n",
      "Processing: 1QFSMGuUrQYVNTZYyv4hSdcOLwHJI8Lsi.json\n",
      "Processing: 1P4bS1uHeJjT4VkiPn6pBzDs3jdZE6WEy.json\n",
      "Processing: 1By3k5P5BUpEfNjn_WVvlt8ZD1UWpKrWT.json\n",
      "Processing: 1cibKhLDMyIN6uVIfk2Q93Ft9Pg_P3hQX.json\n",
      "Processing: 1x5Nr0Yq4mNt5Sycn2inBJ_g1so2uchy0.json\n",
      "Processing: 1ndsHlk-Yq6bKus54tNgrzJPxfdNHToch.json\n",
      "Processing: 11qsvWxCuUEckw7FEvtv5nrOJVeT3MTb9.json\n",
      "Processing: 1PsfUvI_sr4cnXs5LaXNfQHqIneU0F94X.json\n",
      "Processing: 1C127M9COiv1ndISRpRN_kVsacXGG8-gt.json\n",
      "Processing: 12UkwxB3La664ELhUjFbzx4oTLaJAEqWn.json\n",
      "Processing: 1JwoX0ujNnwm0J7YY-4XWFXRz2k5ZGu7Z.json\n",
      "Processing: 11ZX7X-Ou3d3AZOWi_hB5bon2PPyE2wCp.json\n",
      "Processing: 1qv3nFrMp6B4ojZ6-cDxyCLSFgAIzJLoT.json\n",
      "Processing: 1p3VpeUVCMx9LfhEmZr6cwRBTcFNB1MPJ.json\n",
      "Processing: 1aW2a2-0SsCuh7XanNZS60i6N86NAI3VW.json\n",
      "Processing: 17VggXRwA3LpZKZsgXpSV2RghWMQTyNA5.json\n",
      "Processing: 19hKKv2IJ6PgKmKjveNgeB4mrHVOSL5gP.json\n",
      "Processing: 1vK7KT7sn_bosbg94lQ_OM5fIet8HtJVl.json\n",
      "Processing: 1A7o0B_dlJo546uJ76x697GUR6XpLwoo1.json\n",
      "Processing: 1dRdQDr2E-eKQfrTO0BQUGzRd_RX-2JXk.json\n",
      "Processing: 1lC1MrCaoScjIiK0ttI7WFe4WH-YITILR.json\n",
      "Processing: 1krAkwTjw95xlFRSf050tkK1WwxSppHEz.json\n",
      "Processing: 1Xtus0IG-Pc71LO5GZa2nBpr8ENK2Ss3h.json\n",
      "Processing: 1IeCNzINXdyuxiwqGTjU2awgHIo1MlM6o.json\n",
      "Processing: 1u8QkBGkD73n3pXYMvTK_Fc-ESRdc8bXm.json\n",
      "Processing: 1pH4NFkWQWNMdPOoNsISiJqYiwCip0LTh.json\n",
      "Processing: 1jAi8NcLf1S83C_ndBweMX6z02M8ihsvI.json\n",
      "Processing: 1eDs2wW8TPKDs5LeR1Em9Yq_y0JifJ8ir.json\n",
      "Processing: 1FVGjHvd6MUsO1EWGANDei27dUAVfr7Qb.json\n",
      "Processing: 1dKm8v4WSOCgAD_ImtKeYR2VFMHajsMei.json\n",
      "Processing: 1q2YO8cLV7hxNrnc-imR-72z8NCS_LBTG.json\n",
      "Processing: 1p0Y1C94lEj84f_tvyMP6GKGDv13AxQLD.json\n",
      "Processing: 1AhuhVmSPrhGUbf1pg9uOeFIVsQw_K4WP.json\n",
      "Processing: 1SYMZiGCD7TlvTZtlxcIHnGlSoX3v0y5t.json\n",
      "Processing: 11j9ogx3XDIe_oHPNSrXLdo-ZRd9gTBj_.json\n",
      "Processing: 1bwq568kd5F7P8wyZQE73cpDkDJHkm4-2.json\n",
      "Processing: 1nmq-G1gOq7N0dv_2Qooop6ZuMkI9hW7S.json\n",
      "Processing: 19cEqh_5Qs5XhqBpMWB7NUlK6xdJzz0Nl.json\n",
      "Processing: 1Ux3cfYW4kq_y5mHI7qNpOLEu9LE-J4ph.json\n",
      "Processing: 1NTZL3ssmpa4GZ9XtcVJ8mdpzvIjz8Uto.json\n",
      "Processing: 1zTNyAMz3-MEL-v22KhoIPrh-fkr8QO4c.json\n",
      "Processing: 1gvjfl9bZ9OF6hFupaJ3mE38NXIXZFS7C.json\n",
      "Processing: 1ocVFmo2EA9yS7RKINerE9qL6DhIpr4Hl.json\n",
      "Processing: 1dUWZR9TWW9zcRqAey6z49-IYk84BGWlR.json\n",
      "Processing: 11gnRdXw-XT5k6rnGmfBz7hsdnS2Yy4yO.json\n",
      "Processing: 1xW4kCzC7cyRG_9lU7DwFlKMjrnDkUX9n.json\n",
      "Processing: 1VtsJH1LfWiUvNYv_XyoFEmviFBtMDQ8o.json\n",
      "Processing: 1Mbw-ScZ6VuKQ7kS-v7taOPozqfJ-dYSB.json\n",
      "Processing: 16eCnF6ruef7Otvmf-ERwb47dm5o-qT_N.json\n",
      "Processing: 1sQHii6YILH2eU6sZv9UiDGFSXn_pgY6x.json\n",
      "Processing: 1XD6Ir4be8jHys7sAG5mRkN2U2J_eA5fY.json\n",
      "Processing: 1YKBnGU_2Du1usJDBVGx_42W8oONWIJIz.json\n",
      "Processing: 1P8SegWA1JQXsOZo7N87MbiqtzGLm-Dsn.json\n",
      "Processing: 1cUXhxtv74XrG_vV75lXzC5z120z12V3Q.json\n",
      "Processing: 1hmTAm5PF84Vg7ig9DWq2yryuy0ekmvAK.json\n",
      "Processing: 1rOf0RNHfzFqUl6hEAyZETX6uTJbktYht.json\n",
      "Processing: 1dqkMm9y5U7a-r-h944eC9cNyq1LfinfC.json\n",
      "Processing: 1GsQ2WxERk_BgFOpiYMuo4CPkXWI3F740.json\n",
      "Processing: 10YSH-nECaT3jh3ZMvh7NmUeZYA6e_qp1.json\n",
      "Processing: 15G21XVMd1-N12cYJAwlSCJZpYfxup19o.json\n",
      "Processing: 1tSBCdTq-gMKQtntUBYAk0AW8--jfzhfL.json\n",
      "Processing: 1AKo-O5zzAr322b-BY8U9Gh3xPKCpCIeb.json\n",
      "Processing: 1QBD5IYBe-lMaomzD6uTkJ7zYNK2T2oZy.json\n",
      "Processing: 1sZ_b1jMMNgcz8_ZVjWG-IcwYm5bvetfB.json\n",
      "Processing: 1Tv1-eHlUrCuX4wVRE53U1q66OoWyUIpf.json\n",
      "Processing: 1tvxnFel8bH6ouxEFYYb_wUVToVwmQJiS.json\n",
      "Processing: 1foWoCV19bjit6-IZj2kJqkCwhuMiexzj.json\n",
      "Processing: 1KrX0kD9HZgJPZRapK8_mEXXCMgDlJWR0.json\n",
      "Processing: 1VPwJiNYISDnMULJ1z4i9JDjnmeM7u8nC.json\n",
      "Processing: 1Kvymg_NKTIZAbZS5EhaYZ_tBvbuylny6.json\n",
      "Processing: 139RkvEuUaNnN1thZhXUjdLZh-MLA9vLs.json\n",
      "Processing: 165QDUw_ldL1-AMIXQBZsJkbRgiVGHI1k.json\n",
      "Processing: 1THjPNauR474s_9_KKCLNLJMCxdjazStr.json\n",
      "Processing: 1mTNE2xcqwCs4B2poVdCIOXvDVXMCl__g.json\n",
      "Processing: 1ikUcOlo8ZPL4ca-H2FdNAb6krzOPpDMG.json\n",
      "Processing: 15N5xhju0UEBORsmhwd2htB9bQZ34sS2_.json\n",
      "Processing: 1J6qwKM7Ck1F2FQWdqJlzD3MV8_syOsRT.json\n",
      "Processing: 1UsbsUJfmYjAYMT0gx6Vf31E-rHgdfN6v.json\n",
      "Processing: 1Igp2qudfhaXuBKwIMRYHZye145kcldp9.json\n",
      "Processing: 12Xnfgof2UeNr_FupYapZYaoyIRrx7fG4.json\n",
      "Processing: 1schMaLcUTvT_RUrtyEW5TCeWl-DZFTCC.json\n",
      "Processing: 1gH-rBSnllTSOgcJlcOCIfmeWNWc-wnE1.json\n",
      "Processing: 1ndW7NhnLb648R10qU7g0e6BglmdZ8mvZ.json\n",
      "Processing: 1rpZ7j-79YG-hGEjFVw5-RXaAB-0vOlb8.json\n",
      "Processing: 1FC4-mU1Lc18Bbq0yTEhlW2Nn2YqI6Yhc.json\n",
      "Processing: 12Hy8zETbqkppKYsjGx4unURVJzT5yOre.json\n",
      "Processing: 1MkOWPt3lCMuBXlx2rqw3UHhLcF9DoD1T.json\n",
      "Processing: 1BCZBOeULhmC_6qiYf-yS_jqPg9R0Hh2h.json\n",
      "Processing: 164mrEGoJATGysI4-K27R9nGpDfbKV3m_.json\n",
      "Processing: 1zwP-v9gTMo6NrsTtKANHUfkRKhzpO2kd.json\n",
      "Processing: 1KyELWfLp3u5FT4qKmrrgKsmSxZoGFRvS.json\n",
      "Processing: 1yXt7KipT0z3hS7HL7nqUeWeZ9IDX4j1z.json\n",
      "Processing: 1-iQHgJfpxaM8LXdZ2N64ayZwjfuvyiDx.json\n",
      "Processing: 1GwRFKLuT6dUEvOTtR9Rp7ICTyVVBQ6kK.json\n",
      "Processing: 13x9CAg6vhOxBKKJ4wfT1uQzgFlfuLBrv.json\n",
      "Processing: 19JPtwrpCPtCDAaMc8IOl128bRA_HVVyA.json\n",
      "Processing: 1wkIpll6WnsK1DMtoe4Vfq-4raBPwy_sS.json\n",
      "Processing: 1Dj47ZBeigXeNLniA4xAUq3W8uP5KbKBk.json\n",
      "Processing: 1wK23XiYaDS9ZbS59E6wUotbt_KgOEcz5.json\n",
      "Processing: 18rAyF_ydnGokkZ__idfP-zEB5fN8Uuxl.json\n",
      "Processing: 13_gQkS9JEN7DWd7Z2TnclNP6jcTou7LG.json\n",
      "Processing: 1WVzs_FJUAbNv0wXrVbhIvszgEKva3-jP.json\n",
      "Processing: 1SFI46JYvXOq9z9BtXauH7Ise9noYcFd2.json\n",
      "Processing: 1_Tffgc00q_CxtfuEw7HjimQU7_zCetCY.json\n",
      "Processing: 1TuTZEzp8cRHoek99MMyLHTSDPkkwnVle.json\n",
      "Processing: 1_poww_5F0WrWou11PL-vLzqbPfk4NQwu.json\n",
      "Processing: 1RA_RtZxR6xmk_nqo2BEZry4aXPLsx_ar.json\n",
      "Processing: 14qnmB8L3WG-e9a9iHh1Nz9zjWmoqgjEU.json\n",
      "Processing: 1PduxNNRIJjlX7B_aFcWaZjBD_eXdJK6c.json\n",
      "Processing: 1Z2CYfvSGNbwKgNpV3OvM-8msAsiycbAA.json\n",
      "Processing: 1Zp81JbO_Rmexnt63IrGP3a_E6A670UB-.json\n",
      "Processing: 1rv2FL9nZ2Z7kg2CzhPQwACV9BHLvEuvW.json\n",
      "Processing: 1y_nw1AGEV4oUVpeZnFQYnlkVmSHtNPks.json\n",
      "Processing: 1KbWKf26rMopzNNbZ3QFd_l1vpK3NxqK7.json\n",
      "Processing: 1YaiXpC30ZMlcKq6y5yfYK8itPyUGgrap.json\n",
      "Processing: 1z3mOGZOttyquFUbBXU57qlf3HI1BiOsy.json\n",
      "Processing: 17c2GBV-_UU3Yr6wjhzine1xhEZzGYACP.json\n",
      "Processing: 12UNFm7k28ToyS5xIOUez2qK-As-x9paY.json\n",
      "Processing: 1GBN0Pieg-h4v2m11oC3c4CR_re7L_1mf.json\n",
      "Processing: 1_K4UI5bP0PgJ7Eaip39d9qqcqgJzA6ZE.json\n",
      "Processing: 1iTMzYw278y5lrVY3aJ_Wqr1WS-CXFKzD.json\n",
      "Processing: 1PvdIZU0wiqCeOPcVZrEblV8iCE8xRXHm.json\n",
      "Processing: 1I3kjFJzW_Z2t3Pi6_iyOy4xOW0Zsrem0.json\n",
      "Processing: 18RMLD0l0I-Pzt8eROFqD1EGERj-dJ4y_.json\n",
      "Processing: 1_SViI6pAjsXdmqtO40QcdcXeh-JPyYnJ.json\n",
      "Processing: 16PKyTP8FPkwONo3iJa9QU2c_sFsy-wqm.json\n",
      "Processing: 1-y8A4NKPDd5ABKBM6m_YNURXiVl-tWHl.json\n",
      "Processing: 1LLfohSnpQkrwWmnWn5Z870--iAEfNi8q.json\n",
      "Processing: 1Ktnb9R0LfCSaE_0bHdkz3zDem2a7MMYp.json\n",
      "Processing: 1CGa7g07KCVZGVd6Brix8YZKEnC_EiqK7.json\n",
      "Processing: 1V492MszX9L0-uqs-Plkij1r0vcX4eMO6.json\n",
      "Processing: 1LEJxDd8mDp5qgM7fU4HN4OlUZc3LPOLg.json\n",
      "Processing: 1OXvNXnZoRS1Px4NCsSULspE5hdlHmD81.json\n",
      "Processing: 1C4Rv3dVQFi8DeVabkXKxH61IXi0xCaIB.json\n",
      "Processing: 1mbK3pFR2LtS3feqGY7Nhb7BhVf9yIwBS.json\n",
      "Processing: 1LIhTZg7Btvmfmpi8BFv_dSyAA4veny_S.json\n",
      "Processing: 1wZWtYXNkxEnyJmqD8a8osRs6AMx0EL9-.json\n",
      "Processing: 1AAMOuMtlNF4Hf5FllHnTlJofoaY07Ge_.json\n",
      "Processing: 1W1mPZl6OA28tVGm4vsmxOL4Q2lLiqZ3f.json\n",
      "Processing: 1jitP4xCAjz03rDLJDU3jXgJFVTDhkgcV.json\n",
      "Processing: 1llvRT60yWWbAFniDBvo2uL435yomzlcl.json\n",
      "Processing: 1-ite2956Bduhy5QH9YhRs4Nu6i-aIIQW.json\n",
      "Processing: 1EqUS86hy8RxQPI9Qvt1LvHMkDz1ddJB4.json\n",
      "Processing: 1CiJOWaHp2gg_YvKeKlCCorSAzbjw57WR.json\n",
      "Processing: 1ByMv0QjS3KLBARCJpPiLUPb6EtuVL61H.json\n",
      "Processing: 1OSg-HJc7S7E5e9P8NidgqJHAaL2ci76_.json\n",
      "Processing: 1-bujon06tl6eHFtiwiPKQ91glh85pD7z.json\n",
      "Processing: 1HuIQZClE7GAA-Qx-bgfYJeD-cEz7x69Z.json\n",
      "Processing: 1Uj-jx-jyNt1waVy4BgbJ8VvV1lZ7aKFa.json\n",
      "Processing: 1dCMJ--PMHldsb9EyKJcrj3q2QEl5kW2j.json\n",
      "Processing: 1KGK4DybzhOU3abJofcNOjT3nTh0ezzPy.json\n",
      "Processing: 15eYkWuWKMfAJF5yntXj7FB-0fVdjes6s.json\n",
      "Processing: 1tWTNrkk_A4wu5ob2l83zD8d73spxqyRN.json\n",
      "Processing: 13Tw0A8yNAQ4lAqOBRlMfgAjJ7ZNhMycx.json\n",
      "Processing: 1hGtKRjsM5PcG_vvgk344VSnNfF8WUrGF.json\n",
      "Processing: 1TryDAEvVfixCiZNg51x58uS1p_biwvXJ.json\n",
      "Processing: 10KCsC3sy3Rba620PZNdLu9sHAwe09Vgz.json\n",
      "Processing: 19HmT3nrmY465GRcrME91k550Km9qpB9O.json\n",
      "Processing: 12xQXXUXkApDNqvwXZKGJGPsCNbxnbvcR.json\n",
      "Processing: 1FkekYW4t58nY1sr3hFHDp60i5AM6XbYe.json\n",
      "Processing: 1my4v1sJ954TLesO7CesaeQ-43Y9iizqB.json\n",
      "Processing: 18na-z11bqm9AfWp5zypRDqWwQWrSb2W_.json\n",
      "Processing: 1xj2nGFy6LkiphbihDAEy3r4qtalhCPSf.json\n",
      "Processing: 1PZCt7Ms5OwOogVYGCD9PjTNh_Q25eawi.json\n",
      "Processing: 1m94WYgAI3Di0OAFk4mMUSUVVm7K7DtMx.json\n",
      "Processing: 1ftgHEr_mRRdZFQoKcCsvFdhHyz3xH1h-.json\n",
      "Processing: 1gFVxqWe-fzJSyVkkcqfSA8W1nUCLC01x.json\n",
      "Processing: 1swNorYffHk0q37WkeFuP5L9yX9sq7u8o.json\n",
      "Processing: 10Gdw94D8hV5jpcaYdovg_BmzpIoxN75g.json\n",
      "Processing: 1KeDmjC7XFRK5mX9OXHTjGMbVzViRUOEG.json\n",
      "Processing: 19kSQoban_LCFV76qqT4pGxrve2GRUIX5.json\n",
      "Processing: 1e2BE8A3zOHHrGqGiaeIjVJtBWs9CaMKC.json\n",
      "Processing: 1ISckfQ9AZaj5kMwkdlOIJCVfE31BjU5U.json\n",
      "Processing: 1dA6psB1agyCf7xO_VULAfTFGhC01vEJ6.json\n",
      "Processing: 1oru8cEwM3EEZJqafKnSp0-FY-OG16C7_.json\n",
      "Processing: 1jOYC-58fAs-aH5UtjzisQwRvuIad-wA_.json\n",
      "Processing: 17wXBsSa0U8wU7WThL6D5JA29Z48d5gf4.json\n",
      "Processing: 1lzFdstwWfV_5z0JC-nMRiOH8zI7uMKFO.json\n",
      "Processing: 13RIpO5_aHrEIq0--HcHKzOU-MESOE5pG.json\n",
      "Processing: 1q55lXjnStgUauNY8XeQ3Z8MAgKFJzHZl.json\n",
      "Processing: 1tasd-w1mLRYcZg9dfJ-vqf9ynZg7bi-7.json\n",
      "Processing: 15Yz7fwUf4EuKwh_Pi6ugC6lSNEZwDRmV.json\n",
      "Processing: 1GqGPaKGcjzdZjA7p-9OJw3lMEYjlfJNj.json\n",
      "Processing: 1L-Vx6dHcuOZDgtTOrk9k9AvOgYCum6dQ.json\n",
      "Processing: 1hRe6OTOK5j9lxZ94nU9IOZYGStQyBOAP.json\n",
      "Processing: 1vyOj56vLeT16iJvNENb8r8dbPF20DWOR.json\n",
      "Processing: 19Cpl63hZwchgdMFuaUgOrzY_Pv39DmU-.json\n",
      "Processing: 1I4CIMIIBCA6Ise5XUyLB6aWc1ZjMQsx6.json\n",
      "Processing: 1jiQhiPk7bZEwro1xNj1iItDRROpDq9wX.json\n",
      "Processing: 1E67CUe9BDt4zbadus_qo22UPvvgmIfFG.json\n",
      "Processing: 1h7qcHGK0u13_ZSo5C-Zf6DWfDkkIAUCB.json\n",
      "Processing: 1Oc6WjhamRYicT_WbgnxMaQRGK3mYyx51.json\n",
      "Processing: 1SbSrys_ssUfWkIAjva6dTHWHfKtKnEHh.json\n",
      "Processing: 1e6iNJcMF7i8jF9cKkMvSxy2BOCBLaPQ9.json\n",
      "Processing: 1-ZycV_t8iXJn9IaFGtMBhCyvUYZvAQY4.json\n",
      "Processing: 12UfqyVxCtr2Gdrua-_0G6TjDn7UaqMZ0.json\n",
      "Processing: 1q2KDQVNJ8hOwrHv3lBEe5gdNy7PUdb29.json\n",
      "Processing: 1xGEHflfPWwOrHG16aSmca7I77zOtsCwr.json\n",
      "Processing: 1NcXDftbSnMxhcfTiELD2mMowK0oyqvWd.json\n",
      "Processing: 1e1aJI-EbaoULgrtdwTbCil5Tjabi6ctI.json\n",
      "Processing: 1Vt0Qdr3doQ0Avp2dNgpG_TLWj_Rp7NXZ.json\n",
      "Processing: 1wP6TeEbX6KMBJmlw6XSs9xZv5lN3p_Ae.json\n",
      "Processing: 1Bw8ZtMgx1LwwJQPp1vA1MYTVFSuXOcCO.json\n",
      "Processing: 14iyhKrTD1Tv4H_doOa0eC9WKesnYVimh.json\n",
      "Processing: 1dn_zPQXJU33ZfA-QbUpwLJq81cYgGqp9.json\n",
      "Processing: 1Qam-Yq2JidOmOm9pvQRR-d62w5IHLlkZ.json\n",
      "Processing: 1Y5G-Tgw0hJH2DTk1k-ntjNnPfDr5FYs-.json\n",
      "Processing: 1nW2I956hn_ps7FubT-sQpd5PWXrgwuPg.json\n",
      "Processing: 1wx_UisDlDKa4LQKr99z2X0yDtFBRHs_F.json\n",
      "Processing: 1X44QU_87SHrfvb00NpbhrQnBNTWgG0Ph.json\n",
      "Processing: 15eGoanxLycF03AMcvRfx-WmUTsEeRI9j.json\n",
      "Processing: 13uvSi5ZKoL5nc4U9VJyg3SsDf0SWseL-.json\n",
      "Processing: 1u-Y6MsgnsonqjvqetZ_I72v-CZO_wOHu.json\n",
      "Processing: 1pxZdo6mGPpNlMfd3B0a3MXR2zU3ZYhT6.json\n",
      "Processing: 1OwFdC91dm396ubLwDomiAyFGqNiSDwYP.json\n",
      "Processing: 1Maa9q96IoPSSx4GGfYsaJu1h-gyJmpuN.json\n",
      "Processing: 1MXwPLhaWmo4yUAfzsVN2hdYxGpm8iUzW.json\n",
      "Processing: 1ElmoCfIziAOOceB0HwwDIEUaNNPLh7b-.json\n",
      "Processing: 1RYoBPEVpVFvUO-uLDTWx2vckSq73Ihp-.json\n",
      "Processing: 1FAzFYv-fOH5v-IrxH2nn_f9n2PrfpNjl.json\n",
      "Processing: 1evF67huMdrTIoBBKkvnAaQg7q9qncuO0.json\n",
      "Processing: 1NZVSokxQjbsyowem9Ay56RkBK2pR_6e9.json\n",
      "Processing: 19bAuEuQhKrVwuCYprslbAPITShNN5A24.json\n",
      "Processing: 1uAxvVNIeoMGYWUeQeWP4-uBBbbf-SRd-.json\n",
      "Processing: 1JJ9BlxUmTEVO-GGIJk_jP4JzvO6qvWPf.json\n",
      "Processing: 1Jv96_tXn4GhS1SzDFGSoil7hydrHiIvj.json\n",
      "Processing: 1BR_cMikfmC48VdgJCGTX_-Wtl6LsJWUv.json\n",
      "Processing: 1MRPH3QGP33i32mRMRdOQ8rYQ-3k_pOSB.json\n",
      "Processing: 1wQpnC4Btq2IBDEPpcI2YS33-whrO-TLq.json\n",
      "Processing: 1EvY2CGsxVydUl4GqPgTEDqaQBp0_eKwI.json\n",
      "Processing: 1BC5h4r2Ho0o0IBiILyX13PaQlVaQXxLj.json\n",
      "Processing: 16fl5Gbb44QRSp30SH2iSLKljmhdpTO9S.json\n",
      "Processing: 1g4FSO2AD4-tRDlxzu9KntjsRAp_IJ5hl.json\n",
      "Processing: 1VVA9Ou6RF81g8WfHnhyCiErOAxuj2ctI.json\n",
      "Processing: 1ESfFnOAPvJi71dhTfP5-vwAaOg94dG-r.json\n",
      "Processing: 1YX807fFhKVjcaKGxJQ8KRpTSJ-a461zY.json\n",
      "Processing: 1roAdST26phs-xun5lk6H17pJhMlQ3OAM.json\n",
      "Processing: 1xJGr_rSNsXowfomTFLkg42yaBZO9kg4-.json\n",
      "Processing: 1NxLEXfpdCV7QkFTEyZQeZCfUxx9AVHdu.json\n",
      "Processing: 1JYVdOxHGMPOQZpSFsO32GfHy-aTVL_EQ.json\n",
      "Processing: 1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f.json\n",
      "Processing: 1wGktEam1WyecaJ4nQzau5cnpMJI6q1OJ.json\n",
      "Processing: 1dm2bQ27keefgzLjiIb1CPpri2ATrcq8K.json\n",
      "Processing: 1-BXRfWYnubwn7lOVrqae4x0CXxEdFaz4.json\n",
      "Processing: 17v3OEHbvxDpIfgWRyvkcjsV1_IrGU0Ri.json\n",
      "Processing: 1e6ORvNVBNteC_5q2IhnfdReEdsn_bb_-.json\n",
      "Processing: 1yQw-QRBZx9lvjBzcNtSKwdsRLe5C0OIY.json\n",
      "Processing: 1kWfIjRtVR-JgKgfeeAAU-iUr-M7Pl-wo.json\n",
      "Processing: 1ekvONm5eHW792RXe7Wx2nrvXo8zSn2uL.json\n",
      "Processing: 1FzJ_gV43gy6Bz-QMzJatWina5CGnuSbH.json\n",
      "Processing: 1-lWGDxx41n9sg87yIsqVTur1ZVpR0nSO.json\n",
      "Processing: 1AM3BNP3qoqo_nHZMl0RZKQffIi62wBPQ.json\n",
      "Processing: 1bN2NupKkQhL-7CXqCZy6eIYg3HMv7tic.json\n",
      "Processing: 1EgbrftyowG-BLG344HvjMdSdXoYqlLFf.json\n",
      "Processing: 1II0a4SSwrpX8rAN_Ay_Z9oBirqQE-TcH.json\n",
      "Processing: 1dnsux9F1AHnSMpRzJ64R0Anx0ZcyJ34W.json\n",
      "Processing: 1GmwZRUz9Owkf2TclEkiiq3s58YCekLnd.json\n",
      "Processing: 1FwyiVzBttmYOQfnazRi_HYPOlt37xr8N.json\n",
      "Processing: 1_jqq7lGrGU_f_lZGZ77jrvtpcO6o2TbV.json\n",
      "Processing: 1CQ_uG30iRMNGwbnfWpRDKpAmp3zuPkDb.json\n",
      "Processing: 1jbeQ_ymBOVQwsOtYhxGT7RlfLxBQ7-t1.json\n",
      "Processing: 1C0v3_jz8KjDpgimku1Fdmw2UwqGSinzR.json\n",
      "Processing: 1xtWX10-Qg6e0EHglgMpDWp0NARwIisYH.json\n",
      "Processing: 1iNsFLmiPWiN_-injNgBLiXAoelwChP_h.json\n",
      "Processing: 1WYX94uw-WDubLNUgZ_i3NA68-FySkxC-.json\n",
      "Processing: 1gyg2PWmK-h_YcZFKPrSTRwDpeVX-xCB0.json\n",
      "Processing: 1M7vLjOSVj3V6Jlw4JnLe-dGwbKE3HGL6.json\n",
      "Processing: 1QYpyxGkhg1Lf0_hAjZPIAqwSmibpfxdD.json\n",
      "Processing: 1GNPMzzYaDfJcep_FN1H5c9EveeukJAql.json\n",
      "Processing: 1pB3VKjDW-_QboFAToQnVh4AcaGFn-vll.json\n",
      "Processing: 1WG0xTCOtb-Sqh7EDc8hwtv79WqNxulDZ.json\n",
      "Processing: 14VKzIcDY0jPyZj5q8U-3ji5Uc5JsqFfh.json\n",
      "Processing: 1Bgrgp27K_JMg24_AG12kgdihQFZLI38F.json\n",
      "Processing: 1A-YweYaxWJ0i__vUSoQJaBAMLaNTSR4v.json\n",
      "Processing: 1lBqPQrCdJma67bajak4aDA4ig5AHprL4.json\n",
      "Processing: 1RLQ4Wj3CAWWe-ai9PpCjnTd9GS9T3llQ.json\n",
      "Processing: 1ECuDx68IcWRloMOFquD-KyBrzwqXVjCM.json\n",
      "Processing: 1vNGXlYhkomfnBTneQbozqkh2iWW8wNrq.json\n",
      "Processing: 1T6ziXOBBL4HD99k2thLLUnof9AeabXfT.json\n",
      "Processing: 1OzzFPkquV8XPjHMj10HNal27NvismqNU.json\n",
      "Processing: 1ogdDTsrSk7Puy8HvD5HwTN4Lx2rxRYDx.json\n",
      "Processing: 1zD0DbXGuzDmuuKWFKurLk5hp4-YHgzJt.json\n",
      "Processing: 1oH2AAUvZuDAFLgIOvpWFXrtq2PXjlOeA.json\n",
      "Processing: 1hx5ac02YXMaMRDz0yhfTHYRh0cX3GGNk.json\n",
      "Processing: 13euOK8A1xiwPor6MeDB76z2j9k0dbxrl.json\n",
      "Processing: 1hBGIIO1iAs_TOcl-D22I48dmXTYs36zs.json\n",
      "Processing: 1OZksWyvbEzAogS9vZ4xdazIzTcxtWEqT.json\n",
      "Processing: 1xXBdxTUwoXXkAt-oew0P0ZjXjTZEQ9vU.json\n",
      "Processing: 10MGY0KFzDDatqxqAAnb_Qr3QERkrIt76.json\n",
      "Processing: 1DmBa53rxjxzTaOOKV4LsQfVwrY78VJp2.json\n",
      "Processing: 1kv9kfPyGyjvY1O1UH_01iLctxfS1UGk9.json\n",
      "Processing: 16lUfQfrkuObx4vxdKCq6iHuvFpmdz4w0.json\n",
      "Processing: 1zffjzl7-PSmyfljmyWzp98JHSuvbf1Mz.json\n",
      "Processing: 18P0VVT9j1TmJe3yblEbv_NBfUW9CLHSr.json\n",
      "Processing: 1IlMpsLlHYIDwpwv-dbG23pxFretkX54o.json\n",
      "Processing: 1KH8BfVyxWDtxf8_-_fAy_il_1cy-3FxY.json\n",
      "Processing: 1qcZAFBAoEu08C14Vo3x8E0KkYRSlKE4Z.json\n",
      "Processing: 1miwBmGngjmkuhz0JZFyv_zLe92ghZjwQ.json\n",
      "Processing: 1F8pDEDA3UzOzRmt2fK3DTUBXQWFeMNrv.json\n",
      "Processing: 1uU28jLtLHaZM63YQf2HAUqlHm76Y84Uu.json\n",
      "Processing: 1gHR5IBB9y0U8Ag_xGSB0TgarHVzzG3tz.json\n",
      "Processing: 1_slXeCkFcpl5tT_bh1SnFzIz3qPSNQjW.json\n",
      "Processing: 1ieNwqfSB2M-LfDE53m5P40_0MJVgwr5R.json\n",
      "Processing: 1Kwp2lzVJ6eXImnYM9zkx7sqWZ3Jzkzeo.json\n",
      "Processing: 1ca91-ZE2u1uigCJgT-da-fypBEtzYNvB.json\n",
      "Processing: 1OzeEb4YC1Wtd8dNHsniQA0dzOenqXedj.json\n",
      "Processing: 12epNqcjKHkdY2h5YFmLm35gnzgTBMhS0.json\n",
      "Processing: 1JvT7-QDjnv7_V-4JViMjy4NkTpqpwN0m.json\n",
      "Processing: 1rJg7x3jtxcM12PJcjvv1LhidmhDYmQSg.json\n",
      "Processing: 16rz0ZciymjY2g89UTgZKtU2N-qELFP5h.json\n",
      "Processing: 1Iv3520Jh-gIVN4p_mERTAbZUT91QjEsR.json\n",
      "Processing: 1thtiMDx3NkfiUflEYfVoBioRKjw3yIig.json\n",
      "Processing: 1dxTCm7-yA6Y5JYQIMe2jttqu5mJ4E0V2.json\n",
      "Processing: 1E7timyevPuTgBRzpmu7V7HmtilIhwf9w.json\n",
      "Processing: 1EnQ3YLAmcOhnrgH8v29s_1dC_qqHXnRy.json\n",
      "Processing: 1_6Qdm75viH2k6Q3ZVKgJhq4XAPTvh8Uy.json\n",
      "Processing: 1ISirhbmPOg8hMIJuvIHVtv-MymPC13cO.json\n",
      "Processing: 1U6R75f_w3lnIXiTqxUY6d8g0KnF7smno.json\n",
      "Processing: 1WSikzqLteWlrVN6Alrbb4Znabf1nVrcw.json\n",
      "Processing: 1tfM9qyzQXfO2flEgsdbpYGZHd3tbpVzf.json\n",
      "Processing: 16akewCNbJ_WKVcdT5A_3e-3JSKIfV6t6.json\n",
      "Processing: 1tQgcUhA57xu1DpW3_lEJQme7kZS6nRyJ.json\n",
      "Processing: 1xDfUMYyCwmSJysAckhfKUqfmva3PO4p9.json\n",
      "Processing: 1l4T0b0X8edtTqjWBbQoKWmsPyxv87IKI.json\n",
      "Processing: 1Vj9jWuGy5tJytNnQlwIEFdP3XZySZnAx.json\n",
      "Processing: 1g7E1J6-igfouc72_fKbYrfCmQMi3dRfR.json\n",
      "Processing: 1BjARGS28BJKUDAcOomFhss5iUEKanIxL.json\n",
      "Processing: 1at9l31B5JJedNWESHTbIe-lZ0Kb3eLE8.json\n",
      "Processing: 1l1mEkoBdTxaLdSNoIrm5zhGoq4p1IGct.json\n",
      "Processing: 1YYN8euRL-Hi0tVrsuwb6Dtr59oyECoqL.json\n",
      "Processing: 1IbBVFF9oXyjOTSIq_dZ9wb1oIfmQVC-e.json\n",
      "Processing: 1DH6pdfulbNEgJMM-gPxpOBbdp61imdrp.json\n",
      "Processing: 1faEVTMqe5zMedGBfL4ES32PmL5w1Alsu.json\n",
      "Processing: 1y8bY0mQ5qAC-RU89AQe5FeX4qjULF1Y3.json\n",
      "Processing: 1uaC7qVzNBHvslQFY2ue-2qgVT9h04J5B.json\n",
      "Processing: 1mSsHp989m68eByVt50X-waxyFn2uN82L.json\n",
      "Processing: 1cewNJga9p-144i4Pltr4EYL9SdcGHhIF.json\n",
      "Processing: 1yo8nForqLs9iNTudZzfw6kdAGS-hztlN.json\n",
      "Processing: 1DHy0yA7DTW8eIUwIzFjWp070PaNKm7AB.json\n",
      "Processing: 1HD_gRZz2Df_bQqfS_qvuPVrmsSLgqsjp.json\n",
      "Processing: 1jxYX1JNncVSrlx7ZZgVeDdQyUN4B-f-u.json\n",
      "Processing: 10KrdfBV5aLk9UN6_sOEGY4CGHgdS_ynY.json\n",
      "Processing: 1EPUNKPHSyVCz8vgRfybkNQi8VEy30DXK.json\n",
      "Processing: 1NZy7ea-SIqpFReH-Wa-pLtZ__aMuG0xG.json\n",
      "Processing: 1zOj_5wMcwAUMZ4scdxfJvhtg7luoXGn3.json\n",
      "Processing: 1tS0oZayjTgt9rcTnQv88Oh6CKfbwsBBZ.json\n",
      "Processing: 1d3bS2Gti175I5sHJdXo4RW1TsNOzXPu5.json\n",
      "Processing: 1WDGIi_FQ9p5RxEgWigDGorwqm5di3_Mn.json\n",
      "Processing: 1UoJmB4imKSg2XT7ev1dguvMASrmp2YP1.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>webViewLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1di3Ikq5LiB3moG0E75rkZK4muYETUxVn</td>\n",
       "      <td>112T7jIlxZ9OxXh3vRhMHsfScKvkQKsYs.json</td>\n",
       "      <td>https://drive.google.com/file/d/1di3Ikq5LiB3mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bBo9KjX3YAGeIfZ_8xzfOQhTEZppchRn</td>\n",
       "      <td>1kMh0GcOJQs_Hsv8pVYOCcajcrPdUV-4X.json</td>\n",
       "      <td>https://drive.google.com/file/d/1bBo9KjX3YAGeI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1KlHJdNsI5D_8oXzVfOL_ZSmADJSqCjie</td>\n",
       "      <td>17WwbWsmK1FjQyKUFlBz0S6NHRbYrdlQu.json</td>\n",
       "      <td>https://drive.google.com/file/d/1KlHJdNsI5D_8o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1jF1X3ZA2GG8niR_CR9QxRTmRMwVoek4v</td>\n",
       "      <td>1R7Z-6XVWhKd8jxBIwooXGAJpgF9TYZXL.json</td>\n",
       "      <td>https://drive.google.com/file/d/1jF1X3ZA2GG8ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1ZKBOls8fI0vezoyW-zYynU3sTMw5Eag4</td>\n",
       "      <td>1OmBS8YfCz9auI-6_wRpxReUmuKjlJ6bA.json</td>\n",
       "      <td>https://drive.google.com/file/d/1ZKBOls8fI0vez...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1smeBFGIqGj1llkhkNpyJM3pUYeejQHk7</td>\n",
       "      <td>1zOj_5wMcwAUMZ4scdxfJvhtg7luoXGn3.json</td>\n",
       "      <td>https://drive.google.com/file/d/1smeBFGIqGj1ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1_dXmzsV8cQDUq55AFg0J2J5TId13_zy2</td>\n",
       "      <td>1tS0oZayjTgt9rcTnQv88Oh6CKfbwsBBZ.json</td>\n",
       "      <td>https://drive.google.com/file/d/1_dXmzsV8cQDUq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1IC2kmGVju4HX9q_uEIjwiyccQj5rboJz</td>\n",
       "      <td>1d3bS2Gti175I5sHJdXo4RW1TsNOzXPu5.json</td>\n",
       "      <td>https://drive.google.com/file/d/1IC2kmGVju4HX9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>1YESrG9sdNLJTImToRyICg_EooCe_CUbM</td>\n",
       "      <td>1WDGIi_FQ9p5RxEgWigDGorwqm5di3_Mn.json</td>\n",
       "      <td>https://drive.google.com/file/d/1YESrG9sdNLJTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1JKxehgbnnd9RUE7JPjcor4KlV9d0StQ6</td>\n",
       "      <td>1UoJmB4imKSg2XT7ev1dguvMASrmp2YP1.json</td>\n",
       "      <td>https://drive.google.com/file/d/1JKxehgbnnd9RU...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0    1di3Ikq5LiB3moG0E75rkZK4muYETUxVn   \n",
       "1    1bBo9KjX3YAGeIfZ_8xzfOQhTEZppchRn   \n",
       "2    1KlHJdNsI5D_8oXzVfOL_ZSmADJSqCjie   \n",
       "3    1jF1X3ZA2GG8niR_CR9QxRTmRMwVoek4v   \n",
       "4    1ZKBOls8fI0vezoyW-zYynU3sTMw5Eag4   \n",
       "..                                 ...   \n",
       "556  1smeBFGIqGj1llkhkNpyJM3pUYeejQHk7   \n",
       "557  1_dXmzsV8cQDUq55AFg0J2J5TId13_zy2   \n",
       "558  1IC2kmGVju4HX9q_uEIjwiyccQj5rboJz   \n",
       "559  1YESrG9sdNLJTImToRyICg_EooCe_CUbM   \n",
       "560  1JKxehgbnnd9RUE7JPjcor4KlV9d0StQ6   \n",
       "\n",
       "                                       name  \\\n",
       "0    112T7jIlxZ9OxXh3vRhMHsfScKvkQKsYs.json   \n",
       "1    1kMh0GcOJQs_Hsv8pVYOCcajcrPdUV-4X.json   \n",
       "2    17WwbWsmK1FjQyKUFlBz0S6NHRbYrdlQu.json   \n",
       "3    1R7Z-6XVWhKd8jxBIwooXGAJpgF9TYZXL.json   \n",
       "4    1OmBS8YfCz9auI-6_wRpxReUmuKjlJ6bA.json   \n",
       "..                                      ...   \n",
       "556  1zOj_5wMcwAUMZ4scdxfJvhtg7luoXGn3.json   \n",
       "557  1tS0oZayjTgt9rcTnQv88Oh6CKfbwsBBZ.json   \n",
       "558  1d3bS2Gti175I5sHJdXo4RW1TsNOzXPu5.json   \n",
       "559  1WDGIi_FQ9p5RxEgWigDGorwqm5di3_Mn.json   \n",
       "560  1UoJmB4imKSg2XT7ev1dguvMASrmp2YP1.json   \n",
       "\n",
       "                                           webViewLink  \n",
       "0    https://drive.google.com/file/d/1di3Ikq5LiB3mo...  \n",
       "1    https://drive.google.com/file/d/1bBo9KjX3YAGeI...  \n",
       "2    https://drive.google.com/file/d/1KlHJdNsI5D_8o...  \n",
       "3    https://drive.google.com/file/d/1jF1X3ZA2GG8ni...  \n",
       "4    https://drive.google.com/file/d/1ZKBOls8fI0vez...  \n",
       "..                                                 ...  \n",
       "556  https://drive.google.com/file/d/1smeBFGIqGj1ll...  \n",
       "557  https://drive.google.com/file/d/1_dXmzsV8cQDUq...  \n",
       "558  https://drive.google.com/file/d/1IC2kmGVju4HX9...  \n",
       "559  https://drive.google.com/file/d/1YESrG9sdNLJTI...  \n",
       "560  https://drive.google.com/file/d/1JKxehgbnnd9RU...  \n",
       "\n",
       "[561 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Function to check if a file is a folder\n",
    "def is_folder(file):\n",
    "    return file.get('mimeType') == 'application/vnd.google-apps.folder'\n",
    "\n",
    "# Function to process files and folders\n",
    "def process_files(service, folder_id, parent_folders=[]):\n",
    "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "    page_token = None\n",
    "\n",
    "    all_files = []\n",
    "    while True:\n",
    "        response = service.files().list(q=query,\n",
    "                                        spaces='drive',\n",
    "                                        fields='nextPageToken, files(id, name, mimeType, webViewLink)',\n",
    "                                        pageToken=page_token).execute()\n",
    "\n",
    "        for file in response.get('files', []):\n",
    "            # Skip 'tool_data' folder\n",
    "            if file.get('name') == 'tool_data' and is_folder(file):\n",
    "                continue\n",
    "\n",
    "            all_files.append(file)\n",
    "\n",
    "            # Process the file or folder\n",
    "            print('Processing:', '/'.join(parent_folders + [file.get('name')]))\n",
    "\n",
    "            # If it's a folder, recursively process its contents\n",
    "            if is_folder(file):\n",
    "                children_files = process_files(service, file.get('id'), parent_folders + [file.get('name')])\n",
    "                all_files.extend(children_files)\n",
    "\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break\n",
    "\n",
    "    return all_files\n",
    "\n",
    "# Authenticate and create the service\n",
    "SERVICE_ACCOUNT_FILE = service_account_file\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "# Replace with your Google Drive folder ID\n",
    "folder_id = destination_folder_url.split(\"/\")[-1]\n",
    "\n",
    "# Start processing from the specified folder\n",
    "all_files = process_files(service, folder_id)\n",
    "\n",
    "jsonl_df = pd.DataFrame(all_files)\n",
    "jsonl_df = jsonl_df[[\"id\", \"name\", \"webViewLink\"]]\n",
    "jsonl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_id</th>\n",
       "      <th>task_link</th>\n",
       "      <th>number_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1zOj_5wMcwAUMZ4scdxfJvhtg7luoXGn3</td>\n",
       "      <td>https://colab.research.google.com/drive/1zOj_5...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1UoJmB4imKSg2XT7ev1dguvMASrmp2YP1</td>\n",
       "      <td>https://colab.research.google.com/drive/1UoJmB...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16akewCNbJ_WKVcdT5A_3e-3JSKIfV6t6</td>\n",
       "      <td>https://colab.research.google.com/drive/16akew...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1WDGIi_FQ9p5RxEgWigDGorwqm5di3_Mn</td>\n",
       "      <td>https://colab.research.google.com/drive/1WDGIi...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1EPUNKPHSyVCz8vgRfybkNQi8VEy30DXK</td>\n",
       "      <td>https://colab.research.google.com/drive/1EPUNK...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>112T7jIlxZ9OxXh3vRhMHsfScKvkQKsYs</td>\n",
       "      <td>https://colab.research.google.com/drive/112T7j...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>1R7Z-6XVWhKd8jxBIwooXGAJpgF9TYZXL</td>\n",
       "      <td>https://colab.research.google.com/drive/1R7Z-6...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1WQuPASB2kwBdhbyxnFJ-75o6HkpPrO2z</td>\n",
       "      <td>https://colab.research.google.com/drive/1WQuPA...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>17WwbWsmK1FjQyKUFlBz0S6NHRbYrdlQu</td>\n",
       "      <td>https://colab.research.google.com/drive/17WwbW...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>1c9LkyN6hDRb7xE_-P9tUsEO8e__A9QIX</td>\n",
       "      <td>https://colab.research.google.com/drive/1c9Lky...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              colab_id  \\\n",
       "0    1zOj_5wMcwAUMZ4scdxfJvhtg7luoXGn3   \n",
       "1    1UoJmB4imKSg2XT7ev1dguvMASrmp2YP1   \n",
       "2    16akewCNbJ_WKVcdT5A_3e-3JSKIfV6t6   \n",
       "3    1WDGIi_FQ9p5RxEgWigDGorwqm5di3_Mn   \n",
       "4    1EPUNKPHSyVCz8vgRfybkNQi8VEy30DXK   \n",
       "..                                 ...   \n",
       "556  112T7jIlxZ9OxXh3vRhMHsfScKvkQKsYs   \n",
       "557  1R7Z-6XVWhKd8jxBIwooXGAJpgF9TYZXL   \n",
       "558  1WQuPASB2kwBdhbyxnFJ-75o6HkpPrO2z   \n",
       "559  17WwbWsmK1FjQyKUFlBz0S6NHRbYrdlQu   \n",
       "560  1c9LkyN6hDRb7xE_-P9tUsEO8e__A9QIX   \n",
       "\n",
       "                                             task_link  number_of_turns  \n",
       "0    https://colab.research.google.com/drive/1zOj_5...                4  \n",
       "1    https://colab.research.google.com/drive/1UoJmB...                3  \n",
       "2    https://colab.research.google.com/drive/16akew...                3  \n",
       "3    https://colab.research.google.com/drive/1WDGIi...                4  \n",
       "4    https://colab.research.google.com/drive/1EPUNK...                4  \n",
       "..                                                 ...              ...  \n",
       "556  https://colab.research.google.com/drive/112T7j...                2  \n",
       "557  https://colab.research.google.com/drive/1R7Z-6...                4  \n",
       "558  https://colab.research.google.com/drive/1WQuPA...                4  \n",
       "559  https://colab.research.google.com/drive/17WwbW...                4  \n",
       "560  https://colab.research.google.com/drive/1c9Lky...                3  \n",
       "\n",
       "[561 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.keys()\n",
    "\n",
    "parsed_jsons_ref = [\n",
    "    {\n",
    "        \"colab_id\": pj[\"id\"],\n",
    "        \"task_link\": pj[\"metadata\"][\"task_link\"],\n",
    "        \"number_of_turns\": pj[\"metadata\"][\"number_of_turns\"],\n",
    "    }\n",
    "    for pj\n",
    "    in parsed_jsons\n",
    "]\n",
    "conversation_df = pd.DataFrame(parsed_jsons_ref)\n",
    "conversation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>number_of_turns</th>\n",
       "      <th>jsonl_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1zOj_5...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1smeBFGIqGj1ll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1UoJmB...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1JKxehgbnnd9RU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/16akew...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1gb60vTwO78hkB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1WDGIi...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1YESrG9sdNLJTI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1EPUNK...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/15-jPR2TKT3Sav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>https://colab.research.google.com/drive/112T7j...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://drive.google.com/file/d/1di3Ikq5LiB3mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>https://colab.research.google.com/drive/1R7Z-6...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1jF1X3ZA2GG8ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>https://colab.research.google.com/drive/1WQuPA...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/180pheUxammHNP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>https://colab.research.google.com/drive/17WwbW...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1KlHJdNsI5D_8o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>https://colab.research.google.com/drive/1c9Lky...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1UIy7yCKYPn7Bz...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>561 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link  number_of_turns  \\\n",
       "0    https://colab.research.google.com/drive/1zOj_5...                4   \n",
       "1    https://colab.research.google.com/drive/1UoJmB...                3   \n",
       "2    https://colab.research.google.com/drive/16akew...                3   \n",
       "3    https://colab.research.google.com/drive/1WDGIi...                4   \n",
       "4    https://colab.research.google.com/drive/1EPUNK...                4   \n",
       "..                                                 ...              ...   \n",
       "556  https://colab.research.google.com/drive/112T7j...                2   \n",
       "557  https://colab.research.google.com/drive/1R7Z-6...                4   \n",
       "558  https://colab.research.google.com/drive/1WQuPA...                4   \n",
       "559  https://colab.research.google.com/drive/17WwbW...                4   \n",
       "560  https://colab.research.google.com/drive/1c9Lky...                3   \n",
       "\n",
       "                                            jsonl_link  \n",
       "0    https://drive.google.com/file/d/1smeBFGIqGj1ll...  \n",
       "1    https://drive.google.com/file/d/1JKxehgbnnd9RU...  \n",
       "2    https://drive.google.com/file/d/1gb60vTwO78hkB...  \n",
       "3    https://drive.google.com/file/d/1YESrG9sdNLJTI...  \n",
       "4    https://drive.google.com/file/d/15-jPR2TKT3Sav...  \n",
       "..                                                 ...  \n",
       "556  https://drive.google.com/file/d/1di3Ikq5LiB3mo...  \n",
       "557  https://drive.google.com/file/d/1jF1X3ZA2GG8ni...  \n",
       "558  https://drive.google.com/file/d/180pheUxammHNP...  \n",
       "559  https://drive.google.com/file/d/1KlHJdNsI5D_8o...  \n",
       "560  https://drive.google.com/file/d/1UIy7yCKYPn7Bz...  \n",
       "\n",
       "[561 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_df[\"colab_id\"] = jsonl_df[\"name\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "\n",
    "df_merged = conversation_df.merge(jsonl_df, on=\"colab_id\", how=\"inner\")\n",
    "df_merged = df_merged[[\"task_link\", \"number_of_turns\", \"webViewLink\"]]\n",
    "df_merged = df_merged.rename(columns={\"webViewLink\": \"jsonl_link\"})\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Batch Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sheets_utils import upload_df_to_sheet\n",
    "\n",
    "cols = [\"task_link\", \"jsonl_link\", \"number_of_turns\"]\n",
    "upload_df_to_sheet(service_account_file, \"1eUif5I8xhHU8fY0X9v8r2JI9hWPh7Dq_9VXpSIHwww4\", DELIVERY_BATCH_NAME, df_merged[cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
