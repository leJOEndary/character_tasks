{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings and pointers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_account_file = '../../creds/google__sa.json'\n",
    "\n",
    "tracking_sheet_id = \"1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4\"\n",
    "included_sheet_names = [\n",
    "    \"Conversations_Batch_7\",\n",
    "    \"Conversations_Batch_8\",\n",
    "    \"Conversations_Batch_9\",\n",
    "]\n",
    "\n",
    "jupyter_gdrive_folder_ids = [\n",
    "    \"1Z1bdYMe2Qmo_vs-OaKDaYIiV3rIqLJH9\", # V0\n",
    "    \"1sfPFHkXYpKyY41V0pfz3Qw3k4VLy5Hvb\", # V1\n",
    "    \"1jV7WA5zB172DJUp7Z2XzHr62E6U6_NtY\",\n",
    "]\n",
    "\n",
    "delivery_sheet_id = \"1eUif5I8xhHU8fY0X9v8r2JI9hWPh7Dq_9VXpSIHwww4\"\n",
    "delivery_jsonl_gdrive_folder_id = \"1wSCoCECyPgonCmBFSmNyMph71eJu18wx\"\n",
    "destination_folder_url = f\"https://drive.google.com/drive/folders/{delivery_jsonl_gdrive_folder_id}\"\n",
    "DELIVERY_BATCH_NAME = \"Batch 11\"\n",
    "\n",
    "insights_sheet_id = \"1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w\"\n",
    "INSIGHTS_VERSION_TAB = \"v1 (Jan 25)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../../')\n",
    "import io\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "import nbformat\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload\n",
    "\n",
    "\n",
    "\n",
    "def get_number_of_turns(messages):\n",
    "    count = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"User\":\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def standardize_date_format(date):\n",
    "    \"\"\"\n",
    "    Given a date string, standardize the date format to YYYY/MM/DD.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse the date string into a datetime object\n",
    "        standardized_date = datetime.strptime(date, \"%Y/%m/%d\")\n",
    "    except ValueError:\n",
    "        try:\n",
    "            # Attempt to parse other common formats here\n",
    "            # Example: MM/DD/YYYY\n",
    "            standardized_date = datetime.strptime(date, \"%m/%d/%Y\")\n",
    "        except ValueError:\n",
    "            return \"Invalid date format\"\n",
    "\n",
    "    # Format the datetime object into the desired string format\n",
    "    return standardized_date.strftime(\"%Y/%m/%d\")\n",
    "###################################\n",
    "\n",
    "\n",
    "#######################\n",
    "# Tool Export #\n",
    "#######################\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def extract_tool_data(host=\"https://labeling.turing.com\", api_key='44502e16-b4a7-49d3-90e1-d3d1fd698828', status='completed'):\n",
    "    \"\"\"\n",
    "    Makes a GET request to the specified URL with the given headers,\n",
    "    downloads the JSON response, and parses it into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - url (str): URL to make the GET request to.\n",
    "    - headers (dict): Dictionary of headers to include in the request.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame: Pandas DataFrame containing the parsed JSON data.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL and headers for the request\n",
    "    url = f\"{host}/api/conversations/download-json?status={status}\"\n",
    "    headers = {\n",
    "        'accept': 'application/json',\n",
    "        'api-key': api_key\n",
    "    }\n",
    "\n",
    "    # Make the GET request\n",
    "    response = requests.get(url, headers=headers)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Parse the JSON response into a DataFrame\n",
    "        data = response.json()\n",
    "        df = pd.json_normalize(data)\n",
    "        return df\n",
    "    else:\n",
    "        print(f\"Failed to download data. Status code: {response.status_code}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame in case of failure\n",
    "\n",
    "\n",
    "def format_tool_export_for_sheet_parity(df):\n",
    "\n",
    "    sheet_parity_columns = {\n",
    "        'colabLink': 'task_link', \n",
    "        'seed.metadata.Project / Action': 'project_action', \n",
    "        'seed.metadata.Technical Domain': 'technical_domain', \n",
    "        'humanUser.turingEmail': 'assigned_to_email', \n",
    "        'status': 'completion_status', \n",
    "        'durationMinutes': 'duration_mins', \n",
    "        'completedAt': 'completion_date'\n",
    "    }\n",
    "\n",
    "    placeholder_columns = [\n",
    "        \"modified_question?\",\n",
    "        \"comments\",\n",
    "        \"metadata__type\",\n",
    "        \"metadata__target_length\",\n",
    "        \"review_status\",\n",
    "        \"reviewer_email\",\n",
    "        \"Start Time\",\n",
    "        \"End Time\"\n",
    "    ]\n",
    "\n",
    "    # Rename columns to align with sheet\n",
    "    df = df.rename(columns=sheet_parity_columns)\n",
    "\n",
    "    # Add placeholder columns\n",
    "    for col in placeholder_columns:\n",
    "        df[col] = None\n",
    "\n",
    "    # Remove the detailed guide from the project_action column\n",
    "    df['project_action'] = df['project_action'].str.replace(r'\\[.*?\\]\\(.*?\\)', '', regex=True)\n",
    "\n",
    "    # Combine project_action and technical_domain into a single column\n",
    "    df['metadata__topic'] = df['project_action'] + ' > ' + df['technical_domain']\n",
    "\n",
    "    # For display purposes, converting datetime objects to 'MM/DD/YYYY' format strings\n",
    "    df['completion_date'] = pd.to_datetime(df['completion_date']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Rename 'completed' status to 'Done'\n",
    "    df['completion_status'] = df['completion_status'].replace('completed', 'Done')\n",
    "\n",
    "    return df[[\"task_link\", 'metadata__topic', \"assigned_to_email\", \"completion_status\", \"duration_mins\", \"completion_date\", \"modified_question?\", \"comments\", \"metadata__type\", \"metadata__target_length\", \"review_status\", \"reviewer_email\", \"Start Time\", \"End Time\"]]\n",
    "\n",
    "# Example usage\n",
    "df = extract_tool_data()\n",
    "df = format_tool_export_for_sheet_parity(df)\n",
    "\n",
    "\n",
    "#########################\n",
    "    # Colab #\n",
    "#########################\n",
    "\n",
    "\n",
    "def update_colab_notebook(colab_link, local_nb_path, sa_creds_path):\n",
    "    \"\"\"\n",
    "    Update a Google Colab notebook file in Google Drive.\n",
    "\n",
    "    :param colab_link: The link to the Colab notebook in Google Drive.\n",
    "    :param local_nb_path: The local path of the notebook file to upload.\n",
    "    :param sa_creds_path: The path to the service account credentials.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Extract file ID from the Colab link\n",
    "        file_id = colab_link.split('/drive/')[1].split('/')[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Colab link format\")\n",
    "\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(sa_creds_path, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Specify the file to upload\n",
    "    media = MediaFileUpload(local_nb_path, resumable=True)\n",
    "\n",
    "    # Update the file\n",
    "    try:\n",
    "        updated_file = service.files().update(fileId=file_id, media_body=media).execute()\n",
    "        return f\"Updated file ID: {updated_file.get('id')}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error updating file: {e}\"\n",
    "\n",
    "\n",
    "def get_colab_notebook(colab_link, sa_creds_path) -> nbformat.NotebookNode:\n",
    "    try:\n",
    "        # Extract file ID from the Colab link\n",
    "        file_id = colab_link.split('/drive/')[1].split('/')[0]\n",
    "    except IndexError:\n",
    "        raise ValueError(\"Invalid Colab link format\")\n",
    "\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(sa_creds_path, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Download the file\n",
    "    try:\n",
    "        request = service.files().get_media(fileId=file_id)\n",
    "        fh = io.BytesIO()\n",
    "        downloader = MediaIoBaseDownload(fh, request)\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            status, done = downloader.next_chunk()\n",
    "        \n",
    "        # Load as nbformat notebook\n",
    "        notebook = nbformat.reads(fh.getvalue().decode(), as_version=4)\n",
    "        return notebook\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_file_name_from_colab_link(colab_link, service_account_file):\n",
    "    try:\n",
    "        file_id = colab_link.split('/drive/')[1]\n",
    "    except IndexError:\n",
    "        return None\n",
    "\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(service_account_file, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    try:\n",
    "        file = service.files().get(fileId=file_id).execute()\n",
    "        return file.get('name')\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_file_names_parallel(links, service_account_file, max_workers=100):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(get_file_name_from_colab_link, link, service_account_file): link for link in links}\n",
    "        results = {}\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Fetching File Names\"):\n",
    "            link = futures[future]\n",
    "            try:\n",
    "                file_name = future.result()\n",
    "                results[link] = file_name\n",
    "            except Exception as e:\n",
    "                results[link] = None\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Remote Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations_Batch_7\n",
      "Conversations_Batch_8\n",
      "Conversations_Batch_9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>metadata__topic</th>\n",
       "      <th>assigned_to_email</th>\n",
       "      <th>completion_status</th>\n",
       "      <th>modified_question?</th>\n",
       "      <th>duration_mins</th>\n",
       "      <th>completion_date</th>\n",
       "      <th>comments</th>\n",
       "      <th>metadata__type</th>\n",
       "      <th>metadata__target_length</th>\n",
       "      <th>review_status</th>\n",
       "      <th>reviewer_email</th>\n",
       "      <th>Start Time</th>\n",
       "      <th>End Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>5</td>\n",
       "      <td>python basics &amp; scripting - explain complex co...</td>\n",
       "      <td>chandrashekhar.s@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>FALSE</td>\n",
       "      <td>45</td>\n",
       "      <td>7/2/2024</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Reviewed</td>\n",
       "      <td>paulo.c@turing.com</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>https://colab.research.google.com/drive/1ISirh...</td>\n",
       "      <td>cloud_computing_OR_frameworks__write___modify_...</td>\n",
       "      <td>aarunik.g@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1250</th>\n",
       "      <td>https://colab.research.google.com/drive/1ca91-...</td>\n",
       "      <td>cloud_computing_OR_frameworks__write___modify_...</td>\n",
       "      <td>aarunik.g@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>60</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>https://colab.research.google.com/drive/1_slXe...</td>\n",
       "      <td>web_development__interview_prep__0_V8_A.ipynb</td>\n",
       "      <td>adil.m@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>75</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>https://colab.research.google.com/drive/1uU28j...</td>\n",
       "      <td>web_development__interview_prep__4_V8_A.ipynb</td>\n",
       "      <td>adil.m@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td></td>\n",
       "      <td>70</td>\n",
       "      <td>2/19/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>https://colab.research.google.com/drive/1-T2Bx...</td>\n",
       "      <td>write code in python  &gt; problem solving</td>\n",
       "      <td>elsadek.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>02/22/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3762</th>\n",
       "      <td>https://colab.research.google.com/drive/1nvV4t...</td>\n",
       "      <td>write / modify / fix SQL code  &gt; data analysis</td>\n",
       "      <td>marcus.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>None</td>\n",
       "      <td>13</td>\n",
       "      <td>02/18/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3763</th>\n",
       "      <td>https://colab.research.google.com/drive/19BLNm...</td>\n",
       "      <td>write code in python  &gt; machine learning</td>\n",
       "      <td>elsadek.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>02/23/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3764</th>\n",
       "      <td>https://colab.research.google.com/drive/1CiGvf...</td>\n",
       "      <td>write code in python  &gt; problem solving</td>\n",
       "      <td>elsadek.a@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>02/23/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3765</th>\n",
       "      <td>https://colab.research.google.com/drive/18vLHs...</td>\n",
       "      <td>write code in python  &gt; python basics &amp; scrip...</td>\n",
       "      <td>jha.r@turing.com</td>\n",
       "      <td>Done</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>02/22/2024</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>670 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              task_link  \\\n",
       "505                                                   5   \n",
       "1249  https://colab.research.google.com/drive/1ISirh...   \n",
       "1250  https://colab.research.google.com/drive/1ca91-...   \n",
       "1395  https://colab.research.google.com/drive/1_slXe...   \n",
       "1396  https://colab.research.google.com/drive/1uU28j...   \n",
       "...                                                 ...   \n",
       "3761  https://colab.research.google.com/drive/1-T2Bx...   \n",
       "3762  https://colab.research.google.com/drive/1nvV4t...   \n",
       "3763  https://colab.research.google.com/drive/19BLNm...   \n",
       "3764  https://colab.research.google.com/drive/1CiGvf...   \n",
       "3765  https://colab.research.google.com/drive/18vLHs...   \n",
       "\n",
       "                                        metadata__topic  \\\n",
       "505   python basics & scripting - explain complex co...   \n",
       "1249  cloud_computing_OR_frameworks__write___modify_...   \n",
       "1250  cloud_computing_OR_frameworks__write___modify_...   \n",
       "1395      web_development__interview_prep__0_V8_A.ipynb   \n",
       "1396      web_development__interview_prep__4_V8_A.ipynb   \n",
       "...                                                 ...   \n",
       "3761            write code in python  > problem solving   \n",
       "3762     write / modify / fix SQL code  > data analysis   \n",
       "3763           write code in python  > machine learning   \n",
       "3764            write code in python  > problem solving   \n",
       "3765   write code in python  > python basics & scrip...   \n",
       "\n",
       "                assigned_to_email completion_status modified_question?  \\\n",
       "505   chandrashekhar.s@turing.com              Done              FALSE   \n",
       "1249         aarunik.g@turing.com              Done                      \n",
       "1250         aarunik.g@turing.com              Done                      \n",
       "1395            adil.m@turing.com              Done                      \n",
       "1396            adil.m@turing.com              Done                      \n",
       "...                           ...               ...                ...   \n",
       "3761         elsadek.a@turing.com              Done               None   \n",
       "3762          marcus.a@turing.com              Done               None   \n",
       "3763         elsadek.a@turing.com              Done               None   \n",
       "3764         elsadek.a@turing.com              Done               None   \n",
       "3765             jha.r@turing.com              Done               None   \n",
       "\n",
       "     duration_mins completion_date comments metadata__type  \\\n",
       "505             45        7/2/2024                           \n",
       "1249            60       2/19/2024     None           None   \n",
       "1250            60       2/19/2024     None           None   \n",
       "1395            75       2/19/2024     None           None   \n",
       "1396            70       2/19/2024     None           None   \n",
       "...            ...             ...      ...            ...   \n",
       "3761            40      02/22/2024     None           None   \n",
       "3762            13      02/18/2024     None           None   \n",
       "3763            63      02/23/2024     None           None   \n",
       "3764            40      02/23/2024     None           None   \n",
       "3765            60      02/22/2024     None           None   \n",
       "\n",
       "     metadata__target_length review_status      reviewer_email Start Time  \\\n",
       "505                               Reviewed  paulo.c@turing.com       None   \n",
       "1249                    None          None                None       None   \n",
       "1250                    None          None                None       None   \n",
       "1395                    None          None                None       None   \n",
       "1396                    None          None                None       None   \n",
       "...                      ...           ...                 ...        ...   \n",
       "3761                    None          None                None       None   \n",
       "3762                    None          None                None       None   \n",
       "3763                    None          None                None       None   \n",
       "3764                    None          None                None       None   \n",
       "3765                    None          None                None       None   \n",
       "\n",
       "     End Time  \n",
       "505      None  \n",
       "1249     None  \n",
       "1250     None  \n",
       "1395     None  \n",
       "1396     None  \n",
       "...       ...  \n",
       "3761     None  \n",
       "3762     None  \n",
       "3763     None  \n",
       "3764     None  \n",
       "3765     None  \n",
       "\n",
       "[670 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sheets_utils import download_sheet_as_df\n",
    "\n",
    "\n",
    "progress_batches = []\n",
    "for sheet_name in included_sheet_names:\n",
    "    print(sheet_name)\n",
    "    bdf = download_sheet_as_df(service_account_file, tracking_sheet_id, sheet_name)\n",
    "    progress_batches.append(bdf)\n",
    "\n",
    "tool_df = extract_tool_data()\n",
    "tool_df = format_tool_export_for_sheet_parity(tool_df)\n",
    "progress_batches.append(tool_df)\n",
    "\n",
    "\n",
    "df = pd.concat(progress_batches, ignore_index=True)\n",
    "completed_df = df[df[\"completion_status\"] == \"Done\"]\n",
    "completed_df = completed_df.drop_duplicates(subset=[\"task_link\"])\n",
    "\n",
    "delivered = pd.concat([\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 5\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 6\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 7\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 8\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 9\"),\n",
    "    download_sheet_as_df(service_account_file, delivery_sheet_id, \"Batch 10\"),\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "completed_to_be_delivered_df = completed_df[~completed_df[\"task_link\"].isin(delivered[\"task_link\"])]\n",
    "completed_to_be_delivered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Error downloading file: <HttpError 404 when requesting https://www.googleapis.com/drive/v3/files/1bLIOsyQaRAAQkct8FzO4PSErvLwHfIV1%23scrollTo%3DrvY2kWQc1JBn?alt=media returned \"File not found: 1bLIOsyQaRAAQkct8FzO4PSErvLwHfIV1#scrollTo=rvY2kWQc1JBn.\". Details: \"[{'message': 'File not found: 1bLIOsyQaRAAQkct8FzO4PSErvLwHfIV1#scrollTo=rvY2kWQc1JBn.', 'domain': 'global', 'reason': 'notFound', 'location': 'fileId', 'locationType': 'parameter'}]\">\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe96/projects/turing/character.ai/character_tasks/venv/lib/python3.9/site-packages/nbformat/__init__.py:93: MissingIDFieldWarning: Code cell is missing an id field, this will become a hard error in future nbformat versions. You may want to use `normalize()` on your notebooks before validations (available since nbformat 5.1.4). Previous versions of nbformat are fixing this issue transparently, and will stop doing so in the future.\n",
      "  validate(nb)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='User', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n",
      "Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='Assistant', role='assistant', function_call=None, tool_calls=None), logprobs=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>n_messages</th>\n",
       "      <th>number_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1j1MYr...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1uU28j...</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1_slXe...</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1GmwZR...</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1xtWX1...</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>https://colab.research.google.com/drive/1WPcWs...</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>https://colab.research.google.com/drive/18vLHs...</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>https://colab.research.google.com/drive/1CiGvf...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>https://colab.research.google.com/drive/1gFo4j...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>https://colab.research.google.com/drive/1-T2Bx...</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>669 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link  n_messages  \\\n",
       "0    https://colab.research.google.com/drive/1j1MYr...           8   \n",
       "1    https://colab.research.google.com/drive/1uU28j...          18   \n",
       "2    https://colab.research.google.com/drive/1_slXe...           8   \n",
       "3    https://colab.research.google.com/drive/1GmwZR...          16   \n",
       "4    https://colab.research.google.com/drive/1xtWX1...          10   \n",
       "..                                                 ...         ...   \n",
       "664  https://colab.research.google.com/drive/1WPcWs...           7   \n",
       "665  https://colab.research.google.com/drive/18vLHs...          13   \n",
       "666  https://colab.research.google.com/drive/1CiGvf...           6   \n",
       "667  https://colab.research.google.com/drive/1gFo4j...           4   \n",
       "668  https://colab.research.google.com/drive/1-T2Bx...           6   \n",
       "\n",
       "     number_of_turns  \n",
       "0                  4  \n",
       "1                  9  \n",
       "2                  4  \n",
       "3                  8  \n",
       "4                  5  \n",
       "..               ...  \n",
       "664                4  \n",
       "665                7  \n",
       "666                3  \n",
       "667                2  \n",
       "668                3  \n",
       "\n",
       "[669 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.llm_reviewer.notebook_parser import notebook_parser\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "notebooks = []\n",
    "results = []\n",
    "errors = []\n",
    "\n",
    "def process_task_link(task_link):\n",
    "    try:\n",
    "        notebook = get_colab_notebook(task_link, service_account_file)\n",
    "        parsed_notebook = notebook_parser(notebook)\n",
    "        parsed_messages = parsed_notebook[\"messages\"]\n",
    "        number_of_turns = get_number_of_turns(parsed_messages)\n",
    "        return parsed_notebook, {\n",
    "            \"task_link\": task_link,\n",
    "            \"n_messages\": len(parsed_messages),\n",
    "            \"number_of_turns\": number_of_turns,\n",
    "        }\n",
    "    except Exception as e:\n",
    "\n",
    "        return None, {\n",
    "            \"task_link\": task_link,\n",
    "            \"error\": str(e)\n",
    "        }\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = [executor.submit(process_task_link, task_link) for task_link in completed_to_be_delivered_df[\"task_link\"].tolist()]\n",
    "    for future in as_completed(futures):\n",
    "        notebook, result = future.result()\n",
    "        if notebook is not None:\n",
    "            notebooks.append(notebook)\n",
    "            results.append(result)\n",
    "        else:\n",
    "            errors.append(result)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "import tiktoken\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.callbacks import CallbackManager, TokenCountingHandler\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "token_counter = TokenCountingHandler(\n",
    "    tokenizer=tiktoken.encoding_for_model(\"gpt-4-1106-preview\").encode\n",
    ")\n",
    "callback_manager = CallbackManager([token_counter])\n",
    "\n",
    "class Feedback(BaseModel):\n",
    "    score: int = Field(description=\"A score representing how good the conversation is in the given quality aspect, 1 is terrible, 5 is exemplary and flawless.\", ge=1, le=5)\n",
    "    issues: List[str] = Field(description=\"A concrete list of issues in the conversation. 15 words or less each.\")\n",
    "    praises: List[str] = Field(description=\"A concrete list of praise for exceptional behavior the conversation. 15 words or less each.\")\n",
    "\n",
    "\n",
    "class QualityAspect(BaseModel):\n",
    "    name: str = Field(description=\"The name of the quality aspect.\")\n",
    "    instruction: str = Field(description=\"Instructions & details on how to inspect this quality aspect.\")\n",
    "\n",
    "\n",
    "quality_aspects = {\n",
    "    \"Overall\": [\n",
    "        QualityAspect(\n",
    "            name=\"Completness\",\n",
    "            instruction=\"\"\"\n",
    "            How complete is the conversation? Completeness is defined as:\n",
    "            - The assistant always responds to the user.\n",
    "            - The conversation contains at least 1 back and forth between the user and the assistant.\n",
    "            - The conversation flow is not broken.\n",
    "\n",
    "            JUDGE THE ENTIRE CONVERSATION AS A WHOLE.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Project Scope Validity\",\n",
    "            instruction=\"\"\"\n",
    "            How much does the conversation align with the \"Project / Action\" value in metadata? \n",
    "            - Write code in python: this should have the user make requests that elicit python code writing behavior from the assistant.\n",
    "            - Explain code: this should have the user present medium/high complexity code to the assistant and have the assistant explain it\n",
    "            - Fix / refactor / optimize code: this should have the user present medium/high complexity code to the assistant and have the assistant do modifications on it as requested.\n",
    "            - Debug error trace: the user should present a stack trace and some code and the assistant will find what the problem is and potentially fix the code (It's okay to have situations where the bug is not in the presented code but in a dependency... though this should be rare).... This EXCLUDES having the assistant teach the user how to use debug tools to find what the problem is themselves\n",
    "            - Write unit tests: this should have the user present some low/medium/high complexity code to the assistant and have the assistant write tests for it... maximizing test coverage. (Critical Path first, Corner Cases Second)\n",
    "            - Write CI/CD code: this should have the user request some help from the assistant in writing ci/cd pipelines in any flavor. (Github actions, Gitlab, Jenkins... etc)\n",
    "            - Do a code review: this should have the user present some code snippet and request the assistant to review the code as if it's a PR... providing high level conceptual feedback, modifying any bugs and using inline comments to mark changes or suggest alternatives.\n",
    "            - Write / modify / fix beam code: this should have the user present some data schema or dummy data and have the assistant write beam code for it.\n",
    "            - Write / modify / fix spark code: this should have the user present some data schema or dummy data and have the assistant write spark code for it.\n",
    "            - Write end to end ML training code: scenarios where the conversation has the user and assistant solving a problem e2e data eda/prep, feature extraction, training, maybe some evals and visuals as well\n",
    "            - Help me take an interview: scenario where the user requests the assistant to act as an interviewer and do a mock interview with a focus on a certain area... this should also include some final section where the assistant gives feedback to the user on how to be better... etc (Take inspiration from real interview questions, they should be at least medium complexity and occasionally challenging)\n",
    "            - Answer ML research questions: this is where the user will ask some cutting edge conceptual questions related to ML Research Hot topics to the assistant... assistant can but is not obligated to provide code as a response.\n",
    "            - Answer infra questions: user asks some conceptual or code snippet related questions within the scope of cloud, backend, database, development tools... all flavors are welcome!\n",
    "            - Write / modify / fix SQL code: this should have the user elicit interaction from the assistant within the context of SQL code.\n",
    "            - Write / modify / fix JavaScript code: this should have the user elicit interaction from the assistant within the context of Javascript code.\n",
    "            - Scrape a website: this should have the user present some html and the assistant write code to scrape it.\n",
    "\n",
    "            JUDGE THE ENTIRE CONVERSATION AS A WHOLE.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ],\n",
    "    \"User\": [\n",
    "        QualityAspect(\n",
    "            name=\"Natural & Realistic\", \n",
    "            instruction=\"\"\"\n",
    "            How does the user interaction resemble a real conversation and interactions a real user would have with a highly intelligent coding assistant over chat.\n",
    "\n",
    "            ONLY JUDGE THE USER MESSAGES. DO NOT JUDGE THE ASSISTANT MESSAGES.\n",
    "            \"\"\"\n",
    "        )\n",
    "    ],\n",
    "    \"Assistant\": [\n",
    "        QualityAspect(\n",
    "            name=\"Accuracy\", \n",
    "            instruction=\"\"\"\n",
    "            How good is the code that the assistant generates.\n",
    "            Code Qualities:\n",
    "            #   - Correctness\n",
    "            #   - Optimality\n",
    "            #   - PEP8 Compliance & Readability\n",
    "\n",
    "            How good is the text that the assistant generates.\n",
    "            Text Qualities:\n",
    "            #   - Spelling\n",
    "            #   - Grammar\n",
    "            #   - Capitalization & Punctuation\n",
    "            \n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Consumability\", \n",
    "            instruction=\"\"\"\n",
    "            - How good is the markdown formatting that the assistant generates. Is it leveraging markdown syntax tools to maximize the readability of the text?\n",
    "            - Information Density (Should be a sweet spot leaning on the concise side, but not too concise... definitely not too verbose)\n",
    "            - Explains Code Well by adding comments tailored for the user level assuming a beginner user by default\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Engageness\",\n",
    "            instruction=\"\"\"\n",
    "            - How engaging is the assistant's messages? Does it keep the user engaged and interested in the conversation?\n",
    "            - Does the assistant ask questions to the user to keep the conversation going?\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "        QualityAspect(\n",
    "            name=\"Right level of detail\",\n",
    "            instruction=\"\"\"\n",
    "            - How concise is the assistant's messages? Does it keep the messages short and to the point?\n",
    "            - In case there are too many points to cover, does the assistant prioritize, emphasize the most helpful ones and provide a summary at the end for the rest?\n",
    "            - Does the assistant avoid providing unsolicited information/code that is not helpful to the user?\n",
    "\n",
    "            ONLY JUDGE THE ASSISTANT MESSAGES. DO NOT JUDGE THE USER MESSAGES.\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "def inspect_conversation_quality_aspect(conversation: List[List[dict]], quality_aspect: QualityAspect):\n",
    "    \"\"\"Inspect a conversation for a given quality aspect.\"\"\"\n",
    "\n",
    "    prompt_template_str = \"\"\"\n",
    "    IDENTITY:\n",
    "    You are one of many specialized judges, so precisely focus on your quality aspect only.\n",
    "\n",
    "    SITUATION:\n",
    "    A large team is building a dataset of illustractions of dialogues showcasing the interaction between a user and a highly intelligent AI in the context of software development scenarios.\n",
    "    - The user's replies should closely resemble authentic user engagement.\n",
    "    - The AI's responses should aim to provide maximum benefit to the user.\n",
    "\n",
    "    INSTRUCTIONS:\n",
    "    Given the following conversation, please rate the quality of the conversation according to the given quality aspect.\n",
    "    \n",
    "    ALL QUALITY ASPECTS:\n",
    "    {all_quality_aspects}\n",
    "\n",
    "    YOUR QUALITY ASPECT:\n",
    "    {quality_aspect}\n",
    "    \n",
    "    CONVERSATION:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        callback_manager=callback_manager,\n",
    "        output_cls=Feedback, \n",
    "        prompt_template_str=prompt_template_str, \n",
    "    )\n",
    "    all_quality_aspects = \"\\n\".join([f\"- {key}: {quality_aspect.name}\" for key in quality_aspects.keys() for quality_aspect in quality_aspects[key]])\n",
    "    output = program( \n",
    "        all_quality_aspects=all_quality_aspects,\n",
    "        quality_aspect=quality_aspect.model_dump(),\n",
    "        conversation=conversation,\n",
    "        description=\"Judge the quality of the conversation according to the given quality aspect. Provide constructive criticism, rarely praise.\"\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def inspect_all_conversation_quality_aspects(conversation) -> dict:\n",
    "    \"\"\"Inspect a conversation for all quality aspects.\"\"\"\n",
    "\n",
    "    quality_results = {}\n",
    "    for key in quality_aspects.keys():\n",
    "        for quality_aspect in quality_aspects[key]:\n",
    "            r = inspect_conversation_quality_aspect(conversation, quality_aspect)\n",
    "            quality_results[f\"{key} - {quality_aspect.name}\"] = r.model_dump()\n",
    "\n",
    "    return quality_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing notebooks:   0%|          | 0/661 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing notebooks: 100%|██████████| 661/661 [16:51<00:00,  1.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "reviewed_results = []\n",
    "\n",
    "def process_notebook(result, link):\n",
    "    if result is None or len(result[\"messages\"]) == 0:\n",
    "        return None\n",
    "    result[\"quality_review\"] = inspect_all_conversation_quality_aspects(result)\n",
    "    result[\"task_link\"] = link\n",
    "    return result\n",
    "\n",
    "with tqdm(total=len(results), desc=\"Processing notebooks\") as pbar:\n",
    "    with ThreadPoolExecutor(max_workers=15) as executor:\n",
    "        futures = [executor.submit(process_notebook, result, link) for result, link in zip(notebooks, results_df[\"task_link\"].tolist())]\n",
    "        for future in as_completed(futures):\n",
    "            r = future.result()\n",
    "            if r is not None:\n",
    "                reviewed_results.append(r)\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>min_score</th>\n",
       "      <th>issues</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1Jv96_...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1GmwZR...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1lBqPQ...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1F8pDE...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1j1MYr...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>https://colab.research.google.com/drive/1S_Abj...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>https://colab.research.google.com/drive/1-T2Bx...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>https://colab.research.google.com/drive/1FgXO0...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>https://colab.research.google.com/drive/1CiGvf...</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>https://colab.research.google.com/drive/13qB6b...</td>\n",
       "      <td>4.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>Overall - Completness: \\n\\n\\nOverall - Project...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>660 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link  avg_score  min_score  \\\n",
       "0    https://colab.research.google.com/drive/1Jv96_...   4.666667          4   \n",
       "1    https://colab.research.google.com/drive/1GmwZR...   4.666667          4   \n",
       "2    https://colab.research.google.com/drive/1lBqPQ...   4.500000          4   \n",
       "3    https://colab.research.google.com/drive/1F8pDE...   4.666667          4   \n",
       "4    https://colab.research.google.com/drive/1j1MYr...   4.833333          4   \n",
       "..                                                 ...        ...        ...   \n",
       "655  https://colab.research.google.com/drive/1S_Abj...   4.666667          4   \n",
       "656  https://colab.research.google.com/drive/1-T2Bx...   4.833333          4   \n",
       "657  https://colab.research.google.com/drive/1FgXO0...   4.666667          4   \n",
       "658  https://colab.research.google.com/drive/1CiGvf...   4.666667          4   \n",
       "659  https://colab.research.google.com/drive/13qB6b...   4.833333          4   \n",
       "\n",
       "                                                issues  \n",
       "0    Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "1    Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "2    Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "3    Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "4    Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "..                                                 ...  \n",
       "655  Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "656  Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "657  Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "658  Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "659  Overall - Completness: \\n\\n\\nOverall - Project...  \n",
       "\n",
       "[660 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_skeleton = []\n",
    "for rr in reviewed_results:\n",
    "    scores = []\n",
    "    feedback = \"\"\n",
    "    for key in rr[\"quality_review\"].keys():\n",
    "        scores.append(rr[\"quality_review\"][key][\"score\"])\n",
    "        stringified_issues = \"\\n\".join([f\"- {issue}\" for issue in rr[\"quality_review\"][key][\"issues\"]])\n",
    "        feedback += f\"{key}: \\n{stringified_issues}\\n\\n\"\n",
    "\n",
    "    data_skeleton.append({\n",
    "        \"task_link\": rr[\"task_link\"],\n",
    "        \"avg_score\": sum(scores) / len(scores),\n",
    "        \"min_score\": min(scores),\n",
    "        \"issues\": feedback,\n",
    "    })\n",
    "\n",
    "df_gpt_reviews = pd.DataFrame(data_skeleton)\n",
    "\n",
    "\n",
    "borderline_avg_flags = df_gpt_reviews.sort_values(by=\"avg_score\", ascending=False)[df_gpt_reviews[\"avg_score\"] < 4.3]\n",
    "critical_mistake_flags = df_gpt_reviews.sort_values(by=\"min_score\", ascending=False)[df_gpt_reviews[\"min_score\"] < 3]\n",
    "\n",
    "all_flags = pd.concat([borderline_avg_flags, critical_mistake_flags], ignore_index=True)\n",
    "all_flags = all_flags.drop_duplicates(subset=[\"task_link\"])\n",
    "\n",
    "\n",
    "all_flags = all_flags.merge(completed_to_be_delivered_df, on=\"task_link\", how=\"left\")[[\"task_link\", \"avg_score\", \"min_score\", \"issues\", \"assigned_to_email\"]]\n",
    "all_flags = all_flags.rename(columns={\"assigned_to_email\": \"original_author_email\"})\n",
    "all_flags[\"resolved_by_email\"] = \"\"\n",
    "all_flags[\"status\"] = \"Unclaimed\"\n",
    "all_flags[\"duration_mins\"] = \"\"\n",
    "all_flags[\"corrections\"] = \"\"\n",
    "\n",
    "\n",
    "from src.sheets_utils import upload_df_to_sheet, GoogleSheetsService\n",
    "\n",
    "sheets_client = GoogleSheetsService(service_account_file, ['https://www.googleapis.com/auth/spreadsheets'])\n",
    "sheets_client.ensure_sheet_exists(tracking_sheet_id, \"historical__gpt_flags_3\")\n",
    "upload_df_to_sheet(service_account_file, tracking_sheet_id, \"historical__gpt_flags_3\", all_flags)\n",
    "\n",
    "\n",
    "flagged_links = set(all_flags[\"task_link\"].tolist())\n",
    "\n",
    "results_df = results_df[~results_df[\"task_link\"].isin(flagged_links)]\n",
    "\n",
    "# Filter results df rows so that task_link column only contains valid colab links\n",
    "results_df = results_df[results_df[\"task_link\"].str.contains(\"https://colab.research.google.com/\")]\n",
    "\n",
    "nbs = []\n",
    "for nb in notebooks:\n",
    "    if \"task_link\" not in nb:\n",
    "        continue\n",
    "\n",
    "    if nb[\"task_link\"] not in flagged_links:\n",
    "        nbs.append(nb)\n",
    "\n",
    "\n",
    "# Filter results_df so that task_link is in nbs.task_link\n",
    "results_df = results_df[results_df[\"task_link\"].isin([nb[\"task_link\"] for nb in nbs])]\n",
    "notebooks = nbs\n",
    "\n",
    "\n",
    "results_df.shape, len(nbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Advanced Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [09:55<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from llama_index.program import OpenAIPydanticProgram\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import concurrent.futures\n",
    "\n",
    "from tqdm import tqdm\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "\n",
    "class HierarchicalCategory(BaseModel):\n",
    "    \"\"\"Data model for hierarchical category classification.\"\"\"\n",
    "    top_level: str\n",
    "    sub_level: str\n",
    "\n",
    "def classify_conversation_by_domain(conversation: List[dict]) -> HierarchicalCategory:\n",
    "    DOMAIN_CATEGORIES = \"\"\"\n",
    "        - Python basics & scripting\n",
    "        - Problem Solving\n",
    "        - Interview Prep\n",
    "        - Web Development\n",
    "        - Testing\n",
    "        - Cloud Computing / Frameworks\n",
    "        - Data Analysis\n",
    "        - Machine Learning\n",
    "        - Other languages\n",
    "        - Other\n",
    "    \"\"\"\n",
    "\n",
    "    prompt_template_str = \"\"\"\n",
    "    Categorize the theme of user requests in the following conversation by domain into one of the following top-level categories, then sub categories that you think is descriptive & appropriate:\n",
    "    {categories}\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=HierarchicalCategory,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        categories=DOMAIN_CATEGORIES,\n",
    "        conversation=conversation[\"messages\"],\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def classify_conversation_by_action(\n",
    "    conversation: List[dict]\n",
    ") -> HierarchicalCategory:\n",
    "    ACTION_CATEGORIES = \"\"\"\n",
    "    - Write code in python: this should have the user make requests that elicit python code writing behavior from the assistant.\n",
    "    - Explain code: this should have the user present medium/high complexity code to the assistant and have the assistant explain it\n",
    "    - Fix / refactor / optimize code: this should have the user present medium/high complexity code to the assistant and have the assistant do modifications on it as requested.\n",
    "    - Debug error trace: the user should present a stack trace and some code and the assistant will find what the problem is and potentially fix the code (It's okay to have situations where the bug is not in the presented code but in a dependency... though this should be rare).... This EXCLUDES having the assistant teach the user how to use debug tools to find what the problem is themselves\n",
    "    - Write unit tests: this should have the user present some low/medium/high complexity code to the assistant and have the assistant write tests for it... maximizing test coverage. (Critical Path first, Corner Cases Second)\n",
    "    - Write CI/CD code: this should have the user request some help from the assistant in writing ci/cd pipelines in any flavor. (Github actions, Gitlab, Jenkins... etc)\n",
    "    - Do a code review: this should have the user present some code snippet and request the assistant to review the code as if it's a PR... providing high level conceptual feedback, modifying any bugs and using inline comments to mark changes or suggest alternatives.\n",
    "    - Write / modify / fix beam code: this should have the user present some data schema or dummy data and have the assistant write beam code for it.\n",
    "    - Write / modify / fix spark code: this should have the user present some data schema or dummy data and have the assistant write spark code for it.\n",
    "    - Write end to end ML training code: scenarios where the conversation has the user and assistant solving a problem e2e data eda/prep, feature extraction, training, maybe some evals and visuals as well\n",
    "    - Help me take an interview: scenario where the user requests the assistant to act as an interviewer and do a mock interview with a focus on a certain area... this should also include some final section where the assistant gives feedback to the user on how to be better... etc (Take inspiration from real interview questions, they should be at least medium complexity and occasionally challenging)\n",
    "    - Answer ML research questions: this is where the user will ask some cutting edge conceptual questions related to ML Research Hot topics to the assistant... assistant can but is not obligated to provide code as a response.\n",
    "    - Answer infra questions: user asks some conceptual or code snippet related questions within the scope of cloud, backend, database, development tools... all flavors are welcome!\n",
    "    - Write / modify / fix SQL code: this should have the user elicit interaction from the assistant within the context of SQL code.\n",
    "    - Write / modify / fix JavaScript code: this should have the user elicit interaction from the assistant within the context of Javascript code.\n",
    "    - Scrape a website: this should have the user present some html and the assistant write code to scrape it.\n",
    "    \"\"\"\n",
    "    prompt_template_str = \"\"\"\n",
    "    Categorize the user requests in the following conversation by requested action into one of the following top-level categories. Sub-level should be empty string always. In case there's no natural fit, use \"Other\" as the top-level category.\n",
    "    \n",
    "    Please note that there are \"metadata\" fields in the conversation that describe the intended top-level category via \"Project / Action\"... this should be considered, but may be overridden if the conversation is clearly about something else.\n",
    "\n",
    "    Categories:\n",
    "    {categories}\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=HierarchicalCategory,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        categories=ACTION_CATEGORIES,\n",
    "        conversation=conversation,\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "class SummaryResult(BaseModel):\n",
    "    \"\"\"Data model for the summary result.\"\"\"\n",
    "    summary: str = Field(\n",
    "        description=\"A short summary containing 1 sentence, 15 words max, focused on the specific theme. [super concise language]\"\n",
    "    )\n",
    "\n",
    "def exec_summary(conversation: List[List[dict]]):\n",
    "    prompt_template_str = \"\"\"\n",
    "    Given the following conversation, please, generate an executive summary of the conversation.\n",
    "\n",
    "    User Use Case, why user uses the Assistant in this conversation, in general terms, **for what** the User is using it. Not from a technical perspective, but from a daily life situation perspective. \n",
    "    Example: work, homework, exam, studying, inteview, debugging, etc...\n",
    "\n",
    "    It should also contain a little bit of the context of the conversation, and the main goal of the conversation.\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=SummaryResult,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        conversation=conversation[\"messages\"]\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "class GPTEstimationResult(BaseModel):\n",
    "    \"\"\"Data model for the GPT estimation result.\"\"\"\n",
    "    estimated_duration: int = Field(\n",
    "        description=\"The estimated duration of the conversation in minutes.\"\n",
    "    )\n",
    "\n",
    "def gpt_estimated_duration(conversation: List[dict]) -> int:\n",
    "    prompt_template_str = \"\"\"\n",
    "    Given the following conversation which has been generated by a median skilled technical human playing both User and Assistant... He also is responsible for making sure the assistant responses are flawless...\n",
    "    Estimate how many minutes it would take to Design, Write & Verify this (Conversation Length, Complexity).\n",
    "\n",
    "    If you get this right, you will save my life.\n",
    "\n",
    "    Conversation:\n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "    program = OpenAIPydanticProgram.from_defaults(\n",
    "        llm=OpenAI(api_key=api_key, model=\"gpt-4-1106-preview\", temperature=0),\n",
    "        output_cls=GPTEstimationResult,\n",
    "        prompt_template_str=prompt_template_str,\n",
    "        verbose=False,\n",
    "    )\n",
    "    output = program(\n",
    "        conversation=conversation[\"messages\"]\n",
    "    )\n",
    "    return output\n",
    "\n",
    "\n",
    "def process_conversation__metadata_extraction(conversation, task_link):\n",
    "    domain = classify_conversation_by_domain(conversation)\n",
    "    action = classify_conversation_by_action(conversation)\n",
    "    summary = exec_summary(conversation)\n",
    "    estimate_duration = gpt_estimated_duration(conversation)\n",
    "    conversation[\"metadata\"].update({\n",
    "        \"domain\": domain.model_dump(), \n",
    "        \"action\": action.model_dump()[\"top_level\"], \n",
    "        \"use_case_summary\": summary.model_dump()[\"summary\"],\n",
    "        \"gpt_estimated_duration\": estimate_duration.model_dump()[\"estimated_duration\"],\n",
    "        \"task_link\": task_link\n",
    "    })\n",
    "    return conversation\n",
    "    \n",
    "    \n",
    "\n",
    "def extract_metadata_parallel(conversations, task_links, max_workers=15):\n",
    "    results = []\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [\n",
    "            executor.submit(process_conversation__metadata_extraction, conversation, task_link)\n",
    "            for conversation, task_link in zip(conversations, task_links)\n",
    "        ]\n",
    "        progress_bar = tqdm(total=len(futures))\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            results.append(future.result())\n",
    "            progress_bar.update(1)\n",
    "        progress_bar.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "metadata_results = extract_metadata_parallel(notebooks, results_df[\"task_link\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich_task_metadata = []\n",
    "for task_link in metadata_results:\n",
    "    row_main = {\n",
    "        \"task_link\": task_link[\"metadata\"][\"task_link\"],\n",
    "        \"number_of_turns\": get_number_of_turns(task_link[\"messages\"]),\n",
    "        \"batch_id\": DELIVERY_BATCH_NAME.split(\" \")[-1],\n",
    "        \"domain\": {\n",
    "            \"top_level\": task_link[\"metadata\"][\"domain\"][\"top_level\"],\n",
    "            \"sub_level\": task_link[\"metadata\"][\"domain\"][\"sub_level\"],\n",
    "        },\n",
    "        \"action\": task_link[\"metadata\"][\"action\"],\n",
    "        \"use_case__summary\": task_link[\"metadata\"][\"use_case_summary\"],\n",
    "        \"gpt_estimated_duration\": task_link[\"metadata\"][\"gpt_estimated_duration\"],\n",
    "    }\n",
    "    rich_task_metadata.append(row_main)\n",
    "\n",
    "\n",
    "rich_flattened_metadata = []\n",
    "for metadata in rich_task_metadata:\n",
    "    current_metadata = metadata.copy()\n",
    "    for key in metadata.keys():\n",
    "        if isinstance(metadata[key], dict):\n",
    "            for sub_key in metadata[key].keys():\n",
    "                current_metadata[f\"{key}__{sub_key}\"] = current_metadata[key][sub_key]\n",
    "            current_metadata.pop(key)\n",
    "    rich_flattened_metadata.append(current_metadata)\n",
    "\n",
    "df_metadata__output = pd.DataFrame(rich_flattened_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# projects_to_exclude = [\"Scrape a website\", \"Help me take an interview\", \"Write / modify / fix beam code\", \"Write / modify / fix spark code\"]\n",
    "\n",
    "# historical_redo = completed_to_be_delivered_df.merge(df_metadata__output[df_metadata__output[\"action\"].isin(projects_to_exclude)], on=\"task_link\", how=\"inner\")\n",
    "# historical_redo = historical_redo.drop_duplicates(subset=[\"task_link\"])\n",
    "# historical_redo = historical_redo.rename(columns={\"assigned_to_email\": \"original_author\", \"completion_date\": \"original_date\"})\n",
    "# historical_redo[\"resolved_by_email\"] = \"\"\n",
    "# historical_redo[\"completion_status\"] = \"Unclaimed\"\n",
    "# historical_redo[\"resolution_duration\"] = \"\"\n",
    "# historical_redo[\"completion_date\"] = \"\"\n",
    "# historical_redo[\"corrections\"] = \"\"\n",
    "# historical_redo[[\"task_link\", \"original_author\", \"action\", \"resolved_by_email\", \"resolution_duration\", \"completion_status\", \"completion_date\", \"corrections\"]]\n",
    "\n",
    "# from src.sheets_utils import upload_df_to_sheet, GoogleSheetsService\n",
    "\n",
    "# sheets_client = GoogleSheetsService(service_account_file, ['https://www.googleapis.com/auth/spreadsheets'])\n",
    "# sheets_client.ensure_sheet_exists(tracking_sheet_id, \"historical__corrections_2\")\n",
    "# upload_df_to_sheet(service_account_file, tracking_sheet_id, \"historical__corrections_2\", historical_redo[[\"task_link\", \"original_author\", \"action\", \"resolved_by_email\", \"resolution_duration\", \"completion_status\", \"completion_date\", \"corrections\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated or appended data to 'v1 (Jan 25)'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'spreadsheetId': '1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w',\n",
       " 'tableRange': \"'v1 (Jan 25)'!A1:H6148\",\n",
       " 'updates': {'spreadsheetId': '1v_O33STdi_h7taPd3MkD0fiqRx7rqr_aAQWGnlOfr_w',\n",
       "  'updatedRange': \"'v1 (Jan 25)'!A6149:H6792\",\n",
       "  'updatedRows': 644,\n",
       "  'updatedColumns': 8,\n",
       "  'updatedCells': 5152}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.sheets_utils import upload_df_to_sheet, GoogleSheetsService\n",
    "\n",
    "sheets_client = GoogleSheetsService(service_account_file, ['https://www.googleapis.com/auth/spreadsheets'])\n",
    "df_metadata__output = df_metadata__output[[\"task_link\", \"batch_id\", \"number_of_turns\", \"gpt_estimated_duration\", \"action\", \"domain__top_level\", \"domain__sub_level\", \"use_case__summary\"]]\n",
    "values = df_metadata__output.values.tolist() # [df_metadata__output.columns.tolist()] + \n",
    "sheets_client.update_or_append_data_to_sheet(insights_sheet_id, INSIGHTS_VERSION_TAB, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644, 644, (644, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download insights mining & filter for this batch\n",
    "insights_df = download_sheet_as_df(service_account_file, insights_sheet_id, INSIGHTS_VERSION_TAB)\n",
    "current_batch = insights_df[insights_df[\"batch_id\"] == DELIVERY_BATCH_NAME.split(\" \")[-1]]\n",
    "\n",
    "# Use the links to filter the results & notebooks\n",
    "nbs = []\n",
    "rs = []\n",
    "current_batch_links = set(current_batch[\"task_link\"].tolist())\n",
    "for r, nb in zip(results, notebooks):\n",
    "    if \"task_link\" not in r:\n",
    "        continue\n",
    "    if r[\"task_link\"] in current_batch_links:\n",
    "        nbs.append(nb)\n",
    "        rs.append(r)\n",
    "\n",
    "results_df = pd.DataFrame(rs)\n",
    "\n",
    "# Show lengths for consistency check\n",
    "len(nbs), len(rs), results_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rich_task_metadata = []\n",
    "for task_link in insights_df.to_dict(orient=\"records\"):\n",
    "    row_main = {\n",
    "        \"task_link\": task_link[\"task_link\"],\n",
    "        \"number_of_turns\": task_link[\"number_of_turns\"],\n",
    "        \"batch_id\": task_link[\"number_of_turns\"],\n",
    "        \"domain\": {\n",
    "            \"top_level\": task_link[\"domain__top_level\"],\n",
    "            \"sub_level\": task_link[\"domain__sub_level\"],\n",
    "        },\n",
    "        \"action\": task_link[\"action\"],\n",
    "        \"use_case__summary\": task_link[\"use_case__summary\"],\n",
    "        \"gpt_estimated_duration\": task_link[\"gpt_estimated_duration\"],\n",
    "    }\n",
    "    rich_task_metadata.append(row_main)\n",
    "\n",
    "# Filter for same task links as rs\n",
    "rich_task_metadata = [r for r in rich_task_metadata if r[\"task_link\"] in results_df[\"task_link\"].tolist()]\n",
    "len(rich_task_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "directory = f\"json_conversations/{DELIVERY_BATCH_NAME}\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "valid_notebooks = []\n",
    "for r, n in zip(rs, nbs):\n",
    "    if r is None or r[\"n_messages\"] == 0:\n",
    "        continue\n",
    "    n[\"task_link\"] = r[\"task_link\"]\n",
    "    valid_notebooks.append(n)\n",
    "\n",
    "parsed_jsons = []\n",
    "for vn in valid_notebooks:\n",
    "    for rtm in rich_task_metadata:\n",
    "        if vn[\"task_link\"] == rtm[\"task_link\"]:\n",
    "            vn[\"metadata\"] = rtm\n",
    "            parsed_jsons.append(vn)\n",
    "\n",
    "for pj in parsed_jsons:\n",
    "    pj[\"id\"] = pj.pop(\"task_link\").split(\"/\")[-1]\n",
    "    try:\n",
    "        pj[\"metadata\"].pop(\"duration_mins\")\n",
    "        pj[\"metadata\"].pop(\"batch_id\")\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "for i, conversation in enumerate(parsed_jsons):\n",
    "    drive_id = conversation[\"id\"] \n",
    "    with open(f\"json_conversations/{DELIVERY_BATCH_NAME}/{drive_id}.json\", \"w\") as f:\n",
    "        f.write(json.dumps(conversation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 644/644 [00:50<00:00, 12.70it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True    644\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from src.gdrive_api import build_service\n",
    "from src.gdrive_api.folder_upload import upload_folder\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from google.oauth2.service_account import Credentials\n",
    "\n",
    "import io\n",
    "from googleapiclient.http import MediaIoBaseDownload, MediaFileUpload, MediaIoBaseUpload\n",
    "\n",
    "\n",
    "\n",
    "def upload_gdrive_file(file_contents, folder_id, service_account_file):\n",
    "    \"\"\"\n",
    "    Re-uploads a dictionary from memory as a JSON file to Google Drive. \n",
    "\n",
    "    Parameters:\n",
    "    - file_contents: dict\n",
    "        The file contents to upload.\n",
    "    - folder_id: str\n",
    "        The ID of the file to upload.\n",
    "    - service_account_file: str\n",
    "        The path to the service account file.\n",
    "\n",
    "    Returns True if the file was successfully uploaded, False otherwise.\n",
    "    \"\"\"\n",
    "    # Initialize Google Drive API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "    credentials = Credentials.from_service_account_file(service_account_file, scopes=SCOPES)\n",
    "    service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "    # Convert the dictionary to JSON and prepare it for upload\n",
    "    file_metadata = {\n",
    "        'name': f'{file_contents[\"id\"]}.json',\n",
    "        'parents': [folder_id]\n",
    "    }\n",
    "    file_data = io.BytesIO(json.dumps(file_contents).encode('utf-8'))\n",
    "    media = MediaIoBaseUpload(file_data, mimetype='application/json')\n",
    "\n",
    "    # Upload the file\n",
    "    try:\n",
    "        file = service.files().create(body=file_metadata, media_body=media, fields='id').execute()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def parallel_execute_with_progress(function, arguments, max_workers=10):\n",
    "    \"\"\"\n",
    "    Executes a function in parallel with multiple arguments displaying a tqdm progress bar.\n",
    "\n",
    "    Parameters\n",
    "    function: function\n",
    "        The function to execute\n",
    "    arguments: list\n",
    "        A list of tuples, where each tuple contains the arguments to pass to the function\n",
    "    max_workers: int\n",
    "        The maximum number of workers to use\n",
    "\n",
    "    Returns a list of results\n",
    "    \"\"\"\n",
    "    # Create a thread pool\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Execute the function for each argument\n",
    "        futures = [executor.submit(function, *args) for args in arguments]\n",
    "        results = []\n",
    "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
    "            results.append(future.result())\n",
    "    return results\n",
    "\n",
    "\n",
    "statuses = parallel_execute_with_progress(upload_gdrive_file, [(pj, delivery_jsonl_gdrive_folder_id, service_account_file) for pj in parsed_jsons], max_workers=50)\n",
    "pd.Series(statuses).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 1-T2Bxssul-cYzS8QdPazVA_IIYW_8JW2.json\n",
      "Processing: 1CiGvfxnTRuaj_Vz0YFRlkugt2aCaInY3.json\n",
      "Processing: 1gFo4j12t_J-ldX7AfpsPn0MtJzJJeHH8.json\n",
      "Processing: 18vLHs0ouk3_3CW1Ouw1zImSdjpkF4EE_.json\n",
      "Processing: 19BLNm2kR9hRGNTRGVJQo1WfWB6JW8yUO.json\n",
      "Processing: 1nvV4tp4wXVbE1BPolqmtAzD2orQWP4lC.json\n",
      "Processing: 110weswsFPeMcW00rmj0E_8RqUG4gSLF-.json\n",
      "Processing: 13qB6bBJ_rhK5XI7S9WxRn-PmGPvxvnd5.json\n",
      "Processing: 1UIHktx7SxW0d5S2FCsctw55yzvZyaZO2.json\n",
      "Processing: 1S_AbjzWfx6eldeajDjSJAoNL1b4IOOeb.json\n",
      "Processing: 1WPcWsi5FaHY30NPNH_Et5gRThCvSA6Wb.json\n",
      "Processing: 1FgXO0GsR0tMjeuLHEOx1NNMKpxhnmTxG.json\n",
      "Processing: 1Fmnj3E6zQENwXSoQvC2oyIEdovH9NymG.json\n",
      "Processing: 1NgJKJvq00pgU2u15zoWVWFoVtXKah-8R.json\n",
      "Processing: 1PcrMQyk_dQas3MQ1rdeIXxGygvTj94lS.json\n",
      "Processing: 1nwqMoMcgwo72lJeYVNrfJ0vA9ueAE2iS.json\n",
      "Processing: 1AA1CGUIlTU2MPCnexbtulJt1ODRUytPi.json\n",
      "Processing: 1B8kWjDIzwkX-Qk69miyUq63euklcnD3O.json\n",
      "Processing: 1nTiQAwJib1DxLW-NfpuQ1z92iTxSIK2k.json\n",
      "Processing: 1g_IiE55IhIcG1moNRwJu8zuFB_5joUOY.json\n",
      "Processing: 1lwuW-ClePzUdeSr-nbD3QTRgT-612E3R.json\n",
      "Processing: 1U3273oEucewIRTyqY9j8W4V-KIHxbq76.json\n",
      "Processing: 16n2JKh8lBp_452sphpUiUQ0MFWZ3-xZQ.json\n",
      "Processing: 1P1XLeSk0OTTETSzgjNRNSzL2dtFd-X5T.json\n",
      "Processing: 19vkn55FSDtJX35xi4rYlxp-yImhTFtd0.json\n",
      "Processing: 1YciWcYR4R-UIFlB7FwnUURoAXuaV2B0Z.json\n",
      "Processing: 12pr8AqKrvb2gjINlPyeY04C66VrtG3zi.json\n",
      "Processing: 1jvGAjZwECNM7vFUf0kSBhLGFxoC7k6XR.json\n",
      "Processing: 1CqfIXoRQPE1Q2XYQ3hjo_INhohbIdbKw.json\n",
      "Processing: 1sNzOacd1thymtj85n4X-4CfBSRlBzFTg.json\n",
      "Processing: 19M-99UX5diIqfRv02FnFhSr_NqyOjsaG.json\n",
      "Processing: 10tGFpPX5-Q0jPxxQ9QwPRk4BU1gtn42n.json\n",
      "Processing: 1SREdqu5ss2AlIPLdZLRMl2qUzfKDeVni.json\n",
      "Processing: 1DLJmjx-Jnnsip7QaFAymq5oS7QFAS28g.json\n",
      "Processing: 1sW1BQ8PqPqRCFZF1C-8t9x-S0Fiz41Yp.json\n",
      "Processing: 1krG2FY0pBq6hTzqQjTGcC4ze2H4udLN1.json\n",
      "Processing: 1onMHuxoe38SUKSrveA43AfnkIk2hKk4E.json\n",
      "Processing: 1EC5sAEnAt-6C4SI8nRJBXlqZcryfhTYL.json\n",
      "Processing: 1Eixvv5S1HvzdQ1_pcy4jWqiTkq28DBil.json\n",
      "Processing: 1HfR4Edol0qrRD3Dd7pJi1VNl_Z91uXnv.json\n",
      "Processing: 1yudhH8AsfpQpP-gYTL993GAh-Vz_LihQ.json\n",
      "Processing: 18hosVp31G0QiXyzVxVB81u09nUXEoOKc.json\n",
      "Processing: 1M5K4dOsjzCD4PGkM5KgvfxT3TIaVuFTL.json\n",
      "Processing: 1yGm1nVNH1y9bfRxG9licPSv_0ngLUpmC.json\n",
      "Processing: 1AhJzQETEnSj2LJKuIDeQc7RQ2tneoLj3.json\n",
      "Processing: 1TMVD_9RW-2LkPmjghff_O5gyjTwi7GQd.json\n",
      "Processing: 14kROagMiW9lk1ly0f5qotESgzgKRE0NC.json\n",
      "Processing: 1erlM2jlVn2FGdM6d0mA9IBvP2py0kosd.json\n",
      "Processing: 1O4OeUnrn3OToh41YpV1Wdp66hOUMFCqg.json\n",
      "Processing: 1BAvUDtK58WR6VXW7q3c3NSzHH6u8Ax87.json\n",
      "Processing: 1Zzbb7xa2VJyvoMnsHX33buNgWNd6nfjb.json\n",
      "Processing: 1HzvAuGehRe3HQGwRWUS9p-zMfY-RhDaC.json\n",
      "Processing: 1BKu4SgU603GDknarpN1yXz1cixvb5e2K.json\n",
      "Processing: 1HKZUVFMB0oHplSRoqjYNJi69Bh5IaBl5.json\n",
      "Processing: 1ZAvVqMMHBvv3o89B5L82__knRtv7_Xz_.json\n",
      "Processing: 1Mln2dbQcjaewZg7ChMJaM1M-xCs2jBc8.json\n",
      "Processing: 12iHZhhNEw7BbiEqyX2XFiHwmWumrV4jE.json\n",
      "Processing: 1EWDTdLkzcrOw4DOWnMOQYNEKtdecVzPJ.json\n",
      "Processing: 1nduuaVqxqWQt9FwB6z0bF7JD3JK6uMj3.json\n",
      "Processing: 13rwIlSshmyTY6xuX93d09iTNSu0yYkb6.json\n",
      "Processing: 1qQyOA2fGIxrpjqS3JrCQPTox76b66-c5.json\n",
      "Processing: 16go8u3P0Z828IYdZl3239lQByY89-HMn.json\n",
      "Processing: 1gxcX5FegaIBpg-rnEwYFlezmWc1UJaBv.json\n",
      "Processing: 1CDv2RXVOKXFz65fzSbn8A_6WRo8WqbzC.json\n",
      "Processing: 1YapPHMjcO96IFW50GWZGCWdMnDUqAXhR.json\n",
      "Processing: 1RLV1GekIY-c1a9lf357zwBRKqjPk4Xu_.json\n",
      "Processing: 1JSAPeWsY6d7snNViwRdygCl-c2pArmSb.json\n",
      "Processing: 1ieXI17gJLRbR1fOsxxwNHPfSWspCxvpH.json\n",
      "Processing: 1UiIkGDvkE5BFar108cTu50YQQMxZ3Dpa.json\n",
      "Processing: 1OF_vKcLi1YQk9SCXKz5oUYGc5vvsZJyg.json\n",
      "Processing: 15b-PaQz87GVT_E4BRBfkUWp4T4gJrXsE.json\n",
      "Processing: 1DrUFFWxp-l39-3gsGYhVutkJl96i-MHS.json\n",
      "Processing: 1hcTMWWMdULVpblYF9jhjDK5h9xS0H1uI.json\n",
      "Processing: 1Gx0KKmVagA4m4Kid6oEcJ4kegu0XWWdH.json\n",
      "Processing: 15jCR7PfI9XDqUuI9ijqZeZxHni_wXqkK.json\n",
      "Processing: 1QhocT118Ep5Nh72zfOnh9FiYOCB8yN6B.json\n",
      "Processing: 14Nel9BsAP2IXDl2Oh7-4tS4cTjz1zVOF.json\n",
      "Processing: 1uHuB26wFMgBfllWbIUoxB3ImWP0h0NWH.json\n",
      "Processing: 1DEmxrUaOjnoEhma-QuoUUqHbnGTUK8N4.json\n",
      "Processing: 1D0xySYiIGpw382avtc481_zGnOXvJwlU.json\n",
      "Processing: 1Agjrj93g0c0vDO4_Z3l9EqNrCB6Bfg9T.json\n",
      "Processing: 1BdCkwa5l4p8styJgDmnUYjZ5X1JNxDZE.json\n",
      "Processing: 1MH0BuYDzM6QbiihkxTrnzHWHUBVSmv6m.json\n",
      "Processing: 1HuKX7-uuTcN8Fe2bOPpjD-AfxqjKsw7u.json\n",
      "Processing: 1w-yAu9EzEM7j-pNTQ9f9GhMxU_qA_RFv.json\n",
      "Processing: 1-y4Sme-RwzUh3XVjc2Y7V6-MSQpHmf-p.json\n",
      "Processing: 1ciPlgran9AYW585F8-o7OoW3TBBZWpDR.json\n",
      "Processing: 1zsv3czSay6qZsb0azJ9wshE8yBJqlkN7.json\n",
      "Processing: 1SEI6liCdpZIpLlDkSAaXtnWVxFPtVqjt.json\n",
      "Processing: 1IaLDTVML877ZRaHixlyT03dC21TXYSpT.json\n",
      "Processing: 12qAQa7Gq1X6pbrUgt4FzgK6--E0Pj-PH.json\n",
      "Processing: 18zTy_gWr1R821YHc22QBxqdJA9DyEA7Q.json\n",
      "Processing: 1yguKC7Gi80C0Va-m0VyHjargLhwdydMe.json\n",
      "Processing: 1o2a-CjWd08et67qz0kQQfn8ECsZwnTHx.json\n",
      "Processing: 1pkOvi90fOlw0KfhL_vnRDTxKjm8iaJ6N.json\n",
      "Processing: 15Gg7mqGtHSiyXd7w0Hd5ZrMQhVrjI-T4.json\n",
      "Processing: 1E3kaNOlozv-z82wcuA4lkSMybI1G3rrn.json\n",
      "Processing: 1yuRVxJPfwu5VQI6wsbQsP038d5w-3tnd.json\n",
      "Processing: 137gJeWldTMQ_Xj3qhZVwlfSFXt7IaIcu.json\n",
      "Processing: 1DXdA5MtJLV3ukjm-itYjeoQExynVIYzg.json\n",
      "Processing: 15qHSx8IzRvC9mL8MbQyYVbF6wTaoNHhy.json\n",
      "Processing: 1vP4jdUjMMuvNlLNnCRpeomQXj0weP5K_.json\n",
      "Processing: 1Qogr3lR5v_7_Td-qH2Gzb8iGFzPJgZjj.json\n",
      "Processing: 1d6IdH3f46cnsYIKMqX5cRMh4SL5KOiWp.json\n",
      "Processing: 1gZ8lMCIhmw0IxR5V2IPLo9D6sHbqhG2r.json\n",
      "Processing: 1vWQY2VKI1f14lT3aYk4jETwoXRmmntwo.json\n",
      "Processing: 1XxWHO2YpODqBIE2UVS-EDZyxqjKcu6Ci.json\n",
      "Processing: 1aVFnRM2tEM_60QNmunUdKiZs82VkytcF.json\n",
      "Processing: 1shQJ6Sx2Zu_yQ6sbHnfMZnHn90j3_enn.json\n",
      "Processing: 1YO6q8xex9JrdJYLqn2SrhMBhYaD0BKIc.json\n",
      "Processing: 1ePejkOA-0VyocVsxrW9U73wchj3NwKjB.json\n",
      "Processing: 1e1I2gM66H7JdrAkMx2COO3Ff2Yw9B1XG.json\n",
      "Processing: 1yeVvNO_hL58WnXYZTgOBRnvfZ4xWacZ0.json\n",
      "Processing: 1nRMzMqEzn0_TTp9cfIa0s9EttvIl78W9.json\n",
      "Processing: 1uYINmzBdb4pKGnICIh_BwuvOluNu3-76.json\n",
      "Processing: 114zKfNLZTZ3ajaTJfU2cXOsyYnR6SnaC.json\n",
      "Processing: 1mx0jZJVLaO_UdGv2KUslj7aPENUvFi7a.json\n",
      "Processing: 1TfgIwcVTerrmELm6JBr6dxJmhdCbtmUg.json\n",
      "Processing: 1LQahGuZIIwovXdjylhojUBw-2afxwlpP.json\n",
      "Processing: 1QDmzDlAHNq5muc801RV1LasV07rfij1N.json\n",
      "Processing: 1p6IAWuSZEGhetZaKblTlqqCHhAab_c9D.json\n",
      "Processing: 1Hc5cTLoFQ5kJ8ilXPcisrADCSWQWzcUd.json\n",
      "Processing: 1Oc0UsxNIfkvBPcJkEyqHv-Jw8Vi2ifth.json\n",
      "Processing: 10TryAWUgNsoNTgk0QGGPbb4fxhr9IsnW.json\n",
      "Processing: 1U-O-2Q3hoDpZ32bBNLjC6j87RcWjUpFM.json\n",
      "Processing: 1JYY-FgqVBQoQ3pR1sep4PRVbXwA8oGOT.json\n",
      "Processing: 1oWk90VLrvaXQocliZMFDGPPuNY_fM_dP.json\n",
      "Processing: 1NZizCGuHZaN9NzocaztYpFM5Sx0Td_eb.json\n",
      "Processing: 1Lh5vHYX3gikSI1JYpKYfLbMV53iB2BIC.json\n",
      "Processing: 1yMrWq3eC8wipDfLjTcRgbNx8QrzSenv3.json\n",
      "Processing: 1GmvJspW4H7yfnT-RQasM9QO9C23GF7Bo.json\n",
      "Processing: 1GS0_nhuVJ_GCY6SUuR4g08TO75KN5eLf.json\n",
      "Processing: 1Syv02jqCLV7xp9BAUQBh6XJo31s5xYt6.json\n",
      "Processing: 1ot2Dl5xH9EVdmnqSDm1bnivZAV1Bp_Pb.json\n",
      "Processing: 1qPmfd0XM5ECT1Xf-MhAQFrq04HvzV6hI.json\n",
      "Processing: 1zgAn1wTKlFBHLV7zVhYgXU4OtLHUQEWV.json\n",
      "Processing: 1n-iiuy9tOOdo4FZSNupHqdqJSXyaCEUq.json\n",
      "Processing: 1WBzZ__B_6V2uVCwtVxF4M4Bt18XEYX_d.json\n",
      "Processing: 1Jk-T5QYipUx3xEfn7bHHc1-XbhzCB9QJ.json\n",
      "Processing: 1n9CWLx0OgTYcihtlZeykKbWFJvFm00rX.json\n",
      "Processing: 1dtETJ7Si62iOliarNpLmD26wr2_LWe8x.json\n",
      "Processing: 1MWQHeCThZmxzgV3zhOv_FBcZ8CDWh8l4.json\n",
      "Processing: 1ltZec3eUT-r9M78oCdTaJ4JM7Z5qNUOE.json\n",
      "Processing: 14x8LiNQP_4IkJ6B6uY1vpSblwCjoeSTt.json\n",
      "Processing: 1TKgsWGWCfjtcM6hmWjkbqinfPHLqLL15.json\n",
      "Processing: 11u9ZJTTFYtCxzGLK990FLMBPrUB5irMw.json\n",
      "Processing: 1qE7SlgwSLPywgOR7JS5vtQfnggALwVpb.json\n",
      "Processing: 1UOULhwgVXKU52kF3ggjs1lT9CST9uYnV.json\n",
      "Processing: 1QFpM-T8LBJNuAlLt57Y1QJY9u3khIxAt.json\n",
      "Processing: 1OLxOfTRhWkuK_KM5LGq33okOjMdK69ut.json\n",
      "Processing: 1OYVQmA5PNoGwt45h8gew8q3j8jNLfgjV.json\n",
      "Processing: 1XZi8fXuwAf7K2j2cxSWmRdhYrnOi_cTe.json\n",
      "Processing: 158oHVGkGBghzUJ8YoUMU9s6kwuD4Y8pn.json\n",
      "Processing: 1FnU9ETDkFrJ0w-WgkTUbuhkRECzvhzlm.json\n",
      "Processing: 1DP6QlfMeLeZ28j7KT9IcW3N5E9oFAMC3.json\n",
      "Processing: 1OKmxHUrO-cr2fsc1wa1H2ciQlDae5o5S.json\n",
      "Processing: 1Len1bEaCWm-Uev4W-c9YHPUFzUP7M57A.json\n",
      "Processing: 197qY4lKsRhTuheY-bvBxhqP4Gs0bzUQj.json\n",
      "Processing: 1W0Vc-YtGinLpnMxNbAJgqSb2grg9_V6C.json\n",
      "Processing: 12JHf-Q3HKTShh4lfu_9ctoQBynMmTf1j.json\n",
      "Processing: 1ERT0HpXoo5XHR33ZFU9bmyIX21qX_XwJ.json\n",
      "Processing: 1Sd_YdeFWTu-x-gqpmuCQRrmjnOgAG5Oo.json\n",
      "Processing: 1-56wCIF-4Vt5TbewMXn4XxZP-zJQuf8S.json\n",
      "Processing: 1r5Erl-5rkJLlQFcNL9eC08D31DQWuzM_.json\n",
      "Processing: 1KjcpIFUB9p7swXAnnVj4ND6H9Nmp8QQh.json\n",
      "Processing: 1gu0URWu2bupEKKAplDEGoJlFL0A7091g.json\n",
      "Processing: 1RDpgKcvtbRvqiShLYGvMnu86z2EdvkA4.json\n",
      "Processing: 1hIEgPsv6QBA75To1BEni6L18ad-83RTo.json\n",
      "Processing: 19zJ9EyXkVWHgrT8Zm_3ujXvG2l6-0DrI.json\n",
      "Processing: 1tNn95A9Q4XUKp2Jr_2XYp3i4AYq7R8Kg.json\n",
      "Processing: 1SnSigngGDsWeIXhE31w6TpuHNsyaCUWu.json\n",
      "Processing: 1Z9L-Ur49SOIVyUpUMc_VdNdp64DglIyf.json\n",
      "Processing: 1kkXmVFfL15BDQCrnC4ohIpe0yDaMB-V7.json\n",
      "Processing: 13YtYXR4P_AWz_IpSHO1fQBXaBHOGWGU0.json\n",
      "Processing: 16RyuL3Gqv0MZTIecg9tvzO_yWgi_CcWl.json\n",
      "Processing: 1nGNaJ6VWg3OE1lsw0QCXwA1hex3jjJLw.json\n",
      "Processing: 1d1D7ucfkXXiDQJUh2Xal7MJF2RJnJH4Y.json\n",
      "Processing: 1menUm_I0NA28Shg8-uB-Ms0sHoSHhkMk.json\n",
      "Processing: 14bNlkL-mTeOMeZecqXBKg1xZR2utTnln.json\n",
      "Processing: 1iI8cR059IeazPzApb7dY5vCrGz6Bq7Xn.json\n",
      "Processing: 1FJ9Ffqk3s_r0LGCHhBr0korIpvFvqK7z.json\n",
      "Processing: 1QSrHcLdtl5mFejGHUOGifPffRo9wMVkK.json\n",
      "Processing: 1poyJgTvfYCzEKpsa_Tx5H5z2eW3-JXG7.json\n",
      "Processing: 1RpVzVqGXKnvTa1EUq4ouutNCzMHfvtVX.json\n",
      "Processing: 1GN_ysDsgfqiTs6OuG3QXXFd81lITNfE9.json\n",
      "Processing: 15XQbxVSn1y7u3gsCtGj71noaVKWROhbK.json\n",
      "Processing: 1Cz11Pal06pXgv-ZDCrhh1Z4-LptKdHhP.json\n",
      "Processing: 1Z4LWrA4CUEzezSqU5gk4AaWW3cZEZp9P.json\n",
      "Processing: 154g-_MVE8czq3jfltg1vWZv4cMhq6FKt.json\n",
      "Processing: 1qRhbKDq2mPRBgOpsuotIkboIg9pow8zV.json\n",
      "Processing: 12NGzXWSXxzUoS7-zZEtKVK9ZKZHTB3jR.json\n",
      "Processing: 1sG_8YsWFnN_LBejlLup8gc19WIn5Qzra.json\n",
      "Processing: 1Irnm3ZEmIGGwWlwO7gJr6rIvpy-wGMHC.json\n",
      "Processing: 1Xw9pkVHyS5zJoa1fkJoSFjKNqvxofRs5.json\n",
      "Processing: 1iR0CZgnxHV0yCYy4JRYREbdLE_M6GV_S.json\n",
      "Processing: 1MVq7zy_Z9cQx66uoDNiHafyQdQmIG87x.json\n",
      "Processing: 1rUhmwlJwwciSHQAglmhfm8vDvIJOcokF.json\n",
      "Processing: 1AoMrS_PQHLI0NYueS77jlqCiuFfJzcmN.json\n",
      "Processing: 1TVGTpzoyqiY8OBPspu06kzeG0AVjehxW.json\n",
      "Processing: 1qaszgwg62kYVPHdoDtjirKPKX-hvU8JJ.json\n",
      "Processing: 19Dhc-FnxOxDojO341e2EBBakcaDTHF4L.json\n",
      "Processing: 1FzKk8o6FtfKo2Xcv3fCS3y2Ob2NUBj7c.json\n",
      "Processing: 1o7zOh51DTJriskA-i3mH7AmyGXF3O0u-.json\n",
      "Processing: 12wcUsmDitwHBmT4cm3EiU-AwSxnd-qhN.json\n",
      "Processing: 1_B215arjliTOi8jCr7C7IGSWc1SHV8qU.json\n",
      "Processing: 1uUs6OnXkS2kzKY6VHZtyP995Pnf6SYir.json\n",
      "Processing: 1x3srAwO7yHPUE2a1jpK6GSf92GUexjul.json\n",
      "Processing: 15a92DllypdCskIacJgXuJDJlOiJkfddG.json\n",
      "Processing: 1vCwA0d0dVFRGahZbQSiOFYcIW66q9shY.json\n",
      "Processing: 1ttE1mjxDksB4q1whBkhEk9Obz-m3gTzY.json\n",
      "Processing: 1cXor5QipjW8wjbLZSYYpy63vQS9O_mTE.json\n",
      "Processing: 1fKGkrdu0a1vQT06rr8iEc2YusluPcydH.json\n",
      "Processing: 1QZXSZkBo8sZU8QtleQSQhPvRE2z8BiKY.json\n",
      "Processing: 1rvXK8xVtbFO6BwRUsw8ICcxvcf4vAhJg.json\n",
      "Processing: 1VcPk-hV5hcYNCKWo0izDulSB6dK-jk_t.json\n",
      "Processing: 1iAJtgssJP6WsU77ZYKhPrlWNkmDOEYoX.json\n",
      "Processing: 12O4p2vQmiLshM0rd1-5xfOWmhoT-agGc.json\n",
      "Processing: 1-vvyPzqkH00CSqHQ13g3CARrtsQ9N_t7.json\n",
      "Processing: 1yiKGEbWskctkmyYWZbjgNtvY0ScKy6cZ.json\n",
      "Processing: 17LU0St_Z0FigSsXyx7g0NJxPus0L9Arc.json\n",
      "Processing: 10UmVyOicP5y2frBvJyViAf-EzG9tkt2A.json\n",
      "Processing: 1VaPY2txm9cMWSyx28r-coLbZgnl2-gj0.json\n",
      "Processing: 1XLlyHUIn_5iGKuKJ3SN_iQuiU4mlmdw5.json\n",
      "Processing: 1YSrNvPMwUARZzWv6FRorIDFCoAJ-RwJ2.json\n",
      "Processing: 1lXIJ-AWLQMm42aKGus0o7meQCiD_z94X.json\n",
      "Processing: 1sB0lvmiNO5gMr8J62MU-bbvvckYIC8P-.json\n",
      "Processing: 1jFFk5RNYv6ifpvkuizaFrGhdcHHKDBai.json\n",
      "Processing: 12o5nbP95N8WZIYRCtKXI8Zdli4AjcTz0.json\n",
      "Processing: 1gdjIVv4cmVwmWAxrCjnYCdFk6oyDU4Fw.json\n",
      "Processing: 1JeBbs0BViThIGZo56BTBkbzWe-cF-nsJ.json\n",
      "Processing: 1M_o0MvCxONoinvZOf4nh7GCZXCWYCRjW.json\n",
      "Processing: 1_zUWqsQoFnqWW5pXLjf6MxASKLwePgzd.json\n",
      "Processing: 1P6G3lvEa4SYXrZBy2Kkk5Rxvenzgr9fU.json\n",
      "Processing: 1_o62zIfKy12juel1LgoVxyBcYmMj5n1v.json\n",
      "Processing: 1IX9LldjGkDqc6zMZrENph2AkZ3EbmxWF.json\n",
      "Processing: 157x7OKfmeS_Lu5RB3Rqw1A51C8w7LzQU.json\n",
      "Processing: 1ymEcmzR43pJ4sC3d3tCc2WShCNpPuhqw.json\n",
      "Processing: 1Ar2orfoLHhWIUFtcHSmuREgII2ZUQX3d.json\n",
      "Processing: 1Rt-IePHQJtKmTYB1VsB1xJ_mmQnk2vcp.json\n",
      "Processing: 1l-sbh62Ix5kklg24EM5s0W43hA4Z2mZO.json\n",
      "Processing: 1QztkscewwLHxnGV4wXEEn9gL6bivc76v.json\n",
      "Processing: 1Cj668kaee7M7Q5VEK2CG-vxwUG5C-N33.json\n",
      "Processing: 1C4OuEiOK9ZPp9NI_olHyg7YmAfiryw47.json\n",
      "Processing: 1lc1Zy96NglVKv44eHg7aZYPPfM2Q_QRe.json\n",
      "Processing: 1Yq2w2NXndBu4R9CzWdDhOkEwrWVb4pFY.json\n",
      "Processing: 1rxWwiuwoJto8Sk6Nuh5JOtVPKhacaUKs.json\n",
      "Processing: 1KMQOeAZ_HHzK614asHeWmemMV0JA3RJS.json\n",
      "Processing: 1wAO31KTxx6aA8BQ9X12EFmK71F_Mpg8x.json\n",
      "Processing: 1R6WXz_Oyr-4OqYQ1IjqSfuNUKB1dIfhV.json\n",
      "Processing: 15cXYlWgwLE4fiZZ8oXVA4qi1EnxMQmqu.json\n",
      "Processing: 1u19XjY9Pk0c6-9nv8ADRzemwJF8mhauM.json\n",
      "Processing: 1oA07l19SLFjC5sYEffgrIh6QKl3cFghc.json\n",
      "Processing: 1b3gScG0FKycDo3ZrMQb5FesGyMWqnQki.json\n",
      "Processing: 12E4jGCrH1uulxDQCH8F6i5Nb7wjcdOia.json\n",
      "Processing: 1qAmqt9jw_s8g7JMSXXOr8edKlnOvKtlC.json\n",
      "Processing: 1HLYC5nOHgPjjFNFRKJPeYQfyCPMYkgP-.json\n",
      "Processing: 1ft9JvbFQHLyMx0E7yV6qmBVQ_VM5Fosf.json\n",
      "Processing: 1IRZ_oWwM6dUWGg5FVHG8HRHaA51ap9tp.json\n",
      "Processing: 1qozECgHzjiIO-l7Z-ykUcrI5OfHUf3fh.json\n",
      "Processing: 1Lqs0MeG0IqIyX1Z9tNYaFfZoPqQLJpVr.json\n",
      "Processing: 1L7F5tQb3pAuMUrFdKEVg1DQbrS6mOszf.json\n",
      "Processing: 1-EVpqYonn-JZ4VRIQnsJFTYSlj0WvCVg.json\n",
      "Processing: 1-fXthUQpYQK4Uy8K8WUavDEwdnZr9ggX.json\n",
      "Processing: 1E2kaBJ0ZFhTDrng9aTv-6NytI4vA65Xp.json\n",
      "Processing: 1Au6ja1mZB3YpxqDHp_moytJs8VCrDoKd.json\n",
      "Processing: 15Bsj1L6r1csADVGBPwyzo9t_ZcjL4TIm.json\n",
      "Processing: 1g5wtGS7GH4Mx-2536rpWSwCZC0u8XxcP.json\n",
      "Processing: 1ZdGQZUthE3L9tw5_zD26LzRGm0sPuUXn.json\n",
      "Processing: 1x9GYzUU6MktvhLgtc4lB02w4IVfXgFJ0.json\n",
      "Processing: 1GAH1Lu5CCeuQAKz32h45t3L7djvYh2P0.json\n",
      "Processing: 1MS5GKYrGhh-b48w9jh_k4tB8DtgpMJ0n.json\n",
      "Processing: 1MbwEg7zsdg8jaecHUGdzsQ206l8SNL7w.json\n",
      "Processing: 1-VczgEUy55El-f6w2rkye2tEmy3aBo0a.json\n",
      "Processing: 1jY1hmHcrxMy_qclRayXvsQa92DRIeIUB.json\n",
      "Processing: 1hIbQKPt-2DvUT6_mkKSXGEi-8y6kgmes.json\n",
      "Processing: 1n2RB6bjPMqqQcCaVQgLyz83-luyoEmsQ.json\n",
      "Processing: 1N38k_0OkqI-4YHsiX9YCawjWtH1gLZba.json\n",
      "Processing: 1O_53Fr6FegUxOOcSZ0lOL19jxSvoX-br.json\n",
      "Processing: 17-H7t3BqowxNubUL9I2pCZufAJCQsgg9.json\n",
      "Processing: 1UiVW3zsM9muqOuXD_p_cPRwL-0V1Malx.json\n",
      "Processing: 1Yfm8SZZmnglguW4Nk9hACVHgVEh9QaAw.json\n",
      "Processing: 1p2Fqp1SAaupv58tjrHps-zvgQXTstM0C.json\n",
      "Processing: 1D_Be3O3X-6SZj7GmPlqyKewkm8Dz_Kel.json\n",
      "Processing: 1S7e_hYj__eKCZcy-I41AayL7Bcxq6-fp.json\n",
      "Processing: 1XP6dsSjGtCc887S33hoHQES2jyMVHx4U.json\n",
      "Processing: 14pIS4osBol9GV45oi_aryQ1asXVl7XNt.json\n",
      "Processing: 1rL-unyRoX0OOKLGevlTjhnb_aDw9g5mM.json\n",
      "Processing: 11ewzwdDLCp9YXujTiqU10wPY9tDi-DNT.json\n",
      "Processing: 1Ot-GGe7afwo5f2ahy452elFZ8tkzn7ka.json\n",
      "Processing: 19pndC_xGl_ex4osIkDaNawVpl8d17Dhn.json\n",
      "Processing: 1oTIeXut189_y3aKJmF4uuXjKaEkY2BkG.json\n",
      "Processing: 1YB8848hFNmc6LdOeljeI-3MxkkylJ27m.json\n",
      "Processing: 1h4dZ5mtZABO7qbBNgcEQFeXgF46YSIWG.json\n",
      "Processing: 1XU8c6vQNcdwjLEdcSYGK_EnyOzd8-zqf.json\n",
      "Processing: 1c9WjvTtTwzJA3AccdHx5AyozR_SlF8Ol.json\n",
      "Processing: 13_nxt0RUOBdasbrg0fhg8ghCssK5UMdq.json\n",
      "Processing: 1QCNwtFpEOebDS6HkEMPaR-cBCayn2knO.json\n",
      "Processing: 1jNXZwLkuHzHt66Nn-0zkBllDoOXrioom.json\n",
      "Processing: 1vdYSetyfdfhRfXcmWxX7bBfZfWtnW6Jv.json\n",
      "Processing: 1CWXrDrBWpB6n3sfFdppIKdqaURoDE2N-.json\n",
      "Processing: 1I-ymACTdYqbEAx-oau-7zba2yIc_QPiu.json\n",
      "Processing: 1irzO-PnCjEjRLHxmfkZXd2AA26BT4KV_.json\n",
      "Processing: 1ipiD0UC_j0chDT4fKzrXscmsaq0hQGg9.json\n",
      "Processing: 1oa71xLFgCed4RXDE1acXqIqvTKNjRp4I.json\n",
      "Processing: 1EHxfVyQwR3Ee6BYGG3X7yuM0KUCIPrTk.json\n",
      "Processing: 1tl9gHDwhAREiQY4wQC8Sqhhyz8ZgGUP2.json\n",
      "Processing: 1gXPJ8I7tB7xgcfL4ArMMhLMy1tL2-KyS.json\n",
      "Processing: 1wqynSQVIq1PBUEsJn_9soBHCUrKqQjGd.json\n",
      "Processing: 1mGwovP69E85wpHrbaQsPJeJxq05k0p8L.json\n",
      "Processing: 1SSiaY6Y0rFC9BZONw6DH-dAT9aFas2Kc.json\n",
      "Processing: 1gDiezi-UCHLhKRVuwFG41mRjRbKtx4C2.json\n",
      "Processing: 1Ngs2Khm4eqdh4YILKY89i6xkdfeZkr-Y.json\n",
      "Processing: 11oQHf-rqUumn5YfvJvcpEnQiBGXFZUIL.json\n",
      "Processing: 1cJ3nUcB_NVLcmN7xKhgNSFwagdIEaanN.json\n",
      "Processing: 12DMeaPO2g9dD6-x11Iz_9PduHfcA6TTB.json\n",
      "Processing: 1gxc_Bc4N0mA7XXyg2wF5LNFw607aXH-A.json\n",
      "Processing: 1mD1ls0x1BKsM2mrg3uWaQK3oX6DehVMs.json\n",
      "Processing: 1jyEdTt1P4I5a49rmXlYJD_ZgR50kCUlw.json\n",
      "Processing: 1qgSoSqPtEw24wkzObUCYi6rqTGw29E1h.json\n",
      "Processing: 1Bu2H7rPqGoOMyua61xlPXXvIfBG79rBN.json\n",
      "Processing: 13QJ33UfUhOG_mLDhHdTACDQRBFmQtYZO.json\n",
      "Processing: 1o7aEZrKPFuFCYhI4b2cNMjjiYveqXJ_9.json\n",
      "Processing: 1q9xJ26YWHsDhaWIVwZZXHce3KKUC818y.json\n",
      "Processing: 1BhvzfIcNTnsHUaCReXcIo8rVWfQMoyPc.json\n",
      "Processing: 1c9P4w0PP0bmZZK93cIJMWlk9PVi-_J2A.json\n",
      "Processing: 13u5UadOSYF4ZxuHH6AqeI4ncsYM_R-FA.json\n",
      "Processing: 1Bd8piTC_IQbAJBuRwGbdAepSIFI7nM79.json\n",
      "Processing: 1Yjjetg12O_MXQ1Jmf2X0AvQdtox4OQJf.json\n",
      "Processing: 1r1uqH3-5T-OLlVwhaFG9nIifrn0c0d_h.json\n",
      "Processing: 1D6V5PSgktyEFOlKDtkWHXkprpYwD4gPk.json\n",
      "Processing: 1FPuV4QMkGiRCWJciamQtc3l8J--ecV0i.json\n",
      "Processing: 1RDa9fHOupv_-psW1MKD7EPUy2syERYcM.json\n",
      "Processing: 1mQNVhxAi4CnAO9LYbGKNbi4fD0AXkvsg.json\n",
      "Processing: 1YSIXjgWzZd2R2ssV1VXmm0ox3AmIhjxO.json\n",
      "Processing: 18GMTT-BfXVMLcQZars9-keUTq2aYmeEh.json\n",
      "Processing: 1szo0l_8plM_IS5CWK1pfbElazYz2PpB8.json\n",
      "Processing: 1e6oD_7om6kXdiLudWERVxIes4hLLWK85.json\n",
      "Processing: 1XHVDxYNPlPX5wFdenAHEUgDgEkY0U42M.json\n",
      "Processing: 1hBTFW8p0Cp5GsB-oExlIoWEsbeEtzPcA.json\n",
      "Processing: 1ZaoPsrV49bBNICsBmUjS6jMUwEbQbhSc.json\n",
      "Processing: 1ntxfyCFhd4PAqHc280wVK3KiKlzNnmQG.json\n",
      "Processing: 1XIXvmD820VehvC9LlhpJQg45ggNLgVXK.json\n",
      "Processing: 1cqk9fVEMFd1_XS_F5SRJWqXKzgbSYLhZ.json\n",
      "Processing: 165mJ5TjzdGlI4EW67eb8wBm_6Jag9GDc.json\n",
      "Processing: 1eJlo75jnEw_roRfF-5C1SCJ5nhN94ng5.json\n",
      "Processing: 1vmL3uG3WP9f47jeD4qMSjlvEa3p2x9om.json\n",
      "Processing: 1bycHRnbPd31uZTTCp-ib__KYevyJDKem.json\n",
      "Processing: 15XhW3AMSMoe8x3lk5AyvnXqhPJ8VUsQa.json\n",
      "Processing: 1oj1fVyM4kJSEVe7vey1KVvmV0YO_0QaO.json\n",
      "Processing: 1Ignnh1n4Cde-u3o5md6HbryUWEgxCAxL.json\n",
      "Processing: 1JtTn5_bJPg4QhyVWbbkWVGDvR_okesqz.json\n",
      "Processing: 1tvF55qR1K3f46KDMYbOom8is5Fh6YC6P.json\n",
      "Processing: 1wetjluay3t5LhJt9WsmE1dk1tpsiOzVk.json\n",
      "Processing: 1OCNyOfTfVb7FIKR_iRhPQapbkQMdVWGd.json\n",
      "Processing: 1sByzdjaY7C1KRsVYpzquH8rrB2Trtnir.json\n",
      "Processing: 18uP2N9oigFtutvfEXd_Xg6KQ6gDtFRJA.json\n",
      "Processing: 1ejd_yXLSan2IVGtHeS9bYw0HIOQS_ffp.json\n",
      "Processing: 1Bes7BPwkxvrZ9p5S5Q6uGdw6NRSW7JVj.json\n",
      "Processing: 139ySYyKL5cmFChMMTa-ThaJdsnfk3KjQ.json\n",
      "Processing: 1NYMa5QUvI-kXY5dGi66iEEL4yGd-LqFg.json\n",
      "Processing: 1hEsV1sGiGPgzC3PyNCQQqtpyBXryUz3P.json\n",
      "Processing: 1KKpTZ3WwaWS_FTzJKlSFqsDzkEMfQTCp.json\n",
      "Processing: 10LYZphVDphwJfRbmRLRdZPvvB1LZDEn4.json\n",
      "Processing: 1gC8zjcnih0kM8h19wxNMw5p5JKcf-ciC.json\n",
      "Processing: 1o_9F7xiEhmajOb0nNJCArql_ov0B-MEK.json\n",
      "Processing: 1Hc0YcE4xO1TVY8EE2Bl90PT6yUjuABCv.json\n",
      "Processing: 1YVdJtjGydsE8QCqiMEouIEJlikC0Ckh5.json\n",
      "Processing: 1q1tTk9JfdUsUD1lptcP69lq5nIUaN-tM.json\n",
      "Processing: 1oRhjFibUMbSoxFc011tMzy4mJ3G5xdZw.json\n",
      "Processing: 1DmCXsO-OUXhccGbEN8ta6uH3oh9D9TMZ.json\n",
      "Processing: 1pBmXKGTth_x6jYQvRwHQECqOVjAAGS2V.json\n",
      "Processing: 1VE2oc7A_5WH6FUfZmHDbZ1CM5uOanYAK.json\n",
      "Processing: 15ec32KxJ4MjAsfQkAwbMrNd1esV4vcC0.json\n",
      "Processing: 1zEOoLrhDv0viJwz7NYJQ53H-gZAjsV94.json\n",
      "Processing: 1NCoH9JZMz03i3AfWyVouV3lxcLerhBBF.json\n",
      "Processing: 1PorljGK1mWUwtVukp9Uzm_9ljDyoYns-.json\n",
      "Processing: 182xy1Wq8dMgrB4cI4Os310iFAnG-BdjB.json\n",
      "Processing: 1gc_K5M6aitnDfB7bUwz-WL4ZVdcNG--p.json\n",
      "Processing: 1oYRc_9rwMcz-PR1bYknHbtAyFiYUZwtO.json\n",
      "Processing: 1xa3AUfEU4ZdaHBQ8yg6SjelWVdwdOrAx.json\n",
      "Processing: 1555Oh8dZJOCiJFq8I3fiAWYuRE46_NXH.json\n",
      "Processing: 1fuw_SNMedbFuZtr2dl_dsjIUu_3iT6dg.json\n",
      "Processing: 1MXDq8Bcif6nrt2TQKrFGoVdaC4N_njTp.json\n",
      "Processing: 1gZ9yEn8Mm83vrxs3GLSnb35MnCH4h6TR.json\n",
      "Processing: 1wwXsY8ekK8NFprjF85-BYswbV8Krhv3E.json\n",
      "Processing: 1Jq3k9m0zb2f5Ab0t5IIJ3bG2960LiSuh.json\n",
      "Processing: 1s0VbhLZYdxXshccl_RGau_qMaOi31cAx.json\n",
      "Processing: 1qZFpqs_-sHonpcETXY_9PfNogbcbOcPp.json\n",
      "Processing: 1PhHvAzVbyx84ac6Se-zgaFTxD-82LPK3.json\n",
      "Processing: 117BSse0v7pv-N68YXwkpeexKn6pKw5td.json\n",
      "Processing: 1hTbvYFFUck8sdtUYJtkDgDSzXTlhqCpP.json\n",
      "Processing: 1DHFKRXhmu3Y-QA7EjCnG6yMIuTeXRNhe.json\n",
      "Processing: 1GC3V9iAXWBxdcsjtd1gnzgCJMkuZDt4R.json\n",
      "Processing: 1pQ07QlzEooj7VL-Gk6Y5XbG93nLdV4Go.json\n",
      "Processing: 10YDdwhFGLFgjYLZcH1vD9a_gfj9SjjFc.json\n",
      "Processing: 1BJl7xaow4siFkke_G5HX7FiiM7d9koff.json\n",
      "Processing: 1Wc_27Hq8jQlF9DyOxgaGUrklx2em8QBm.json\n",
      "Processing: 1rZXHskeT57i57TaK3gZI5Lfgl_B76S5k.json\n",
      "Processing: 1nAEljFjIld9JTKXBUDF8h5lRrr-hSweZ.json\n",
      "Processing: 1IGXBVcbrnhtLx0Mnm8ZPrJzZ_qsaTdcr.json\n",
      "Processing: 1D_Fz7E7-P1IBgmhm2odKI6xuoAg24IBD.json\n",
      "Processing: 1ruVlCe_KIYUqq3rX5zxjqBfydMnIXuxe.json\n",
      "Processing: 1dwRH90ZYV-Az7CsBTUt3iK4zAQGOAhdP.json\n",
      "Processing: 1buN-ROobdihzg_Bj9w-9zV6cWe9BvqFd.json\n",
      "Processing: 1VY95qkIo6oxs6TU0Mdu9f21Y_TurcQqi.json\n",
      "Processing: 18sulrAhFeC6ODIVmk-pBGL4PWruTdSrv.json\n",
      "Processing: 1DlqEJ3sDKzZq3-wWaq4IcJOwODBZuYFp.json\n",
      "Processing: 178c_5WloIhk9pNDTf1Gw2KeBBOc4fpMn.json\n",
      "Processing: 10ZK3_c11TvgSCYNGO0209spp9FJ4LlHv.json\n",
      "Processing: 1Dn3rQj803Wyu4P79f5doi--Fvteiwy4I.json\n",
      "Processing: 1ucAjjimGSpPzscOPjiigBTfx3Zy3e8x7.json\n",
      "Processing: 18UfXXFq0ICE459ejKssCNjoyyZNFAiPu.json\n",
      "Processing: 1TlEAZn5ZB7p1N6PN8djIqhNvehzfXGBW.json\n",
      "Processing: 1NIKEFsAqoLFRgvrlSA1UzQXgF0do-SZy.json\n",
      "Processing: 1HpWChcyg7z4pR9XkX76wW8AOyBiY7OV-.json\n",
      "Processing: 1pOX_PNkXQiEdbdkm--V-44neM_Pms0Yp.json\n",
      "Processing: 1mE3wjxQVtJiF0cGDXX94tpHxjBJ1lsam.json\n",
      "Processing: 1EiVvll4G2ipSUhLjjt_ToFR4feLDKjpQ.json\n",
      "Processing: 1CEKENfqnKg0WYOtcPmLB1jFbgZuVZNnx.json\n",
      "Processing: 1tmhgk2QFs-ru8gO6AJ28JaYynfLnLWx9.json\n",
      "Processing: 1MMfp0ZYMkjig8bs0SU_RlmJ1lAyQXIhY.json\n",
      "Processing: 19gwSEkgZF9VU34Pi4itiZcps26nY8gDw.json\n",
      "Processing: 1W3QEE35Q8Yln8CxvsxQUKigWltyZhvEK.json\n",
      "Processing: 1n0U9PlQcViP7PXKcy0HyzncnQc7UlLtK.json\n",
      "Processing: 1MHgYZPBCSGVxOF9CtWQOihJOWvBfEgmq.json\n",
      "Processing: 1ILBgatJdWzo1FMrqKfVQxRxyWXGvfdra.json\n",
      "Processing: 1bAil56Z_hWsmw_7TsM8u46GmSVOlgYVM.json\n",
      "Processing: 1TYLwGguEb_EbcW29y9f3QJT8AMzvZp3D.json\n",
      "Processing: 1RX-tpnkuH3DIN7FuS1eG_NoQ9UnsYhdc.json\n",
      "Processing: 1Pp8oadtFk89wvdZFFtFyHr6OejVExjXE.json\n",
      "Processing: 1a5jAWGD5B03mdJRmdNFnRcdL0CrjceSV.json\n",
      "Processing: 1JKCPji7CTmasZnZTWNtycOF3cOlltm6A.json\n",
      "Processing: 1kvPUNBWhp-8TUeoi6H2EFFDWjAVYE_K9.json\n",
      "Processing: 1YFXOCentMVQun0lM2XURQIfdp00i9Onk.json\n",
      "Processing: 1RFGuK-oz1qMyQDWLQwWqcvT5S6UgFNHp.json\n",
      "Processing: 1GTOT2O0hnwSSOgayjezQzDJ9m4EnmdaD.json\n",
      "Processing: 1rFq481ihhQ9wM2w-VVrj6pfvIah9oZFL.json\n",
      "Processing: 1llRGh1mKWmeEVdTQQeTijzWbW2wjCWD1.json\n",
      "Processing: 1CmnGRIm8AzYukwZ90KfKAwG3E2ZDp1IX.json\n",
      "Processing: 1osS7hdnErgBpMhVOo_pPYA23KheFjp3-.json\n",
      "Processing: 1pOvcrE1IjwXvrVOgkbEU1gr0sp8z_Od0.json\n",
      "Processing: 1F6VIuDnryeZtMPT42RPqhBgRVL709no-.json\n",
      "Processing: 1yrFXe0ydN1jIrxFUF8ABBHFq18kAb3wU.json\n",
      "Processing: 1Opr0uBCVq4l8BaPTcxj_w94R_Ac8x17i.json\n",
      "Processing: 17odDhhbmbgI07M2fwdPBzq8sDSTqAKyo.json\n",
      "Processing: 19rNQcINThr752-wOdnLfYMG_GZI-G1WA.json\n",
      "Processing: 1W_jT5Afx8dOdo51BAkwP2VgwHgNz41pM.json\n",
      "Processing: 10qZ_n8PIz1t1CUshrwWR6qjskr8sZEq0.json\n",
      "Processing: 1w2ItTQzwXsY1ROWXDLI7UgECZDWnRTHX.json\n",
      "Processing: 1A-s9ARlE4jTZnrUI2kJT18VIv7rABLvE.json\n",
      "Processing: 1z5FaRj00KKCXivMxgu7R_a9hq3UKzvKK.json\n",
      "Processing: 1mYxnAVd3SLmzVCJoS40UquA8HHzt5tIW.json\n",
      "Processing: 1oA5pEbmkJJrtshwQV78SZQIGJAPMw7NK.json\n",
      "Processing: 1h_yQawUt0-4Bd66n_g7StJPCrcGiyNxu.json\n",
      "Processing: 1TArszacgno3bdWmr4BrU7X_QlbT0rmd5.json\n",
      "Processing: 1Y5fpbHBok6zR19Ji_2fmS1KAXND6qcWd.json\n",
      "Processing: 1IpxuhV0cG1-YbmmCYORZfix4nPldSWsR.json\n",
      "Processing: 1t-uiwcIUBhKzDHqT0YvrAmBF2rP_JXKc.json\n",
      "Processing: 18Gh5Eqk-pCBsnpjn6u0U57hKAhqgyktp.json\n",
      "Processing: 18BefX0hKNryyhpuzqU6ZeK66Gj31GyEO.json\n",
      "Processing: 1v4KmOuySFdnQm8RRk4oRUWtkcXIddkXe.json\n",
      "Processing: 1XpPOoxPcozPSMOAc74Ifpim9FsVW3diM.json\n",
      "Processing: 1IolMxYilEXe2kZtLI3DoVlwcp5DKoI3R.json\n",
      "Processing: 1ZgBPpErbCnCkbkoA6H_8_DuNnyz5ZLpH.json\n",
      "Processing: 10xHvyhJflBhglf5BoHMYGxndfVWV3pmj.json\n",
      "Processing: 1pBkNglX5SfNK75Fxm8r7rDldbJjaVnt8.json\n",
      "Processing: 1KObX5LuxXMUPTj93w0zL5rK61YVnRlW7.json\n",
      "Processing: 1CMaqkDiE_jKVsFTZA2RlJxU9LaGTdW6V.json\n",
      "Processing: 1GiwZln9yZA46MNRTHErA7KONkcsD8O1w.json\n",
      "Processing: 1-BEZkAqkk93gO-8c7UN2bfT_glBBANoh.json\n",
      "Processing: 1JQuvCDJiKpDi-0dsupv2ihiAw5jDhOKY.json\n",
      "Processing: 182cle5C6MkwFGk7ct_OeMPN-yopkzZP9.json\n",
      "Processing: 163FTruKwWz5lzTGEshfG0-ssOg8rU1px.json\n",
      "Processing: 1W_uDcf-eqOyO0cILwHiYu1be7WUJmWOa.json\n",
      "Processing: 16cBIhmQWd87gMK4PllyvW-D3xclhcurB.json\n",
      "Processing: 1oeST1oDHZ71xbBoM10Re7C4lbvvrrNni.json\n",
      "Processing: 18Di5LGqyhuDLVl4JbKZClqYDUtzlhSh7.json\n",
      "Processing: 1VE3FiG_LD8iIu662uYm8DMV9Y9-YkjZe.json\n",
      "Processing: 19meJBZNNqIv5wO_YLVkPyePGpFC3vXzU.json\n",
      "Processing: 1rGMCXmXFjKXpOJ_ivU84OV474zPuHhVc.json\n",
      "Processing: 1wDrA320DaMY435MeY_4O2nvCKBkTjDk8.json\n",
      "Processing: 1YYKD623PpWTwqwdsOlRFFXLjPYUp8J_1.json\n",
      "Processing: 1qVUYdD3jrP6nOhotpiwYuDMyTTCb0UOI.json\n",
      "Processing: 1VJfukJPRzOVtKyY7lxbUgwhhq-5mqK8U.json\n",
      "Processing: 1ktJ6bkOls018C6YBMk9QDXVybsF4Gwor.json\n",
      "Processing: 1pBkalt5EqhyXXQgDA23q_g-bpfMcinFW.json\n",
      "Processing: 1xGuuEDsC9Klg_slwxCXAYLJcPi6vRZI1.json\n",
      "Processing: 1rcuH-YDmwbbd4ialFwll27d_Kci1HHBj.json\n",
      "Processing: 1CMv3fqfcVv7qwSMcR8fuJTsP1xD2ARYK.json\n",
      "Processing: 1aMLGCnnzfKGJ2aq9a0Hw8C6XetFPKQoi.json\n",
      "Processing: 1HMfqCW-0ASgYyZq682VMCqPaGupzl80S.json\n",
      "Processing: 1XK3iVnqH3cpe9TwUcffWfICG7GiJ6OxT.json\n",
      "Processing: 1V-mS7KVjz_KQqimgNHXzKPVEQj2EhsMx.json\n",
      "Processing: 1AvfKdjNwwIVWFwEwbvwRRm4AhwtUbLb-.json\n",
      "Processing: 1QcQCvC4EhT1tgUfSmUX9TtG2kTMsd6_G.json\n",
      "Processing: 1cx8WL3dKYJhSJiiLafswegtywpQQY_WM.json\n",
      "Processing: 1YmisVp0FSAOMY9354oeprjkU743Pj9Fj.json\n",
      "Processing: 1xQnq3hmslbkuoH84GEnDsm1BRhzQgCZs.json\n",
      "Processing: 1Pqkuoe3-W7y8psa1-aZ39Q15vqq7-5kv.json\n",
      "Processing: 188Lns30CtHDBvmsUdhz3ejjREpDZJD10.json\n",
      "Processing: 1LWRJMfemPW_EAdKYGgcSj73D9cHARWvW.json\n",
      "Processing: 1BMU0WuhRa9X_Ghy3a0rV8QcUR-YdGVXe.json\n",
      "Processing: 1t3MhMsBc3j1zWilonUC94wk7IwDDdltu.json\n",
      "Processing: 1-tqbdXvsg8rAtug6PsTC0LHQ00Al37YU.json\n",
      "Processing: 1vdRU_sJTUASobNIgjQflmLD7BgBjrAIh.json\n",
      "Processing: 1HK6UAoy6OVsvVRuuVR6g2Q2naeSfu2so.json\n",
      "Processing: 1TTa6etlfHhSGVa75EG2OkkD4kCbwuVhN.json\n",
      "Processing: 1ebMUiBkcdi80MjQJ3HSayxe6frHnT9Pj.json\n",
      "Processing: 1Q2DqrDn4AFX8BZcGzdNuqqeAJs35_N9y.json\n",
      "Processing: 11w6dLx9_rMGLHG182whJ22SP3BhGctvQ.json\n",
      "Processing: 1KgGf-2Fi-TsfT047tpiDz7D22itqghoL.json\n",
      "Processing: 1N8CFCYU6nfhsk9Iapw0DfvhNk6tDkl1T.json\n",
      "Processing: 16BHEvF97cnn4Z4lhAi86mhhZKQqMy6Nd.json\n",
      "Processing: 15AW6AKvORG_Ms_aVzR83TwXw5MXWiPuc.json\n",
      "Processing: 14VNx-EkPSmDht3sZJB2VdzqCjPwzu5ZZ.json\n",
      "Processing: 1udGqlg8k54I3iNZ_WdS-Iox1g-2GXLqa.json\n",
      "Processing: 1ELdq4KAcaSxTMcLWDYTwYTq_es9ICZiZ.json\n",
      "Processing: 1ILeuYZzhXcEincaCJSAIowo2JMHCwSKc.json\n",
      "Processing: 1RX06VS0dDTWr6-rbXE7plZcjenmuuZYl.json\n",
      "Processing: 1QDnU_Hs8tZnxjAx25ftg2HOmEmJ0uIA6.json\n",
      "Processing: 1H1PuQtV_iMis0A2JYyGkhDK_yO86NWf9.json\n",
      "Processing: 1VvKIlirLG91nFK8WONIrYYGfT8clv_V1.json\n",
      "Processing: 16Notquai1oIpJ9iE3ThJcqoJPr1GDUIb.json\n",
      "Processing: 1OmRwgOWXWnFVxN15uAIQbpwZ62hqvFm_.json\n",
      "Processing: 1iSi4J6w0lP07gLaF1SZUvStk0IktVdbI.json\n",
      "Processing: 1t__jZvRwyDdE1wZKWadAf7LDQhh1koO_.json\n",
      "Processing: 1-pjaa4sTo7EP-URZMFo6ndAQoRZtU9fh.json\n",
      "Processing: 1wY_zVAjbJzt6rV0vLJKRlwT_d2Zk_xe7.json\n",
      "Processing: 1nbrgNmEVSFx4Y3Ocu76BT6J2PGAfE0hH.json\n",
      "Processing: 1ORSQ6kU2hjZhfk5SCmhngTpCCO6zYuwq.json\n",
      "Processing: 1G5YC6H9Qz9Tjq4bgQZbMlXwSIEIoAAhK.json\n",
      "Processing: 13eRu_JqJdCokB6RmouBnhNXPPdD9sK7G.json\n",
      "Processing: 1pY4zYi8NVCAZ0dWJq7fjnz7RDkq8eZgn.json\n",
      "Processing: 1UkjuZ_-TajC4cIliZsd7s4ApXHKrgklI.json\n",
      "Processing: 1ACIABzqC0DRLnngLuCf8h9x2H-0-0M_E.json\n",
      "Processing: 10CrZYy20t0_W1NCPnN7L5OHSFIk3SuqK.json\n",
      "Processing: 1NHP_HsIrKOqqsHnfY599G970_ZQPp9Sd.json\n",
      "Processing: 1AsG5Bmkmb5UGGu14OFu4I_ovfKyOQFaX.json\n",
      "Processing: 1AY5QUM48UmVb2VMZ4rKRYIfZzhC1RQ_E.json\n",
      "Processing: 1AP6UUp9fSMYoV2kkU5FVrxHz6u35Iw1R.json\n",
      "Processing: 1s-6H9AIwvMUjkMsi3enrGK6MnXSUGnTQ.json\n",
      "Processing: 1uqqIpy7jzLUJbXGdeKxDvdq5DW7vDhty.json\n",
      "Processing: 1DTvSRLAmUvi2KMGhpD2T8m31h94_dvF9.json\n",
      "Processing: 1yIqAZ626uuaOhM_w_m6b1Jv6E4JQ0e8-.json\n",
      "Processing: 1zn5osTKBFhlWw20mtjchhbfxZYvWfRFV.json\n",
      "Processing: 1laemzdTIicSzfF67CFFvSDYn9IiN29b1.json\n",
      "Processing: 1Cxo7y7bnjYx3c4M3iIGSxoJnvchpr2K1.json\n",
      "Processing: 1t9vi4eGXjNT9DrZuKbkMCVu36I9TwXEv.json\n",
      "Processing: 1-1p_H5bW0oxw1QAycPCQkSsPKKFym9js.json\n",
      "Processing: 1MZdECuBAkvquM9_CL2SqzelM-TaWcgDo.json\n",
      "Processing: 1BSPdtlQYHkhxJW1mRSxB0Vt_sfIiFBWC.json\n",
      "Processing: 1_b9V5ObZtd_f0na-V3md6jikdAyZHFw5.json\n",
      "Processing: 1L1s8KnpiEvSWrRF0QJVPx6kZs9DN6GQL.json\n",
      "Processing: 1vMEC-Kouk2zryQJiia2AdQ9dFEN28HnT.json\n",
      "Processing: 1ZpSZdy9kmi8qZm0tybyW1HER1fI1B7Rx.json\n",
      "Processing: 1oUCWUhxkq1AvZicxql6-1TE1lmSQbaJJ.json\n",
      "Processing: 1QqGyYvNofrUKRY_fpfnLQs5FV21KU-_I.json\n",
      "Processing: 1yg7934_BTS4PthqTxSt8W1RCWsgCM2dd.json\n",
      "Processing: 1oViILuoWaeYTSKhcHZjmTC8muosZa00e.json\n",
      "Processing: 1iz3U1ITkcWEi-9soq0HdCUdt9hUfVECL.json\n",
      "Processing: 1pw0u44RGcf04yr-BR9eNWhUozljDiZ8z.json\n",
      "Processing: 14HZ_ba5wEVf_xv1YVa9F6OSMcVSUPD2h.json\n",
      "Processing: 1z12elhGmguyO5fhYWl_1N6NgGv-Nnl3u.json\n",
      "Processing: 1OJJ0vynUqNH-cEpSPqItzDhhdyHPXUe5.json\n",
      "Processing: 11Ng4dvxIKogvmabUwWFkx-Zf6Rgid6KO.json\n",
      "Processing: 1DgMbvwW4h_TkWDaqiRGA-LlazY0lG2Bw.json\n",
      "Processing: 1vfSE3LzgTUu3uJHQtNedZ5bJqx9Ez6lH.json\n",
      "Processing: 168pnf-1bTC3t5MyyvJRJm0kVznod90v_.json\n",
      "Processing: 12bkk47VS8GJjUpO7y1OV-TJA-9IxmgVv.json\n",
      "Processing: 1gbXpHtZ6mvbuvqVm7QeW81bt-p7D5RA_.json\n",
      "Processing: 1DAWbOKNCWx4PrtN-jWKa0Ckw2pvFijeM.json\n",
      "Processing: 1gCfvmbDWfDpqlMxjsPzaSc0FOHddst7g.json\n",
      "Processing: 1Ej8pOH6-1EmGowRSw2kxfbYP4_3OLMGt.json\n",
      "Processing: 1NwK2Sv8HHsdkP_kH5q5cFX684O3YALFe.json\n",
      "Processing: 1IrfYjtIUhnXZJZLz_OMOyyefV4KKgsEw.json\n",
      "Processing: 17hz_yjz4RahjfSxBG6OTULSROUbSjwuq.json\n",
      "Processing: 1U81nq6Qtv6W9PHDtM-9vk-E4CXeWHeN1.json\n",
      "Processing: 1JLq6fHJDAvDvPjNbHcQQH89iJrnJEpPL.json\n",
      "Processing: 1zTNyAMz3-MEL-v22KhoIPrh-fkr8QO4c.json\n",
      "Processing: 199Hg04UHofn4pvauzofu90fdPfXFbQ_V.json\n",
      "Processing: 1AM3BNP3qoqo_nHZMl0RZKQffIi62wBPQ.json\n",
      "Processing: 1vDUJUiwykFd0Jfz6MYeojQKEAOYiLYAH.json\n",
      "Processing: 1THjPNauR474s_9_KKCLNLJMCxdjazStr.json\n",
      "Processing: 1CQCN3WAze2XL8AFXpSOffYmfQhAN1aSV.json\n",
      "Processing: 1FL01RBzTbP0n14Nkh8OkYaVp_lLQcLK6.json\n",
      "Processing: 1NZCu9Nm_gDLB7BQ1iZ-R4-sP7YY94qKX.json\n",
      "Processing: 12Hy8zETbqkppKYsjGx4unURVJzT5yOre.json\n",
      "Processing: 1Zqm5rvCzwx0xeUE2VqJ1tx6_y-F9C8nm.json\n",
      "Processing: 158deVqlYa2N9IN-eNxVLw7hLMi36gwE1.json\n",
      "Processing: 1QIZ5_sIU_1Iv5Ml1d_so8HPOHR0s8doY.json\n",
      "Processing: 1kAPfGmeqFgYZ4xl3TBkzUHYukkt2fpR6.json\n",
      "Processing: 1L5rJlrSpDyV3HT7NBb7pU4wIvZLTr5TY.json\n",
      "Processing: 1Ex_XiEnEfGvpLEheuhj-ZUuu4aVTc0q-.json\n",
      "Processing: 1jTxcB8xAAjWlY0T0UIJAt7ycM1gnH0on.json\n",
      "Processing: 1Oy_ztdMrCW6wiW61RvKB9aAAyo7jDC_U.json\n",
      "Processing: 15BmV7GP7sRcruBZqslNfHLjpKp31VlW7.json\n",
      "Processing: 1uU28jLtLHaZM63YQf2HAUqlHm76Y84Uu.json\n",
      "Processing: 12xQXXUXkApDNqvwXZKGJGPsCNbxnbvcR.json\n",
      "Processing: 1x03PXWEs2CTDjnyWgX6WkQXtil_KO7A1.json\n",
      "Processing: 1hBGIIO1iAs_TOcl-D22I48dmXTYs36zs.json\n",
      "Processing: 14VKzIcDY0jPyZj5q8U-3ji5Uc5JsqFfh.json\n",
      "Processing: 1be2_yTWew_6U4RVvU7sRdE01PX16NYof.json\n",
      "Processing: 1KeDmjC7XFRK5mX9OXHTjGMbVzViRUOEG.json\n",
      "Processing: 1OXvNXnZoRS1Px4NCsSULspE5hdlHmD81.json\n",
      "Processing: 1FAzFYv-fOH5v-IrxH2nn_f9n2PrfpNjl.json\n",
      "Processing: 1KGK4DybzhOU3abJofcNOjT3nTh0ezzPy.json\n",
      "Processing: 11j9ogx3XDIe_oHPNSrXLdo-ZRd9gTBj_.json\n",
      "Processing: 19cEqh_5Qs5XhqBpMWB7NUlK6xdJzz0Nl.json\n",
      "Processing: 1UsbsUJfmYjAYMT0gx6Vf31E-rHgdfN6v.json\n",
      "Processing: 1HuIQZClE7GAA-Qx-bgfYJeD-cEz7x69Z.json\n",
      "Processing: 1LLfohSnpQkrwWmnWn5Z870--iAEfNi8q.json\n",
      "Processing: 1GmwZRUz9Owkf2TclEkiiq3s58YCekLnd.json\n",
      "Processing: 19HmT3nrmY465GRcrME91k550Km9qpB9O.json\n",
      "Processing: 1Jv96_tXn4GhS1SzDFGSoil7hydrHiIvj.json\n",
      "Processing: 15Yz7fwUf4EuKwh_Pi6ugC6lSNEZwDRmV.json\n",
      "Processing: 1LEJxDd8mDp5qgM7fU4HN4OlUZc3LPOLg.json\n",
      "Processing: 1my4v1sJ954TLesO7CesaeQ-43Y9iizqB.json\n",
      "Processing: 1oru8cEwM3EEZJqafKnSp0-FY-OG16C7_.json\n",
      "Processing: 1SbSrys_ssUfWkIAjva6dTHWHfKtKnEHh.json\n",
      "Processing: 1ISirhbmPOg8hMIJuvIHVtv-MymPC13cO.json\n",
      "Processing: 19bAuEuQhKrVwuCYprslbAPITShNN5A24.json\n",
      "Processing: 1xtWX10-Qg6e0EHglgMpDWp0NARwIisYH.json\n",
      "Processing: 1F8pDEDA3UzOzRmt2fK3DTUBXQWFeMNrv.json\n",
      "Processing: 1zffjzl7-PSmyfljmyWzp98JHSuvbf1Mz.json\n",
      "Processing: 1Qam-Yq2JidOmOm9pvQRR-d62w5IHLlkZ.json\n",
      "Processing: 1RYoBPEVpVFvUO-uLDTWx2vckSq73Ihp-.json\n",
      "Processing: 10MGY0KFzDDatqxqAAnb_Qr3QERkrIt76.json\n",
      "Processing: 1kv9kfPyGyjvY1O1UH_01iLctxfS1UGk9.json\n",
      "Processing: 1L-Vx6dHcuOZDgtTOrk9k9AvOgYCum6dQ.json\n",
      "Processing: 1wCdxBB8zovCbxQlkRHwVk1Oqar-Qbshv.json\n",
      "Processing: 1zD0DbXGuzDmuuKWFKurLk5hp4-YHgzJt.json\n",
      "Processing: 1h7qcHGK0u13_ZSo5C-Zf6DWfDkkIAUCB.json\n",
      "Processing: 1nj5pO3qUOUj_V2OAWtEzQu-ly9lJA32Z.json\n",
      "Processing: 1xGEHflfPWwOrHG16aSmca7I77zOtsCwr.json\n",
      "Processing: 1_slXeCkFcpl5tT_bh1SnFzIz3qPSNQjW.json\n",
      "Processing: 1ogdDTsrSk7Puy8HvD5HwTN4Lx2rxRYDx.json\n",
      "Processing: 1BR_cMikfmC48VdgJCGTX_-Wtl6LsJWUv.json\n",
      "Processing: 1wx_UisDlDKa4LQKr99z2X0yDtFBRHs_F.json\n",
      "Processing: 1lBqPQrCdJma67bajak4aDA4ig5AHprL4.json\n",
      "Processing: 1e6ORvNVBNteC_5q2IhnfdReEdsn_bb_-.json\n",
      "Processing: 1ca91-ZE2u1uigCJgT-da-fypBEtzYNvB.json\n",
      "Processing: 1-lWGDxx41n9sg87yIsqVTur1ZVpR0nSO.json\n",
      "Processing: 15eYkWuWKMfAJF5yntXj7FB-0fVdjes6s.json\n",
      "Processing: 1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>webViewLink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1gDHNp-3SGT9jv9v7IFhIk0QJ0BXXJLwn</td>\n",
       "      <td>1-T2Bxssul-cYzS8QdPazVA_IIYW_8JW2.json</td>\n",
       "      <td>https://drive.google.com/file/d/1gDHNp-3SGT9jv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1HWsDfkGwIqFJd3HGBkKMQeWgIM25sq6y</td>\n",
       "      <td>1CiGvfxnTRuaj_Vz0YFRlkugt2aCaInY3.json</td>\n",
       "      <td>https://drive.google.com/file/d/1HWsDfkGwIqFJd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1sjtNn_FpTmh4Y_NwQoovcJ1NIIQztwF-</td>\n",
       "      <td>1gFo4j12t_J-ldX7AfpsPn0MtJzJJeHH8.json</td>\n",
       "      <td>https://drive.google.com/file/d/1sjtNn_FpTmh4Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1wyX7M98j0CJW0VuuogbJIjkmlLYTMio6</td>\n",
       "      <td>18vLHs0ouk3_3CW1Ouw1zImSdjpkF4EE_.json</td>\n",
       "      <td>https://drive.google.com/file/d/1wyX7M98j0CJW0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1w1DSLeLKvd2FBpECMspj79wMQQqbs5qA</td>\n",
       "      <td>19BLNm2kR9hRGNTRGVJQo1WfWB6JW8yUO.json</td>\n",
       "      <td>https://drive.google.com/file/d/1w1DSLeLKvd2FB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1Cn7ajO_CZYXyI8g_RPx7NIjXlucCwSfH</td>\n",
       "      <td>1e6ORvNVBNteC_5q2IhnfdReEdsn_bb_-.json</td>\n",
       "      <td>https://drive.google.com/file/d/1Cn7ajO_CZYXyI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>1Ay0oht_Viu2IRvycMOezP92DBfid9Ltq</td>\n",
       "      <td>1ca91-ZE2u1uigCJgT-da-fypBEtzYNvB.json</td>\n",
       "      <td>https://drive.google.com/file/d/1Ay0oht_Viu2IR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1FpcZv93zjZeATjXZWiGMxDrWz0xBp6l4</td>\n",
       "      <td>1-lWGDxx41n9sg87yIsqVTur1ZVpR0nSO.json</td>\n",
       "      <td>https://drive.google.com/file/d/1FpcZv93zjZeAT...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1EuRDw6xBrAxbK3c8MLURLZDXv82-6-FG</td>\n",
       "      <td>15eYkWuWKMfAJF5yntXj7FB-0fVdjes6s.json</td>\n",
       "      <td>https://drive.google.com/file/d/1EuRDw6xBrAxbK...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1JDiCGG78xDtjPK2taErhow2ak6JCqBQd</td>\n",
       "      <td>1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f.json</td>\n",
       "      <td>https://drive.google.com/file/d/1JDiCGG78xDtjP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  \\\n",
       "0    1gDHNp-3SGT9jv9v7IFhIk0QJ0BXXJLwn   \n",
       "1    1HWsDfkGwIqFJd3HGBkKMQeWgIM25sq6y   \n",
       "2    1sjtNn_FpTmh4Y_NwQoovcJ1NIIQztwF-   \n",
       "3    1wyX7M98j0CJW0VuuogbJIjkmlLYTMio6   \n",
       "4    1w1DSLeLKvd2FBpECMspj79wMQQqbs5qA   \n",
       "..                                 ...   \n",
       "639  1Cn7ajO_CZYXyI8g_RPx7NIjXlucCwSfH   \n",
       "640  1Ay0oht_Viu2IRvycMOezP92DBfid9Ltq   \n",
       "641  1FpcZv93zjZeATjXZWiGMxDrWz0xBp6l4   \n",
       "642  1EuRDw6xBrAxbK3c8MLURLZDXv82-6-FG   \n",
       "643  1JDiCGG78xDtjPK2taErhow2ak6JCqBQd   \n",
       "\n",
       "                                       name  \\\n",
       "0    1-T2Bxssul-cYzS8QdPazVA_IIYW_8JW2.json   \n",
       "1    1CiGvfxnTRuaj_Vz0YFRlkugt2aCaInY3.json   \n",
       "2    1gFo4j12t_J-ldX7AfpsPn0MtJzJJeHH8.json   \n",
       "3    18vLHs0ouk3_3CW1Ouw1zImSdjpkF4EE_.json   \n",
       "4    19BLNm2kR9hRGNTRGVJQo1WfWB6JW8yUO.json   \n",
       "..                                      ...   \n",
       "639  1e6ORvNVBNteC_5q2IhnfdReEdsn_bb_-.json   \n",
       "640  1ca91-ZE2u1uigCJgT-da-fypBEtzYNvB.json   \n",
       "641  1-lWGDxx41n9sg87yIsqVTur1ZVpR0nSO.json   \n",
       "642  15eYkWuWKMfAJF5yntXj7FB-0fVdjes6s.json   \n",
       "643  1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f.json   \n",
       "\n",
       "                                           webViewLink  \n",
       "0    https://drive.google.com/file/d/1gDHNp-3SGT9jv...  \n",
       "1    https://drive.google.com/file/d/1HWsDfkGwIqFJd...  \n",
       "2    https://drive.google.com/file/d/1sjtNn_FpTmh4Y...  \n",
       "3    https://drive.google.com/file/d/1wyX7M98j0CJW0...  \n",
       "4    https://drive.google.com/file/d/1w1DSLeLKvd2FB...  \n",
       "..                                                 ...  \n",
       "639  https://drive.google.com/file/d/1Cn7ajO_CZYXyI...  \n",
       "640  https://drive.google.com/file/d/1Ay0oht_Viu2IR...  \n",
       "641  https://drive.google.com/file/d/1FpcZv93zjZeAT...  \n",
       "642  https://drive.google.com/file/d/1EuRDw6xBrAxbK...  \n",
       "643  https://drive.google.com/file/d/1JDiCGG78xDtjP...  \n",
       "\n",
       "[644 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "# Function to check if a file is a folder\n",
    "def is_folder(file):\n",
    "    return file.get('mimeType') == 'application/vnd.google-apps.folder'\n",
    "\n",
    "# Function to process files and folders\n",
    "def process_files(service, folder_id, parent_folders=[]):\n",
    "    query = f\"'{folder_id}' in parents and trashed = false\"\n",
    "    page_token = None\n",
    "\n",
    "    all_files = []\n",
    "    while True:\n",
    "        response = service.files().list(q=query,\n",
    "                                        spaces='drive',\n",
    "                                        fields='nextPageToken, files(id, name, mimeType, webViewLink)',\n",
    "                                        pageToken=page_token).execute()\n",
    "\n",
    "        for file in response.get('files', []):\n",
    "            # Skip 'tool_data' folder\n",
    "            if file.get('name') == 'tool_data' and is_folder(file):\n",
    "                continue\n",
    "\n",
    "            all_files.append(file)\n",
    "\n",
    "            # Process the file or folder\n",
    "            print('Processing:', '/'.join(parent_folders + [file.get('name')]))\n",
    "\n",
    "            # If it's a folder, recursively process its contents\n",
    "            if is_folder(file):\n",
    "                children_files = process_files(service, file.get('id'), parent_folders + [file.get('name')])\n",
    "                all_files.extend(children_files)\n",
    "\n",
    "        page_token = response.get('nextPageToken', None)\n",
    "        if page_token is None:\n",
    "            break\n",
    "\n",
    "    return all_files\n",
    "\n",
    "# Authenticate and create the service\n",
    "SERVICE_ACCOUNT_FILE = service_account_file\n",
    "SCOPES = ['https://www.googleapis.com/auth/drive']\n",
    "credentials = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('drive', 'v3', credentials=credentials)\n",
    "\n",
    "# Replace with your Google Drive folder ID\n",
    "folder_id = destination_folder_url.split(\"/\")[-1]\n",
    "\n",
    "# Start processing from the specified folder\n",
    "all_files = process_files(service, folder_id)\n",
    "\n",
    "jsonl_df = pd.DataFrame(all_files)\n",
    "jsonl_df = jsonl_df[[\"id\", \"name\", \"webViewLink\"]]\n",
    "jsonl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colab_id</th>\n",
       "      <th>task_link</th>\n",
       "      <th>number_of_turns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f</td>\n",
       "      <td>https://colab.research.google.com/drive/1j1MYr...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1uU28jLtLHaZM63YQf2HAUqlHm76Y84Uu</td>\n",
       "      <td>https://colab.research.google.com/drive/1uU28j...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_slXeCkFcpl5tT_bh1SnFzIz3qPSNQjW</td>\n",
       "      <td>https://colab.research.google.com/drive/1_slXe...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1GmwZRUz9Owkf2TclEkiiq3s58YCekLnd</td>\n",
       "      <td>https://colab.research.google.com/drive/1GmwZR...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1xtWX10-Qg6e0EHglgMpDWp0NARwIisYH</td>\n",
       "      <td>https://colab.research.google.com/drive/1xtWX1...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1WPcWsi5FaHY30NPNH_Et5gRThCvSA6Wb</td>\n",
       "      <td>https://colab.research.google.com/drive/1WPcWs...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>18vLHs0ouk3_3CW1Ouw1zImSdjpkF4EE_</td>\n",
       "      <td>https://colab.research.google.com/drive/18vLHs...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>1CiGvfxnTRuaj_Vz0YFRlkugt2aCaInY3</td>\n",
       "      <td>https://colab.research.google.com/drive/1CiGvf...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1gFo4j12t_J-ldX7AfpsPn0MtJzJJeHH8</td>\n",
       "      <td>https://colab.research.google.com/drive/1gFo4j...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>1-T2Bxssul-cYzS8QdPazVA_IIYW_8JW2</td>\n",
       "      <td>https://colab.research.google.com/drive/1-T2Bx...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              colab_id  \\\n",
       "0    1j1MYrC5QM0lMjKqyCdEzyZZEEotFjl-f   \n",
       "1    1uU28jLtLHaZM63YQf2HAUqlHm76Y84Uu   \n",
       "2    1_slXeCkFcpl5tT_bh1SnFzIz3qPSNQjW   \n",
       "3    1GmwZRUz9Owkf2TclEkiiq3s58YCekLnd   \n",
       "4    1xtWX10-Qg6e0EHglgMpDWp0NARwIisYH   \n",
       "..                                 ...   \n",
       "639  1WPcWsi5FaHY30NPNH_Et5gRThCvSA6Wb   \n",
       "640  18vLHs0ouk3_3CW1Ouw1zImSdjpkF4EE_   \n",
       "641  1CiGvfxnTRuaj_Vz0YFRlkugt2aCaInY3   \n",
       "642  1gFo4j12t_J-ldX7AfpsPn0MtJzJJeHH8   \n",
       "643  1-T2Bxssul-cYzS8QdPazVA_IIYW_8JW2   \n",
       "\n",
       "                                             task_link number_of_turns  \n",
       "0    https://colab.research.google.com/drive/1j1MYr...               4  \n",
       "1    https://colab.research.google.com/drive/1uU28j...               9  \n",
       "2    https://colab.research.google.com/drive/1_slXe...               4  \n",
       "3    https://colab.research.google.com/drive/1GmwZR...               8  \n",
       "4    https://colab.research.google.com/drive/1xtWX1...               5  \n",
       "..                                                 ...             ...  \n",
       "639  https://colab.research.google.com/drive/1WPcWs...               3  \n",
       "640  https://colab.research.google.com/drive/18vLHs...               7  \n",
       "641  https://colab.research.google.com/drive/1CiGvf...               3  \n",
       "642  https://colab.research.google.com/drive/1gFo4j...               2  \n",
       "643  https://colab.research.google.com/drive/1-T2Bx...               3  \n",
       "\n",
       "[644 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_jsons_ref = [\n",
    "    {\n",
    "        \"colab_id\": pj[\"id\"],\n",
    "        \"task_link\": pj[\"metadata\"][\"task_link\"],\n",
    "        \"number_of_turns\": pj[\"metadata\"][\"number_of_turns\"],\n",
    "    }\n",
    "    for pj\n",
    "    in parsed_jsons\n",
    "]\n",
    "conversation_df = pd.DataFrame(parsed_jsons_ref)\n",
    "conversation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_link</th>\n",
       "      <th>number_of_turns</th>\n",
       "      <th>jsonl_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://colab.research.google.com/drive/1j1MYr...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1JDiCGG78xDtjP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://colab.research.google.com/drive/1uU28j...</td>\n",
       "      <td>9</td>\n",
       "      <td>https://drive.google.com/file/d/1x5Y-4MEakvBaE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://colab.research.google.com/drive/1_slXe...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://drive.google.com/file/d/1Lopn3R4e4_dgM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://colab.research.google.com/drive/1GmwZR...</td>\n",
       "      <td>8</td>\n",
       "      <td>https://drive.google.com/file/d/1x2oHoNUXg0R4i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://colab.research.google.com/drive/1xtWX1...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://drive.google.com/file/d/1zr6CWZ5nxrAxw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>https://colab.research.google.com/drive/1WPcWs...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1UbPmxmbDtbHII...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>https://colab.research.google.com/drive/18vLHs...</td>\n",
       "      <td>7</td>\n",
       "      <td>https://drive.google.com/file/d/1wyX7M98j0CJW0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>https://colab.research.google.com/drive/1CiGvf...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1HWsDfkGwIqFJd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>https://colab.research.google.com/drive/1gFo4j...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://drive.google.com/file/d/1sjtNn_FpTmh4Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>https://colab.research.google.com/drive/1-T2Bx...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://drive.google.com/file/d/1gDHNp-3SGT9jv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             task_link number_of_turns  \\\n",
       "0    https://colab.research.google.com/drive/1j1MYr...               4   \n",
       "1    https://colab.research.google.com/drive/1uU28j...               9   \n",
       "2    https://colab.research.google.com/drive/1_slXe...               4   \n",
       "3    https://colab.research.google.com/drive/1GmwZR...               8   \n",
       "4    https://colab.research.google.com/drive/1xtWX1...               5   \n",
       "..                                                 ...             ...   \n",
       "639  https://colab.research.google.com/drive/1WPcWs...               3   \n",
       "640  https://colab.research.google.com/drive/18vLHs...               7   \n",
       "641  https://colab.research.google.com/drive/1CiGvf...               3   \n",
       "642  https://colab.research.google.com/drive/1gFo4j...               2   \n",
       "643  https://colab.research.google.com/drive/1-T2Bx...               3   \n",
       "\n",
       "                                            jsonl_link  \n",
       "0    https://drive.google.com/file/d/1JDiCGG78xDtjP...  \n",
       "1    https://drive.google.com/file/d/1x5Y-4MEakvBaE...  \n",
       "2    https://drive.google.com/file/d/1Lopn3R4e4_dgM...  \n",
       "3    https://drive.google.com/file/d/1x2oHoNUXg0R4i...  \n",
       "4    https://drive.google.com/file/d/1zr6CWZ5nxrAxw...  \n",
       "..                                                 ...  \n",
       "639  https://drive.google.com/file/d/1UbPmxmbDtbHII...  \n",
       "640  https://drive.google.com/file/d/1wyX7M98j0CJW0...  \n",
       "641  https://drive.google.com/file/d/1HWsDfkGwIqFJd...  \n",
       "642  https://drive.google.com/file/d/1sjtNn_FpTmh4Y...  \n",
       "643  https://drive.google.com/file/d/1gDHNp-3SGT9jv...  \n",
       "\n",
       "[644 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonl_df[\"colab_id\"] = jsonl_df[\"name\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "\n",
    "df_merged = conversation_df.merge(jsonl_df, on=\"colab_id\", how=\"inner\")\n",
    "df_merged = df_merged[[\"task_link\", \"number_of_turns\", \"webViewLink\"]]\n",
    "df_merged = df_merged.rename(columns={\"webViewLink\": \"jsonl_link\"})\n",
    "df_merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload Batch Sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new sheet: 'Batch 11'\n"
     ]
    }
   ],
   "source": [
    "from src.sheets_utils import upload_df_to_sheet, GoogleSheetsService\n",
    "\n",
    "cols = [\"task_link\", \"jsonl_link\", \"number_of_turns\"]\n",
    "\n",
    "sheets_client = GoogleSheetsService(service_account_file, ['https://www.googleapis.com/auth/spreadsheets'])\n",
    "sheets_client.ensure_sheet_exists(delivery_sheet_id, DELIVERY_BATCH_NAME)\n",
    "upload_df_to_sheet(service_account_file, delivery_sheet_id, DELIVERY_BATCH_NAME, df_merged[cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
