{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "from src.Q_generator.question_generator import QuestionGenerator\n",
    "from src.Q_generator.question_processor import crawl_keys\n",
    "from src.Q_generator.question_processor import process_problems, find_and_load_all_problems, extract_questions_by_topic, load_complexity_data, flatten_complexity_scores, sort_and_rank_complexity_scores, create_and_save_notebook, process_notebooks_in_folder\n",
    "from src.Q_generator.gdrive_upload import build_service_and_upload_files, update_problems_with_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = QuestionGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = \"./notebooks\"\n",
    "all_problems = find_and_load_all_problems(parent_dir)\n",
    "questions_grouped_by_topics = extract_questions_by_topic(all_problems)\n",
    "\n",
    "# # Printing each topic and its questions\n",
    "# for topic, questions in questions_grouped_by_topic.items():\n",
    "#     print(f\"Topic: {topic}\")\n",
    "#     for question in questions:\n",
    "#         print(f\" - {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the `topic_hierarchy.json` file and retrieve all topics\n",
    "with open('topic_hierarchy.json') as json_file:\n",
    "    topic_hierarchy = json.load(json_file)\n",
    "\n",
    "all_topics = crawl_keys(topic_hierarchy)\n",
    "print(f\"Total number of topics: {len(all_topics)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    with open(\"./configs/config.json\", \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "config = load_config()\n",
    "\n",
    "MAX_QUESTIONS = config[\"MAX_QUESTIONS\"]\n",
    "generated_questions_count = config[\"generated_questions_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "questions_grouped_by_topic = {}\n",
    "\n",
    "# Convert if the existing questions are not grouped by full topic paths\n",
    "for topic in all_topics:\n",
    "    questions_grouped_by_topic[topic] = questions_grouped_by_topics.get(topic, set())\n",
    "\n",
    "problems = []\n",
    "generated_questions_count = config[\"generated_questions_count\"]\n",
    "\n",
    "\n",
    "# Function to generate questions for a given topic\n",
    "def generate_for_topic(topic):\n",
    "    global generated_questions_count\n",
    "\n",
    "    new_problems = []\n",
    "    existing_questions = questions_grouped_by_topic[topic]\n",
    "\n",
    "    if generated_questions_count < MAX_QUESTIONS:\n",
    "        questions = generator.generate_human_like_questions(topic, 3, existing_questions)\n",
    "        for question in questions[\"questions\"]:\n",
    "            if generated_questions_count >= MAX_QUESTIONS:\n",
    "                break\n",
    "            new_problems.append({\n",
    "                \"metadata\": {\n",
    "                    \"topic\": topic,\n",
    "                    \"type\": \"query\",\n",
    "                    \"difficulty\": \"Easy\",\n",
    "                    \"target_length\": 1\n",
    "                },\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": question},\n",
    "                ]\n",
    "            })\n",
    "            generated_questions_count += 1\n",
    "    return new_problems\n",
    "\n",
    "# Set the maximum number of threads to use\n",
    "MAX_THREADS = 20\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "    # Create a dictionary to store future-to-topic mapping\n",
    "    future_to_topic = {executor.submit(generate_for_topic, topic): topic for topic in questions_grouped_by_topic.keys()}\n",
    "\n",
    "    with tqdm(total=MAX_QUESTIONS) as pbar:\n",
    "        for future in as_completed(future_to_topic):\n",
    "            new_problems = future.result()\n",
    "            problems.extend(new_problems)\n",
    "            pbar.update(len(new_problems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_titles, file_path_to_problem, problem_topic_counts = process_problems(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complexity_data = load_complexity_data('./topic_dist.json')\n",
    "complexity_scores = flatten_complexity_scores(complexity_data)\n",
    "topic_percentiles = sort_and_rank_complexity_scores(complexity_scores)\n",
    "\n",
    "create_and_save_notebook('notebooks/v3/old_pipe/{}.ipynb', problems, problem_titles, topic_percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creds_path = 'creds/google__sa.json'\n",
    "folder_path = './notebooks/v3/new_pipe/batch_1/'\n",
    "destination_folder_url = 'https://drive.google.com/drive/u/2/folders/1FuHZZ18qn6k8iXTi5YbstGRr56w0kDEz'\n",
    "\n",
    "file_path_to_url = build_service_and_upload_files(creds_path, folder_path, destination_folder_url)\n",
    "update_problems_with_metadata(file_path_to_url, file_path_to_problem, \"batch_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = 'creds/google__sa.json'\n",
    "\n",
    "# The scopes required for the Sheets API\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "# The ID of your spreadsheet\n",
    "SPREADSHEET_ID = '1qBU7Kvuuij2fxbqPxebReKMxWgIBmOIE5Gi4ZuX0j_4'\n",
    "\n",
    "# Authenticate and build the service\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "        SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "# Specify the range and values to update\n",
    "range_ = 'Conversations_Batch_5!A380:E1000'  # For example, this updates cells from A1 to D5 in Sheet1\n",
    "values = []\n",
    "\n",
    "for problem in problems:\n",
    "    values.append([\n",
    "        problem[\"metadata\"][\"colab_url\"],\n",
    "        problem[\"metadata\"][\"topic\"],\n",
    "    ])\n",
    "\n",
    "\n",
    "body = {\n",
    "    'values': values\n",
    "}\n",
    "\n",
    "# Call the Sheets API to update the range\n",
    "request = service.spreadsheets().values().update(spreadsheetId=SPREADSHEET_ID, range=range_, valueInputOption='RAW', body=body)\n",
    "response = request.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './notebooks/v3/new_pipe/batch_2/'\n",
    "process_notebooks_in_folder(folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
